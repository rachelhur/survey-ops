{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a78b1b7",
   "metadata": {},
   "source": [
    "# Simple sequence imitation with DQN in pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c564147-dfec-4075-963e-541d9e9a0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../environments')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from neural_nets import DQN, exponential_schedule, linear_schedule\n",
    "from buffer import ReplayBuffer\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62949243",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(X,Y):\n",
    "  \"\"\"\"\"\"\n",
    "  return cdist(X,Y,metric='euclidean')\n",
    "\n",
    "def get_distance(point1,point2):\n",
    "    \"\"\"Compute Euclidean distance between two points.\"\"\"\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "006df58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'ToyEnv_v1'\n",
    "OUTDIR = f'results/{env_name}/'\n",
    "if not os.path.exists(OUTDIR):\n",
    "    os.makedirs(OUTDIR)\n",
    "    \n",
    "SEED = 10\n",
    "seed_everything(SEED)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"cpu\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec5166e",
   "metadata": {},
   "source": [
    "# Simulate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a618ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_fields(coords, distance_matrix):\n",
    "    \"\"\"\n",
    "    Given a list of coordinates, picks the field closest to the origin first, then \n",
    "    always picks the field closest unless it has already been visited\n",
    "    \"\"\"\n",
    "    ordered_indices = np.argsort(distance_matrix, axis=1) # low to high\n",
    "\n",
    "    start_ind = np.argmin(np.sum(coords**2, axis=1))\n",
    "    target_indices = [start_ind]\n",
    "\n",
    "    last_ind = start_ind\n",
    "    for i in range(len(coords) - 1):\n",
    "        j = 0\n",
    "        current_ind = ordered_indices[last_ind][j]\n",
    "        while current_ind in target_indices:\n",
    "            j += 1\n",
    "            current_ind = ordered_indices[last_ind][j]\n",
    "        target_indices.append(current_ind)\n",
    "        last_ind = current_ind\n",
    "    return target_indices, coords[target_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4fff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_dataset(n_datasets=100):\n",
    "    def get_target_fields(coords, distance_matrix):\n",
    "        \"\"\"\n",
    "        Given a list of coordinates, picks the field closest to the origin first, then \n",
    "        always picks the field closest unless it has already been visited\n",
    "        \"\"\"\n",
    "        ordered_indices = np.argsort(distance_matrix, axis=1) # low to high\n",
    "\n",
    "        start_ind = np.argmin(np.sum(coords**2, axis=1))\n",
    "        target_indices = [start_ind]\n",
    "\n",
    "        last_ind = start_ind\n",
    "        for i in range(len(coords) - 1):\n",
    "            j = 0\n",
    "            current_ind = ordered_indices[last_ind][j]\n",
    "            while current_ind in target_indices:\n",
    "                j += 1\n",
    "                current_ind = ordered_indices[last_ind][j]\n",
    "            target_indices.append(current_ind)\n",
    "            last_ind = current_ind\n",
    "        return target_indices, coords[target_indices]\n",
    "    grid_max = 10\n",
    "    ra_range = (-grid_max, grid_max)\n",
    "    dec_range = (-grid_max, grid_max)\n",
    "    n_points = grid_max\n",
    "    \n",
    "    # generate random coords\n",
    "    ra_list = np.random.randint(ra_range[0], ra_range[1], size=(n_datasets, n_points))\n",
    "    dec_list = np.random.randint(dec_range[0], dec_range[1], size=(n_datasets, n_points))\n",
    "    coords = np.stack([ra_list, dec_list], axis=2) # shape (num_ep, nra_points, ndec_points)\n",
    "    coords_dict = {f'eps{i}': coord for i, coord in enumerate(coords)}\n",
    "    \n",
    "    distance_matrices = np.empty(shape=(n_datasets, grid_max, grid_max))\n",
    "    full_target_fields = []\n",
    "    full_target_coords = []\n",
    "    # get distance matrices\n",
    "    for i in range(n_datasets):\n",
    "        distance_matrices[i] = get_distance_matrix(coords[i], coords[i])\n",
    "        np.fill_diagonal(distance_matrices[i], np.inf)\n",
    "        target_fields, target_coords = get_target_fields(coords[i], distance_matrices[i])\n",
    "        full_target_fields.append(target_fields)\n",
    "        full_target_coords.append(target_coords)\n",
    "        # full_target_coords.append(coords[i][target_fields])\n",
    "    return np.array(full_target_fields), np.array(full_target_coords), coords_dict, coords\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06111e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fields, target_coords, coords_dict, coords = generate_dataset(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d4f9a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f249238c790>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), layout='constrained')\n",
    "ax.plot(target_coords[j][:, 0], target_coords[j][:, 1], linestyle='dotted', label='target sequence', zorder=1, color='grey')\n",
    "\n",
    "for i, index in enumerate(target_fields[j]):\n",
    "    if i == 0:\n",
    "        marker = '*'\n",
    "        s = 500\n",
    "        label='start'\n",
    "    elif i == len(target_fields[j])-1:\n",
    "        marker = 's'\n",
    "        s = 200\n",
    "        label='end'\n",
    "    else:\n",
    "        marker = 'o'\n",
    "        s = 30\n",
    "        label=None\n",
    "    ax.scatter(coords[j][index][0], coords[j][index][1], marker=marker, s=s, label=label)\n",
    "# fig.legend(bbox_to_anchor=(1.2, 1), loc='upper right')\n",
    "fig.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7118f272",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fields = target_fields[0]\n",
    "target_coords = target_coords[0]\n",
    "coords = coords[0]\n",
    "coords_dict = {i: coord for i, coord in enumerate(coords_dict['eps0'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddeca7c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True],\n",
       "       [ True,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_coords == coords[target_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dafe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyEnv_v1(gym.Env):\n",
    "    def __init__(self, coords_dict, max_visits, target_fields):\n",
    "        super().__init__()\n",
    "        # instantiate static attributes\n",
    "        self.coords_dict = coords_dict # field_id: (x,y)\n",
    "        self.nfields = len(coords_dict)\n",
    "        self.max_visits = max_visits\n",
    "        self.zenith = np.array([0.0,0.0])\n",
    "        self.target_fields = target_fields\n",
    "        self.total_visits = int(self.nfields * self.max_visits)\n",
    "\n",
    "        # Initialize variable attributes - will be set in reset()\n",
    "        self._init_to_nonstate()\n",
    "       \n",
    "        # Define observation space - (step, fieldid, nvisits array)\n",
    "        self.obs_size = 2 + self.nfields\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-1,\n",
    "            high=1e5,\n",
    "            shape=(self.obs_size,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # Define action space        \n",
    "        self.action_space = gym.spaces.Discrete(self.nfields)\n",
    "\n",
    "    \n",
    "    \n",
    "    # ------------------------------------------------------------ #\n",
    "    # -----------------------Gymnasium API ----------------------- #\n",
    "    # ------------------------------------------------------------ #\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Start a new episode.\n",
    "\n",
    "        Args:\n",
    "            seed: Random seed for reproducible episodes\n",
    "            options: Additional configuration (unused in this example)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, info) for the initial state\n",
    "        \"\"\"\n",
    "        # IMPORTANT: Must call this first to seed the random number generator\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # initialize into a non-state.\n",
    "        # this allows first field choice to be learned\n",
    "        self._init_to_nonstate()\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return obs, info\n",
    "    \n",
    "    def step(self, action: int):\n",
    "        \"\"\"Execute one timestep within the environment.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        assert self.action_space.contains(action), f\"Invalid action {action}\"\n",
    "        self._update_obs(action)\n",
    "        # if self._step_count == 0:\n",
    "        #     last_field_coord = self.zenith\n",
    "        # else:\n",
    "        #     last_field_coord = self.coords_dict[self._visited[-2]]\n",
    "\n",
    "        # separation = get_distance(self._coord, last_field_coord)\n",
    "        # if separation <= self.nfields//5*2:\n",
    "        #     reward = 1\n",
    "        # elif separation <= self.nfields//5*3:\n",
    "        #     reward = .5\n",
    "        # elif separation <= self.nfields//5*4:\n",
    "        #     reward = .1\n",
    "        # else:\n",
    "        #     reward = 0\n",
    "\n",
    "        if self._step_count < len(self.target_fields):\n",
    "            correct_field = self.target_fields[self._step_count]\n",
    "            if action == correct_field:\n",
    "                reward = 1.0\n",
    "            elif abs(action - correct_field) == 1:\n",
    "                reward = .25\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        # end condition\n",
    "        truncated = False\n",
    "        terminated = self._step_count + 1 >= self.total_visits\n",
    "\n",
    "        # get obs and info\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "            \n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    # ------------------------------------------------------------ #\n",
    "    # -------------Convenience functions-------------------------- #\n",
    "    # ------------------------------------------------------------ #\n",
    "\n",
    "    def _init_to_nonstate(self):\n",
    "        self._step_count = -1\n",
    "        self._field_id = -1\n",
    "        self._nvisits = np.zeros(self.nfields, dtype=np.int32)\n",
    "        self._visited = []\n",
    "        self._coord = np.array([None, None])\n",
    "        self._action_mask = np.ones(self.nfields, dtype=bool)\n",
    "\n",
    "    def _update_action_mask(self):\n",
    "        \"\"\"Update mask for cutting invalid actions.\n",
    "        Must update self._field and self._nvisits before updating actions\n",
    "        \"\"\"\n",
    "        self._action_mask = self._nvisits < self.max_visits\n",
    "\n",
    "    def _update_obs(self, action):\n",
    "        self._step_count += 1\n",
    "        self._field_id = action\n",
    "        self._nvisits[action] += 1\n",
    "        self._visited.append(action)\n",
    "        self._coord = np.array(self.coords_dict[action], dtype=np.float32) #TODO need to change for closest distance learning\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"Convert internal state to observation format.\n",
    "    \n",
    "        Returns:\n",
    "            dict: Observation with agent and target positions\n",
    "        \"\"\"\n",
    "        obs = np.concatenate((\n",
    "            np.array([self._step_count], dtype=np.float32),\n",
    "            np.array([self._field_id], dtype=np.float32),\n",
    "            self._nvisits.astype(np.float32)\n",
    "        ))\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def _get_info(self):\n",
    "        \"\"\"Compute auxiliary information for debugging.\n",
    "\n",
    "        Returns:\n",
    "            \n",
    "        \"\"\"\n",
    "        return {'action_mask': self._action_mask.copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cabee5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: array([-1,  0]),\n",
       "  1: array([-6, -2]),\n",
       "  2: array([ 5, -6]),\n",
       "  3: array([-10,   9]),\n",
       "  4: array([7, 6]),\n",
       "  5: array([ 6, -6]),\n",
       "  6: array([7, 5]),\n",
       "  7: array([-2,  1]),\n",
       "  8: array([-1,  1]),\n",
       "  9: array([-10,  -9])},\n",
       " array([0, 8, 7, 1, 9, 2, 5, 6, 4, 3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords_dict, target_fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01fef55-9862-4d9a-97bf-69fda1c04689",
   "metadata": {},
   "source": [
    "# Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8aa9dfa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment passes all checks!\n"
     ]
    }
   ],
   "source": [
    "# Register the environment so we can create it with gym.make()\n",
    "gym.register(\n",
    "    id=f\"gymnasium_env/{env_name}\",\n",
    "    entry_point=ToyEnv_v1,\n",
    "    max_episode_steps=300,  # Prevent infinite episodes. Here just set to 300 even though episode will terminate when stepping to last element of sequence\n",
    ")\n",
    "env = gym.make(f\"gymnasium_env/{env_name}\", coords_dict=coords_dict, max_visits=1, target_fields=target_fields)\n",
    "# Create multiple environments for parallel training\n",
    "# vec_env = gym.make_vec(\"gymnasium_env/SimpleTel-v0\", num_envs=5, vectorization_mode='sync', Nf=Nf, target_sequence=true_sequence, nv_max=nv_max)\n",
    "\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "# This will catch many common issues\n",
    "try:\n",
    "    check_env(env.unwrapped)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea705b4",
   "metadata": {},
   "source": [
    "## Pytorch Agent and DQN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dc21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(\n",
    "            self,\n",
    "            env: gym.Env, \n",
    "            replay_buffer: ReplayBuffer, \n",
    "            device,\n",
    "            ):\n",
    "        \"\"\"Base Agent class handling the interaction with the environment.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.device = device\n",
    "\n",
    "        # get obs and action dims for network construction\n",
    "        obs, _ = self.env.reset()\n",
    "        n_observations = len(obs)\n",
    "        n_actions = self.env.action_space.n\n",
    "\n",
    "        # initialize networks\n",
    "        self.policy_net = DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net = DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "        self.reset()\n",
    "        self.steps_done = 0\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the environment and updates the state.\"\"\"\n",
    "        self.obs, self.info = self.env.reset()\n",
    "\n",
    "    def select_action(self, epsilon: float) -> int:\n",
    "        \"\"\"\n",
    "        Epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        # if random sample less than epsilon, take random action\n",
    "        if np.random.random() < epsilon:\n",
    "            valid_actions = np.where(self.info['action_mask'])[0]\n",
    "            action = np.random.choice(valid_actions)\n",
    "            return int(action)\n",
    "\n",
    "        # greedy selection from policy\n",
    "        obs = torch.tensor(self.obs, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_values = self.policy_net(obs).squeeze(0)\n",
    "\n",
    "            # mask invalid actions\n",
    "            mask = torch.tensor(self.info['action_mask'], device=self.device, dtype=torch.bool)\n",
    "            q_values[~mask] = float('-inf')\n",
    "            action = torch.argmax(q_values).item()\n",
    "        return int(action)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def play_step(\n",
    "        self,\n",
    "        epsilon: float = 0.0,\n",
    "        buffer=None,\n",
    "    ) -> Tuple[float, bool]:\n",
    "        \"\"\"\n",
    "        Carries out a single interaction step between the agent and the environment and records experience\n",
    "        \"\"\"\n",
    "        # select action\n",
    "        action = self.select_action(epsilon)\n",
    "\n",
    "        # interact with environment\n",
    "        next_obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        exp_args = (\n",
    "            self.obs,\n",
    "            action,\n",
    "            reward,\n",
    "            next_obs,\n",
    "            terminated,\n",
    "            self.info[\"action_mask\"],\n",
    "            info[\"action_mask\"],\n",
    "        )\n",
    "        \n",
    "        # if predicting\n",
    "        if buffer is None:\n",
    "            self.replay_buffer.append(*exp_args)\n",
    "        else: # training\n",
    "            buffer.append(*exp_args)\n",
    "\n",
    "        # reset or move to next obs\n",
    "        if terminated or truncated:\n",
    "            self.reset()\n",
    "        else:\n",
    "            # set next_obs to current obs for next step\n",
    "            self.obs = next_obs\n",
    "            self.info = info\n",
    "\n",
    "        return reward, terminated\n",
    "\n",
    "    \n",
    "    def predict(self, max_timesteps):\n",
    "        \"\"\"\n",
    "        Rolls out policy.\n",
    "\n",
    "        Returns\n",
    "        ------\n",
    "        buffer: ReplayBuffer\n",
    "            Memory of this roll-out\n",
    "        log: Dict\n",
    "            Contains quantities that might be useful for diagnostics\n",
    "        \"\"\"\n",
    "        log = {\n",
    "            'rewards': [],\n",
    "            'obs': [],\n",
    "            # 'action': [],\n",
    "            'terminated': [],\n",
    "            'action_mask': []\n",
    "            }\n",
    "        \n",
    "        self.reset()\n",
    "        buffer = ReplayBuffer(max_timesteps, device=self.device)\n",
    "        for _ in range(max_timesteps):\n",
    "            reward, terminated = self.play_step(epsilon=0, buffer=buffer)\n",
    "\n",
    "            log['rewards'].append(reward)\n",
    "            log['terminated'].append(terminated)\n",
    "            log['obs'].append(self.obs)\n",
    "            log['action_mask'].append(self.info['action_mask'])\n",
    "\n",
    "            if terminated:\n",
    "                break\n",
    "        return buffer, log\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9261e0b7",
   "metadata": {},
   "source": [
    "## How does model do with no training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b70fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DQNAgent(\n",
    "    env=env,\n",
    "    replay_buffer=ReplayBuffer(10000, device=device),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66720b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer, log = agent.predict(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e774bdee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 3., 0., 1., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False]))],\n",
       "      maxlen=50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f45f1dc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 7, 1, 3, 4, 6, 5, 0, 2]\n",
      "[0 8 7 1 9 2 5 6 4 3]\n"
     ]
    }
   ],
   "source": [
    "print([exp[1] for exp in buffer.buffer])\n",
    "print(target_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91830795-b43e-4d67-826b-2a489c2b54b9",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d710a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "def train_agent(\n",
    "        agent: DQNAgent,\n",
    "        total_timesteps: int,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        gamma: float,\n",
    "        eps_scheduler_kwargs: dict[str, int | str],\n",
    "        tau: float,\n",
    "        eps_scheduler: Callable,\n",
    "        learn_start: int,\n",
    "        train_freq: int, #4\n",
    "        target_freq: int,\n",
    "        optimizer_kwargs: Dict = {},\n",
    "        lr_scheduler_kwargs: Dict = {},\n",
    "        wandb_run=None\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Trains a DQN agent.\n",
    "    \n",
    "    Args\n",
    "    -----\n",
    "    agent: DQNAgent\n",
    "    total_timesteps: int\n",
    "        Total number of timesteps through which to step agent through environment.\n",
    "        Number of episodes is total_timesteps // episode_steps\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    gamma: float\n",
    "    eps_scheduler_kwargs: dict[str, int | str]\n",
    "        arguments for epsilon scheduling method\n",
    "    tau: float\n",
    "    eps_scheduler: Callable,\n",
    "        Function that calculates epsilon at each time step\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "        Optimizer for neural network. Adamw is recommended.\n",
    "    optimizer_kwargs: Dict,\n",
    "        Kwargs for chosen optimizer\n",
    "    learn_start: int\n",
    "        Time step at which updates to policy network and target network \n",
    "    train_freq: int, #4\n",
    "        Number of time steps between policy network updates  \n",
    "    target_freq: int\n",
    "        Number of time steps between target network updates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    agent.reset()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(agent.policy_net.parameters(), lr=lr, amsgrad=False, **optimizer_kwargs)\n",
    "\n",
    "    T_max = (total_timesteps - learn_start) // train_freq\n",
    "    lr_scheduler_kwargs = {'T_max': total_timesteps - learn_start, 'eta_min': 1e-6}\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **lr_scheduler_kwargs)\n",
    "    device = agent.device\n",
    "    loss_history = []\n",
    "\n",
    "    for t_i in range(total_timesteps):\n",
    "        # set epsilon according to scheduler\n",
    "        epsilon = eps_scheduler(t=t_i, **eps_scheduler_kwargs)\n",
    "        if wandb_run:\n",
    "            wandb_run.log({'epsilon': epsilon}, step=t_i)\n",
    "\n",
    "        # agent performs step in environment and sees next observation\n",
    "        reward, terminated = agent.play_step(epsilon)\n",
    "        \n",
    "        # train - use temporal difference between new obs and last obs to update Q-values\n",
    "        if t_i > learn_start and batch_size <= len(agent.replay_buffer) and (t_i % train_freq == 0):\n",
    "            # sample from experiences\n",
    "            obs, actions, rewards, next_obs, dones, _, next_action_masks = agent.replay_buffer.sample(batch_size)\n",
    "            \n",
    "            # convert to tensors\n",
    "            obs = torch.tensor(np.array(obs), device=device, dtype=torch.float32)\n",
    "            actions = torch.tensor(actions, device=device, dtype=torch.long).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, device=device, dtype=torch.float32)\n",
    "            dones = torch.tensor(dones, device=device, dtype=torch.float32)\n",
    "            next_obs = torch.tensor(np.array(next_obs), device=device, dtype=torch.float32)\n",
    "\n",
    "            # wandb_run.log({'batch_rewards': rewards}, step=t_i)\n",
    "            # get current q vals\n",
    "            q_vals = agent.policy_net(obs)\n",
    "            current_q = q_vals.gather(1, actions).squeeze()\n",
    "\n",
    "\n",
    "            with torch.no_grad():\n",
    "            # gets maximally valued action for each observation in batch\n",
    "                next_q = agent.target_net(next_obs)\n",
    "\n",
    "                # mask invalid actions\n",
    "                mask_tensor = torch.tensor(next_action_masks, device=device, dtype=torch.bool)\n",
    "                next_q[~mask_tensor] = -1e9# float('-inf')\n",
    "                # wandb_run.log({'masked next q': next_q},step=t_i)\n",
    "\n",
    "                max_next_q = next_q.max(dim=1)[0]\n",
    "                # print('(7) max_masked_next_q', max_next_q)\n",
    "\n",
    "                td_target = rewards + gamma * max_next_q * (1 - dones) # , dtype=torch.float32, device=device\n",
    "\n",
    "            \n",
    "            # print('td_target', td_target)\n",
    "            loss = F.mse_loss(current_q, td_target)\n",
    "            if wandb_run:\n",
    "                wandb_run.log({'loss': loss.item()}, step=t_i)\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "            # optimize w/ backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(agent.policy_net.parameters(), max_norm=1.)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # update target network\n",
    "            if t_i % target_freq == 0:\n",
    "                for target_param, param in zip(agent.target_net.parameters(), agent.policy_net.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
    "    if not wandb_run:\n",
    "        env.close()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6689def1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'gamma': .99,\n",
    "    'eps_scheduler_kwargs': {'eps_start': .9, 'eps_end': .01, 'decay_rate': 2500},\n",
    "    'tau': .005,\n",
    "    'lr': 1e-2,\n",
    "    'total_timesteps': 10000,\n",
    "    'learn_start': 100,\n",
    "    'train_freq': 4,\n",
    "    'target_freq': 100\n",
    "}\n",
    "\n",
    "agent = DQNAgent(\n",
    "    env=env,\n",
    "    replay_buffer=ReplayBuffer(capacity=100000, device=device),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d1c7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_agent(\n",
    "    agent=agent,\n",
    "    eps_scheduler=exponential_schedule,\n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8ea7180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.30187755823135376,\n",
       " 0.5405961275100708,\n",
       " 0.4162525534629822,\n",
       " 0.28009411692619324,\n",
       " 0.13261401653289795,\n",
       " 0.27716484665870667,\n",
       " 0.2601093053817749,\n",
       " 0.17107170820236206,\n",
       " 0.18371494114398956,\n",
       " 0.1810331493616104,\n",
       " 0.1217440813779831,\n",
       " 0.0805160254240036,\n",
       " 0.06756344437599182,\n",
       " 0.20459827780723572,\n",
       " 0.08619482815265656,\n",
       " 0.07847300171852112,\n",
       " 0.08964040875434875,\n",
       " 0.044586461037397385,\n",
       " 0.08055797219276428,\n",
       " 0.035620421171188354,\n",
       " 0.1260533481836319,\n",
       " 0.13375689089298248,\n",
       " 0.13009092211723328,\n",
       " 0.0899268165230751,\n",
       " 0.07609313726425171,\n",
       " 0.039733096957206726,\n",
       " 0.07817263901233673,\n",
       " 0.06633526086807251,\n",
       " 0.06700249016284943,\n",
       " 0.06594578921794891,\n",
       " 0.04735581576824188,\n",
       " 0.01765439286828041,\n",
       " 0.07133979350328445,\n",
       " 0.03443260118365288,\n",
       " 0.09252183139324188,\n",
       " 0.09758652746677399,\n",
       " 0.041248954832553864,\n",
       " 0.04351180046796799,\n",
       " 0.06375180184841156,\n",
       " 0.030360259115695953,\n",
       " 0.06580433994531631,\n",
       " 0.02792447805404663,\n",
       " 0.09657815843820572,\n",
       " 0.05624058470129967,\n",
       " 0.03310992196202278,\n",
       " 0.04173474758863449,\n",
       " 0.10225952416658401,\n",
       " 0.09855052083730698,\n",
       " 0.051091842353343964,\n",
       " 0.05839508771896362,\n",
       " 0.05113273859024048,\n",
       " 0.10793356597423553,\n",
       " 0.05797027051448822,\n",
       " 0.03848722577095032,\n",
       " 0.07281526923179626,\n",
       " 0.04564765840768814,\n",
       " 0.07649765908718109,\n",
       " 0.041308075189590454,\n",
       " 0.0484447106719017,\n",
       " 0.02385280653834343,\n",
       " 0.05908471718430519,\n",
       " 0.03596704453229904,\n",
       " 0.0979386419057846,\n",
       " 0.057230278849601746,\n",
       " 0.04123278707265854,\n",
       " 0.06980425119400024,\n",
       " 0.06439801305532455,\n",
       " 0.04685572534799576,\n",
       " 0.045500196516513824,\n",
       " 0.047688208520412445,\n",
       " 0.08247639238834381,\n",
       " 0.022190263494849205,\n",
       " 0.023940883576869965,\n",
       " 0.0577666349709034,\n",
       " 0.0639510303735733,\n",
       " 0.02552810125052929,\n",
       " 0.0408344641327858,\n",
       " 0.051848456263542175,\n",
       " 0.03823568671941757,\n",
       " 0.02975744567811489,\n",
       " 0.021763889119029045,\n",
       " 0.10116584599018097,\n",
       " 0.05843634158372879,\n",
       " 0.04345313087105751,\n",
       " 0.06273622810840607,\n",
       " 0.07375505566596985,\n",
       " 0.07388893514871597,\n",
       " 0.05352487415075302,\n",
       " 0.04036494717001915,\n",
       " 0.038821201771497726,\n",
       " 0.04619215428829193,\n",
       " 0.06171964854001999,\n",
       " 0.0584682822227478,\n",
       " 0.06903000175952911,\n",
       " 0.0477578341960907,\n",
       " 0.07084144651889801,\n",
       " 0.04342249780893326,\n",
       " 0.04079248756170273,\n",
       " 0.08066505193710327,\n",
       " 0.05608121305704117,\n",
       " 0.04524821415543556,\n",
       " 0.035380035638809204,\n",
       " 0.06857536733150482,\n",
       " 0.04896757751703262,\n",
       " 0.04025418683886528,\n",
       " 0.04747580736875534,\n",
       " 0.07978425920009613,\n",
       " 0.07906836271286011,\n",
       " 0.022789787501096725,\n",
       " 0.09060482680797577,\n",
       " 0.054360780864953995,\n",
       " 0.01845313236117363,\n",
       " 0.022539157420396805,\n",
       " 0.02674136683344841,\n",
       " 0.0619984045624733,\n",
       " 0.047735266387462616,\n",
       " 0.0706205666065216,\n",
       " 0.03739951550960541,\n",
       " 0.08355998992919922,\n",
       " 0.05016391724348068,\n",
       " 0.041063129901885986,\n",
       " 0.03608708828687668,\n",
       " 0.024761199951171875,\n",
       " 0.07609046995639801,\n",
       " 0.0628267228603363,\n",
       " 0.06665728986263275,\n",
       " 0.0618697814643383,\n",
       " 0.10380318015813828,\n",
       " 0.07667146623134613,\n",
       " 0.04549528285861015,\n",
       " 0.029154375195503235,\n",
       " 0.04929516091942787,\n",
       " 0.0893104150891304,\n",
       " 0.025033922865986824,\n",
       " 0.016460992395877838,\n",
       " 0.045485615730285645,\n",
       " 0.049189113080501556,\n",
       " 0.08609262853860855,\n",
       " 0.014390082098543644,\n",
       " 0.059274472296237946,\n",
       " 0.06102222204208374,\n",
       " 0.0485253781080246,\n",
       " 0.05499697104096413,\n",
       " 0.07124826312065125,\n",
       " 0.046244651079177856,\n",
       " 0.06385856121778488,\n",
       " 0.07502033561468124,\n",
       " 0.07900269329547882,\n",
       " 0.07602682709693909,\n",
       " 0.06046098843216896,\n",
       " 0.08187349140644073,\n",
       " 0.07082909345626831,\n",
       " 0.07123540341854095,\n",
       " 0.07168438285589218,\n",
       " 0.08370635658502579,\n",
       " 0.03286593407392502,\n",
       " 0.024167142808437347,\n",
       " 0.06486925482749939,\n",
       " 0.04398243501782417,\n",
       " 0.04814716428518295,\n",
       " 0.06265826523303986,\n",
       " 0.044104546308517456,\n",
       " 0.0686940848827362,\n",
       " 0.04652899503707886,\n",
       " 0.054848767817020416,\n",
       " 0.07017503678798676,\n",
       " 0.0708872452378273,\n",
       " 0.07115444540977478,\n",
       " 0.04140598326921463,\n",
       " 0.04213649779558182,\n",
       " 0.06696829199790955,\n",
       " 0.04539932683110237,\n",
       " 0.04455481469631195,\n",
       " 0.04012766480445862,\n",
       " 0.060623396188020706,\n",
       " 0.06829118728637695,\n",
       " 0.05543650686740875,\n",
       " 0.05480388551950455,\n",
       " 0.03855370730161667,\n",
       " 0.035099539905786514,\n",
       " 0.06293164938688278,\n",
       " 0.05444315820932388,\n",
       " 0.03020768240094185,\n",
       " 0.038768112659454346,\n",
       " 0.056143149733543396,\n",
       " 0.03822802007198334,\n",
       " 0.09080161154270172,\n",
       " 0.04723966121673584,\n",
       " 0.05997958779335022,\n",
       " 0.04033961892127991,\n",
       " 0.03948606550693512,\n",
       " 0.0844864547252655,\n",
       " 0.08408708870410919,\n",
       " 0.07158498466014862,\n",
       " 0.03315316140651703,\n",
       " 0.05101972073316574,\n",
       " 0.036892760545015335,\n",
       " 0.04622356593608856,\n",
       " 0.09263505041599274,\n",
       " 0.10256832838058472,\n",
       " 0.04869268089532852,\n",
       " 0.04896450415253639,\n",
       " 0.06168712303042412,\n",
       " 0.05330894514918327,\n",
       " 0.022766150534152985,\n",
       " 0.045057304203510284,\n",
       " 0.07622159272432327,\n",
       " 0.03355574980378151,\n",
       " 0.07836535573005676,\n",
       " 0.06634803861379623,\n",
       " 0.07433602213859558,\n",
       " 0.09012854099273682,\n",
       " 0.11723044514656067,\n",
       " 0.08701592683792114,\n",
       " 0.028934411704540253,\n",
       " 0.04581684619188309,\n",
       " 0.042754679918289185,\n",
       " 0.038202255964279175,\n",
       " 0.08792811632156372,\n",
       " 0.04312530905008316,\n",
       " 0.05369124561548233,\n",
       " 0.057121001183986664,\n",
       " 0.1050800234079361,\n",
       " 0.05272345617413521,\n",
       " 0.05565083771944046,\n",
       " 0.11842697858810425,\n",
       " 0.033860914409160614,\n",
       " 0.09486791491508484,\n",
       " 0.07364417612552643,\n",
       " 0.0990602895617485,\n",
       " 0.05435536056756973,\n",
       " 0.0725896954536438,\n",
       " 0.053649839013814926,\n",
       " 0.04689985513687134,\n",
       " 0.08342015743255615,\n",
       " 0.04587957635521889,\n",
       " 0.0416572242975235,\n",
       " 0.08717237412929535,\n",
       " 0.08468899875879288,\n",
       " 0.13985870778560638,\n",
       " 0.052306629717350006,\n",
       " 0.06244736537337303,\n",
       " 0.03843526914715767,\n",
       " 0.028804194182157516,\n",
       " 0.06425924599170685,\n",
       " 0.052052147686481476,\n",
       " 0.04312298074364662,\n",
       " 0.017667245119810104,\n",
       " 0.04443805664777756,\n",
       " 0.06136962026357651,\n",
       " 0.08856141567230225,\n",
       " 0.105447918176651,\n",
       " 0.05778571963310242,\n",
       " 0.07904879748821259,\n",
       " 0.06596456468105316,\n",
       " 0.04104328155517578,\n",
       " 0.07349260151386261,\n",
       " 0.039475101977586746,\n",
       " 0.10262000560760498,\n",
       " 0.07010306417942047,\n",
       " 0.05509414151310921,\n",
       " 0.04391172528266907,\n",
       " 0.09396416693925858,\n",
       " 0.03128333389759064,\n",
       " 0.05397316813468933,\n",
       " 0.08276356756687164,\n",
       " 0.0757618397474289,\n",
       " 0.04515978321433067,\n",
       " 0.07268740236759186,\n",
       " 0.05620972439646721,\n",
       " 0.06515789777040482,\n",
       " 0.035269852727651596,\n",
       " 0.0831318199634552,\n",
       " 0.029586857184767723,\n",
       " 0.08507136255502701,\n",
       " 0.0371570847928524,\n",
       " 0.04833764210343361,\n",
       " 0.11881375312805176,\n",
       " 0.03531055152416229,\n",
       " 0.08032897114753723,\n",
       " 0.04807478189468384,\n",
       " 0.08195167779922485,\n",
       " 0.07552601397037506,\n",
       " 0.09507544338703156,\n",
       " 0.13409146666526794,\n",
       " 0.05670412257313728,\n",
       " 0.12056300044059753,\n",
       " 0.04838497191667557,\n",
       " 0.040467433631420135,\n",
       " 0.041916534304618835,\n",
       " 0.07571721076965332,\n",
       " 0.09075586497783661,\n",
       " 0.0715777650475502,\n",
       " 0.0639914870262146,\n",
       " 0.04572213068604469,\n",
       " 0.03822635859251022,\n",
       " 0.04257001727819443,\n",
       " 0.051049768924713135,\n",
       " 0.05900520831346512,\n",
       " 0.06412754952907562,\n",
       " 0.03399081528186798,\n",
       " 0.04975701868534088,\n",
       " 0.03947674483060837,\n",
       " 0.07578793913125992,\n",
       " 0.051460012793540955,\n",
       " 0.07407709956169128,\n",
       " 0.06744886189699173,\n",
       " 0.04480155557394028,\n",
       " 0.05127082020044327,\n",
       " 0.025911003351211548,\n",
       " 0.04950551688671112,\n",
       " 0.0894470140337944,\n",
       " 0.10987597703933716,\n",
       " 0.06883519142866135,\n",
       " 0.09529353678226471,\n",
       " 0.011137889698147774,\n",
       " 0.03619624674320221,\n",
       " 0.0357392393052578,\n",
       " 0.051324859261512756,\n",
       " 0.04464912787079811,\n",
       " 0.06381073594093323,\n",
       " 0.026655513793230057,\n",
       " 0.04219178855419159,\n",
       " 0.08114905655384064,\n",
       " 0.04019639268517494,\n",
       " 0.06068435311317444,\n",
       " 0.11895815283060074,\n",
       " 0.06089106202125549,\n",
       " 0.11426965147256851,\n",
       " 0.020479951053857803,\n",
       " 0.026347124949097633,\n",
       " 0.037877701222896576,\n",
       " 0.053233563899993896,\n",
       " 0.01934037357568741,\n",
       " 0.06981657445430756,\n",
       " 0.08529538661241531,\n",
       " 0.08927202224731445,\n",
       " 0.06636486947536469,\n",
       " 0.06139270216226578,\n",
       " 0.054423727095127106,\n",
       " 0.06453344970941544,\n",
       " 0.025566574186086655,\n",
       " 0.04629157856106758,\n",
       " 0.06601785123348236,\n",
       " 0.036484912037849426,\n",
       " 0.04783257097005844,\n",
       " 0.034678246825933456,\n",
       " 0.10850630700588226,\n",
       " 0.08464200794696808,\n",
       " 0.06443414092063904,\n",
       " 0.035467855632305145,\n",
       " 0.07029843330383301,\n",
       " 0.09924691915512085,\n",
       " 0.09245378524065018,\n",
       " 0.03686468303203583,\n",
       " 0.07319375872612,\n",
       " 0.11597351729869843,\n",
       " 0.05728771910071373,\n",
       " 0.054132089018821716,\n",
       " 0.04010111093521118,\n",
       " 0.08332552015781403,\n",
       " 0.05507514625787735,\n",
       " 0.07248325645923615,\n",
       " 0.05755190551280975,\n",
       " 0.09247921407222748,\n",
       " 0.06218032166361809,\n",
       " 0.05598884075880051,\n",
       " 0.14486196637153625,\n",
       " 0.031024085357785225,\n",
       " 0.07934782654047012,\n",
       " 0.1081637293100357,\n",
       " 0.05842242017388344,\n",
       " 0.06736744940280914,\n",
       " 0.0662199854850769,\n",
       " 0.054689113050699234,\n",
       " 0.054075002670288086,\n",
       " 0.06560321897268295,\n",
       " 0.039635878056287766,\n",
       " 0.03825350105762482,\n",
       " 0.08417275547981262,\n",
       " 0.03440016508102417,\n",
       " 0.053445279598236084,\n",
       " 0.03583325073122978,\n",
       " 0.08140154182910919,\n",
       " 0.03231266885995865,\n",
       " 0.07913344353437424,\n",
       " 0.03928464278578758,\n",
       " 0.04158691316843033,\n",
       " 0.06023173779249191,\n",
       " 0.04599587619304657,\n",
       " 0.02805539220571518,\n",
       " 0.06415527313947678,\n",
       " 0.040467269718647,\n",
       " 0.026344284415245056,\n",
       " 0.021941039711236954,\n",
       " 0.04736790060997009,\n",
       " 0.11732640862464905,\n",
       " 0.06441764533519745,\n",
       " 0.08438736945390701,\n",
       " 0.1037699431180954,\n",
       " 0.06307067722082138,\n",
       " 0.08000113070011139,\n",
       " 0.03213915228843689,\n",
       " 0.06409972161054611,\n",
       " 0.04981112480163574,\n",
       " 0.08339385688304901,\n",
       " 0.06939330697059631,\n",
       " 0.0632595345377922,\n",
       " 0.04274258017539978,\n",
       " 0.04962771013379097,\n",
       " 0.06081017851829529,\n",
       " 0.06466862559318542,\n",
       " 0.05940801650285721,\n",
       " 0.1598871499300003,\n",
       " 0.08216337859630585,\n",
       " 0.06576631218194962,\n",
       " 0.04394249990582466,\n",
       " 0.07914458960294724,\n",
       " 0.04943910986185074,\n",
       " 0.056967709213495255,\n",
       " 0.06338761746883392,\n",
       " 0.01917221024632454,\n",
       " 0.03670445457100868,\n",
       " 0.05824841558933258,\n",
       " 0.04912467300891876,\n",
       " 0.048113636672496796,\n",
       " 0.07028555870056152,\n",
       " 0.05766560509800911,\n",
       " 0.04595264419913292,\n",
       " 0.016605427488684654,\n",
       " 0.05681803077459335,\n",
       " 0.06741075217723846,\n",
       " 0.04281085357069969,\n",
       " 0.07930144667625427,\n",
       " 0.05328343063592911,\n",
       " 0.040701974183321,\n",
       " 0.04111207649111748,\n",
       " 0.030091501772403717,\n",
       " 0.04485215246677399,\n",
       " 0.055578965693712234,\n",
       " 0.054130181670188904,\n",
       " 0.029973851516842842,\n",
       " 0.09891840815544128,\n",
       " 0.04532715678215027,\n",
       " 0.07866035401821136,\n",
       " 0.04660705476999283,\n",
       " 0.038266345858573914,\n",
       " 0.10024896264076233,\n",
       " 0.058512911200523376,\n",
       " 0.06315290927886963,\n",
       " 0.042399268597364426,\n",
       " 0.06137772649526596,\n",
       " 0.11103063821792603,\n",
       " 0.05469678342342377,\n",
       " 0.052204735577106476,\n",
       " 0.06064870208501816,\n",
       " 0.049870241433382034,\n",
       " 0.08338867872953415,\n",
       " 0.08900552988052368,\n",
       " 0.0595557801425457,\n",
       " 0.0484749898314476,\n",
       " 0.07999110221862793,\n",
       " 0.05887584388256073,\n",
       " 0.0367436408996582,\n",
       " 0.05382657051086426,\n",
       " 0.056129373610019684,\n",
       " 0.08722219616174698,\n",
       " 0.05043065920472145,\n",
       " 0.09763193875551224,\n",
       " 0.04050173610448837,\n",
       " 0.040732406079769135,\n",
       " 0.042332060635089874,\n",
       " 0.05305567383766174,\n",
       " 0.03512551635503769,\n",
       " 0.0674513578414917,\n",
       " 0.06820553541183472,\n",
       " 0.05292307212948799,\n",
       " 0.05880136787891388,\n",
       " 0.04544573277235031,\n",
       " 0.0285017192363739,\n",
       " 0.07415599375963211,\n",
       " 0.045764703303575516,\n",
       " 0.03781116381287575,\n",
       " 0.03703291714191437,\n",
       " 0.04061081260442734,\n",
       " 0.07313962280750275,\n",
       " 0.0909094586968422,\n",
       " 0.06227009743452072,\n",
       " 0.04082378000020981,\n",
       " 0.06044434383511543,\n",
       " 0.045457080006599426,\n",
       " 0.029771752655506134,\n",
       " 0.06501063704490662,\n",
       " 0.09244415163993835,\n",
       " 0.05438223481178284,\n",
       " 0.05406267195940018,\n",
       " 0.044514186680316925,\n",
       " 0.10066454112529755,\n",
       " 0.056194793432950974,\n",
       " 0.058735474944114685,\n",
       " 0.04351631551980972,\n",
       " 0.05548904463648796,\n",
       " 0.031443316489458084,\n",
       " 0.0730394572019577,\n",
       " 0.045477740466594696,\n",
       " 0.04727911949157715,\n",
       " 0.07621895521879196,\n",
       " 0.028673429042100906,\n",
       " 0.05840623751282692,\n",
       " 0.05647403001785278,\n",
       " 0.062492527067661285,\n",
       " 0.05276712775230408,\n",
       " 0.04232101887464523,\n",
       " 0.05755847692489624,\n",
       " 0.039111509919166565,\n",
       " 0.021357011049985886,\n",
       " 0.06311476230621338,\n",
       " 0.04237259924411774,\n",
       " 0.05728689208626747,\n",
       " 0.06390704214572906,\n",
       " 0.07442105561494827,\n",
       " 0.06742995232343674,\n",
       " 0.07303199917078018,\n",
       " 0.12035350501537323,\n",
       " 0.04544123262166977,\n",
       " 0.07673324644565582,\n",
       " 0.03869765251874924,\n",
       " 0.04418434575200081,\n",
       " 0.03100825473666191,\n",
       " 0.05368742719292641,\n",
       " 0.07977057248353958,\n",
       " 0.02710958570241928,\n",
       " 0.08110041916370392,\n",
       " 0.08157189935445786,\n",
       " 0.11341546475887299,\n",
       " 0.06625204533338547,\n",
       " 0.05330375209450722,\n",
       " 0.04195059835910797,\n",
       " 0.11314530670642853,\n",
       " 0.05648455023765564,\n",
       " 0.041339606046676636,\n",
       " 0.04923665523529053,\n",
       " 0.06739788502454758,\n",
       " 0.07512041181325912,\n",
       " 0.046134889125823975,\n",
       " 0.048763833940029144,\n",
       " 0.06845556944608688,\n",
       " 0.10360080003738403,\n",
       " 0.05612478777766228,\n",
       " 0.07053374499082565,\n",
       " 0.0710797980427742,\n",
       " 0.03399531543254852,\n",
       " 0.06306657195091248,\n",
       " 0.10154318064451218,\n",
       " 0.06549672782421112,\n",
       " 0.049536071717739105,\n",
       " 0.10361146926879883,\n",
       " 0.08844452351331711,\n",
       " 0.07386733591556549,\n",
       " 0.06903199851512909,\n",
       " 0.027286764234304428,\n",
       " 0.08682925999164581,\n",
       " 0.09638956934213638,\n",
       " 0.04162346571683884,\n",
       " 0.0908820629119873,\n",
       " 0.056615158915519714,\n",
       " 0.04106246680021286,\n",
       " 0.060801051557064056,\n",
       " 0.07462483644485474,\n",
       " 0.03926190361380577,\n",
       " 0.06704775243997574,\n",
       " 0.047851309180259705,\n",
       " 0.10820059478282928,\n",
       " 0.051463402807712555,\n",
       " 0.04374868795275688,\n",
       " 0.061404190957546234,\n",
       " 0.06867291033267975,\n",
       " 0.04125908762216568,\n",
       " 0.10365721583366394,\n",
       " 0.06490454822778702,\n",
       " 0.11284974217414856,\n",
       " 0.12147118896245956,\n",
       " 0.07186107337474823,\n",
       " 0.07461782544851303,\n",
       " 0.04336268827319145,\n",
       " 0.0643344521522522,\n",
       " 0.03755604103207588,\n",
       " 0.056987032294273376,\n",
       " 0.040585100650787354,\n",
       " 0.06968903541564941,\n",
       " 0.057081207633018494,\n",
       " 0.1643511950969696,\n",
       " 0.05604599788784981,\n",
       " 0.06625399738550186,\n",
       " 0.057564735412597656,\n",
       " 0.17555783689022064,\n",
       " 0.10786072909832001,\n",
       " 0.05850810185074806,\n",
       " 0.06401591002941132,\n",
       " 0.06877107918262482,\n",
       " 0.06902299076318741,\n",
       " 0.08396854996681213,\n",
       " 0.11599339544773102,\n",
       " 0.07780097424983978,\n",
       " 0.06499485671520233,\n",
       " 0.05924365669488907,\n",
       " 0.09782068431377411,\n",
       " 0.06645072996616364,\n",
       " 0.05992691591382027,\n",
       " 0.0621732696890831,\n",
       " 0.11661596596240997,\n",
       " 0.09751494228839874,\n",
       " 0.060879021883010864,\n",
       " 0.043036311864852905,\n",
       " 0.03724878281354904,\n",
       " 0.08197454363107681,\n",
       " 0.046495161950588226,\n",
       " 0.0355226993560791,\n",
       " 0.11261184513568878,\n",
       " 0.0899914801120758,\n",
       " 0.12176574766635895,\n",
       " 0.12155792117118835,\n",
       " 0.08601471781730652,\n",
       " 0.051832299679517746,\n",
       " 0.0983361154794693,\n",
       " 0.11739031970500946,\n",
       " 0.07175526767969131,\n",
       " 0.11047464609146118,\n",
       " 0.04476410895586014,\n",
       " 0.040182940661907196,\n",
       " 0.08021382242441177,\n",
       " 0.05236620828509331,\n",
       " 0.05224250257015228,\n",
       " 0.05847182124853134,\n",
       " 0.08718633651733398,\n",
       " 0.0707530528306961,\n",
       " 0.06832420825958252,\n",
       " 0.07496366649866104,\n",
       " 0.06912445276975632,\n",
       " 0.04445217549800873,\n",
       " 0.05829162895679474,\n",
       " 0.06035745516419411,\n",
       " 0.06811265647411346,\n",
       " 0.10816390812397003,\n",
       " 0.08007719367742538,\n",
       " 0.08835145086050034,\n",
       " 0.06374897062778473,\n",
       " 0.07773900032043457,\n",
       " 0.07896462082862854,\n",
       " 0.06689444184303284,\n",
       " 0.051956478506326675,\n",
       " 0.08904241025447845,\n",
       " 0.06901614367961884,\n",
       " 0.03945224732160568,\n",
       " 0.06313685327768326,\n",
       " 0.033604055643081665,\n",
       " 0.055244747549295425,\n",
       " 0.05299314856529236,\n",
       " 0.036140792071819305,\n",
       " 0.04039069637656212,\n",
       " 0.05773613601922989,\n",
       " 0.05802781507372856,\n",
       " 0.07644200325012207,\n",
       " 0.054174840450286865,\n",
       " 0.10237836837768555,\n",
       " 0.05295494943857193,\n",
       " 0.05996490269899368,\n",
       " 0.07246074080467224,\n",
       " 0.049190081655979156,\n",
       " 0.06617498397827148,\n",
       " 0.07055610418319702,\n",
       " 0.032484184950590134,\n",
       " 0.04742415249347687,\n",
       " 0.05257350206375122,\n",
       " 0.06354944407939911,\n",
       " 0.06601792573928833,\n",
       " 0.05295327305793762,\n",
       " 0.040909480303525925,\n",
       " 0.05981200188398361,\n",
       " 0.0775732547044754,\n",
       " 0.032434478402137756,\n",
       " 0.07335027307271957,\n",
       " 0.045366350561380386,\n",
       " 0.054330646991729736,\n",
       " 0.08916546404361725,\n",
       " 0.04610008746385574,\n",
       " 0.05499709025025368,\n",
       " 0.060323867946863174,\n",
       " 0.0964905172586441,\n",
       " 0.060016993433237076,\n",
       " 0.07556461542844772,\n",
       " 0.029482081532478333,\n",
       " 0.10560914129018784,\n",
       " 0.027967145666480064,\n",
       " 0.054226189851760864,\n",
       " 0.0623723566532135,\n",
       " 0.035861626267433167,\n",
       " 0.0358600914478302,\n",
       " 0.06677711009979248,\n",
       " 0.02892666682600975,\n",
       " 0.07117699086666107,\n",
       " 0.05135654658079147,\n",
       " 0.06420580297708511,\n",
       " 0.0687849298119545,\n",
       " 0.03394840285181999,\n",
       " 0.06982282549142838,\n",
       " 0.057611964643001556,\n",
       " 0.046008698642253876,\n",
       " 0.07148361206054688,\n",
       " 0.0493667796254158,\n",
       " 0.06444433331489563,\n",
       " 0.04965013265609741,\n",
       " 0.10652181506156921,\n",
       " 0.061406925320625305,\n",
       " 0.04895760864019394,\n",
       " 0.03291410207748413,\n",
       " 0.05612320080399513,\n",
       " 0.07315679639577866,\n",
       " 0.04067620635032654,\n",
       " 0.08714260160923004,\n",
       " 0.07193591445684433,\n",
       " 0.11462356150150299,\n",
       " 0.05966416001319885,\n",
       " 0.049847546964883804,\n",
       " 0.037054941058158875,\n",
       " 0.10020563006401062,\n",
       " 0.06786368787288666,\n",
       " 0.05489349365234375,\n",
       " 0.11492009460926056,\n",
       " 0.055101241916418076,\n",
       " 0.0528937466442585,\n",
       " 0.08740696310997009,\n",
       " 0.09210410714149475,\n",
       " 0.07131218910217285,\n",
       " 0.06342745572328568,\n",
       " 0.07915827631950378,\n",
       " 0.08965648710727692,\n",
       " 0.15130189061164856,\n",
       " 0.03446482494473457,\n",
       " 0.055078595876693726,\n",
       " 0.0387393981218338,\n",
       " 0.05692543089389801,\n",
       " 0.0557551383972168,\n",
       " 0.06885990500450134,\n",
       " 0.06927689164876938,\n",
       " 0.0622146837413311,\n",
       " 0.033592697232961655,\n",
       " 0.08324018120765686,\n",
       " 0.0888916403055191,\n",
       " 0.08851839601993561,\n",
       " 0.04039643704891205,\n",
       " 0.06718765199184418,\n",
       " 0.09957829117774963,\n",
       " 0.0453852079808712,\n",
       " 0.036185480654239655,\n",
       " 0.05714091658592224,\n",
       " 0.06844636797904968,\n",
       " 0.05209597200155258,\n",
       " 0.03836730867624283,\n",
       " 0.0282965786755085,\n",
       " 0.04885612428188324,\n",
       " 0.05965640768408775,\n",
       " 0.055984016507864,\n",
       " 0.0500212088227272,\n",
       " 0.06206899508833885,\n",
       " 0.06562594324350357,\n",
       " 0.045029304921627045,\n",
       " 0.061066627502441406,\n",
       " 0.07329809665679932,\n",
       " 0.06300489604473114,\n",
       " 0.032087381929159164,\n",
       " 0.04184846580028534,\n",
       " 0.023108765482902527,\n",
       " 0.09327896684408188,\n",
       " 0.07076121866703033,\n",
       " 0.04563699662685394,\n",
       " 0.07472938299179077,\n",
       " 0.06473924964666367,\n",
       " 0.05810261517763138,\n",
       " 0.06391187757253647,\n",
       " 0.030856790021061897,\n",
       " 0.0374099425971508,\n",
       " 0.06568965315818787,\n",
       " 0.07395808398723602,\n",
       " 0.0755203515291214,\n",
       " 0.05516643077135086,\n",
       " 0.06899535655975342,\n",
       " 0.09758730977773666,\n",
       " 0.060373082756996155,\n",
       " 0.07046666741371155,\n",
       " 0.04123368114233017,\n",
       " 0.055195778608322144,\n",
       " 0.10636086016893387,\n",
       " 0.058758582919836044,\n",
       " 0.06373682618141174,\n",
       " 0.07687729597091675,\n",
       " 0.06455269455909729,\n",
       " 0.08056314289569855,\n",
       " 0.0747586339712143,\n",
       " 0.04336046054959297,\n",
       " 0.07724471390247345,\n",
       " 0.05345214903354645,\n",
       " 0.05285639315843582,\n",
       " 0.0657990425825119,\n",
       " 0.05570143461227417,\n",
       " 0.08062911778688431,\n",
       " 0.03127561882138252,\n",
       " 0.10065857321023941,\n",
       " 0.06751362979412079,\n",
       " 0.09119999408721924,\n",
       " 0.06084573268890381,\n",
       " 0.09272545576095581,\n",
       " 0.04382192716002464,\n",
       " 0.06620748341083527,\n",
       " 0.06864103674888611,\n",
       " 0.05074910447001457,\n",
       " 0.03347323089838028,\n",
       " 0.060854263603687286,\n",
       " 0.07112018764019012,\n",
       " 0.061905570328235626,\n",
       " 0.05902213603258133,\n",
       " 0.050898537039756775,\n",
       " 0.06022682413458824,\n",
       " 0.13948997855186462,\n",
       " 0.07083509117364883,\n",
       " 0.056392159312963486,\n",
       " 0.07504646480083466,\n",
       " 0.03838113322854042,\n",
       " 0.04768625646829605,\n",
       " 0.049583375453948975,\n",
       " 0.06215518340468407,\n",
       " 0.03679888695478439,\n",
       " 0.027889952063560486,\n",
       " 0.036568693816661835,\n",
       " 0.05737050622701645,\n",
       " 0.06855492293834686,\n",
       " 0.07404148578643799,\n",
       " 0.045531414449214935,\n",
       " 0.044955648481845856,\n",
       " 0.05612017586827278,\n",
       " 0.047358788549900055,\n",
       " 0.02601059339940548,\n",
       " 0.048061806708574295,\n",
       " 0.048050656914711,\n",
       " 0.03786493465304375,\n",
       " 0.041193265467882156,\n",
       " 0.08422716706991196,\n",
       " 0.07698709517717361,\n",
       " 0.06147383153438568,\n",
       " 0.05058280751109123,\n",
       " 0.06620626896619797,\n",
       " 0.04731975123286247,\n",
       " 0.048636797815561295,\n",
       " 0.06182540953159332,\n",
       " 0.06972967833280563,\n",
       " 0.10740683972835541,\n",
       " 0.05702665448188782,\n",
       " 0.056070342659950256,\n",
       " 0.0530938059091568,\n",
       " 0.029407769441604614,\n",
       " 0.04255261272192001,\n",
       " 0.03294483199715614,\n",
       " 0.03733639046549797,\n",
       " 0.05574561655521393,\n",
       " 0.06292571872472763,\n",
       " 0.07561017572879791,\n",
       " 0.023730777204036713,\n",
       " 0.04440424218773842,\n",
       " 0.07622657716274261,\n",
       " 0.04968086630105972,\n",
       " 0.05449236184358597,\n",
       " 0.029005147516727448,\n",
       " 0.06998339295387268,\n",
       " 0.04360534995794296,\n",
       " 0.04113350808620453,\n",
       " 0.02919185161590576,\n",
       " 0.06199314817786217,\n",
       " 0.05098707973957062,\n",
       " 0.06794186681509018,\n",
       " 0.04956483840942383,\n",
       " 0.056889090687036514,\n",
       " 0.07238872349262238,\n",
       " 0.030744757503271103,\n",
       " 0.0335964635014534,\n",
       " 0.06242462247610092,\n",
       " 0.047775089740753174,\n",
       " 0.07821616530418396,\n",
       " 0.07172924280166626,\n",
       " 0.024885067716240883,\n",
       " 0.05798513814806938,\n",
       " 0.05818413943052292,\n",
       " 0.0954432263970375,\n",
       " 0.07831964641809464,\n",
       " 0.06781129539012909,\n",
       " 0.06537049263715744,\n",
       " 0.04186505079269409,\n",
       " 0.03127151355147362,\n",
       " 0.02616274729371071,\n",
       " 0.028788911178708076,\n",
       " 0.04155264049768448,\n",
       " 0.04597592353820801,\n",
       " 0.04023854807019234,\n",
       " 0.039829522371292114,\n",
       " 0.03803294897079468,\n",
       " 0.06638649106025696,\n",
       " 0.04507182165980339,\n",
       " 0.06371216475963593,\n",
       " 0.04371844232082367,\n",
       " 0.04402858391404152,\n",
       " 0.027135176584124565,\n",
       " 0.036736615002155304,\n",
       " 0.037165265530347824,\n",
       " 0.03829734027385712,\n",
       " 0.060346946120262146,\n",
       " 0.028800904750823975,\n",
       " 0.07627969235181808,\n",
       " 0.07510742545127869,\n",
       " 0.03836045414209366,\n",
       " 0.05236773192882538,\n",
       " 0.052827756851911545,\n",
       " 0.039604708552360535,\n",
       " 0.06135956197977066,\n",
       " 0.03844672814011574,\n",
       " 0.0226284209638834,\n",
       " 0.04578826576471329,\n",
       " 0.03182496130466461,\n",
       " 0.029698260128498077,\n",
       " 0.06639285385608673,\n",
       " 0.04627952724695206,\n",
       " 0.07361805438995361,\n",
       " 0.04838750511407852,\n",
       " 0.07265360653400421,\n",
       " 0.03485170751810074,\n",
       " 0.05447729676961899,\n",
       " 0.062069956213235855,\n",
       " 0.050155989825725555,\n",
       " 0.03696300834417343,\n",
       " 0.031159168109297752,\n",
       " 0.02652246505022049,\n",
       " 0.03526875004172325,\n",
       " 0.06184766814112663,\n",
       " 0.04419457167387009,\n",
       " 0.05874328315258026,\n",
       " 0.03718700259923935,\n",
       " 0.03615616261959076,\n",
       " 0.06542201340198517,\n",
       " 0.07530545443296432,\n",
       " 0.05038253217935562,\n",
       " 0.03658341243863106,\n",
       " 0.04538198187947273,\n",
       " 0.05049506574869156,\n",
       " 0.06550288200378418,\n",
       " 0.06447065621614456,\n",
       " 0.025521596893668175,\n",
       " 0.05052321404218674,\n",
       " 0.07169095426797867,\n",
       " 0.037048839032649994,\n",
       " 0.09532710909843445,\n",
       " 0.04944060742855072,\n",
       " 0.06335951387882233,\n",
       " 0.05360933020710945,\n",
       " 0.07982909679412842,\n",
       " 0.05831485241651535,\n",
       " 0.08913938701152802,\n",
       " 0.08045139908790588,\n",
       " 0.05739155039191246,\n",
       " 0.04206188768148422,\n",
       " 0.059804048389196396,\n",
       " 0.05470338463783264,\n",
       " 0.06292510032653809,\n",
       " 0.08085908740758896,\n",
       " 0.05880425125360489,\n",
       " 0.03949500992894173,\n",
       " 0.06170070543885231,\n",
       " 0.030251599848270416,\n",
       " 0.07119821012020111,\n",
       " 0.04642960801720619,\n",
       " 0.041785381734371185,\n",
       " 0.06100524961948395,\n",
       " 0.04535949230194092,\n",
       " 0.04380059614777565,\n",
       " 0.024670038372278214,\n",
       " 0.03729978948831558,\n",
       " 0.03667888417840004,\n",
       " 0.02524593658745289,\n",
       " 0.04299605265259743,\n",
       " 0.024602286517620087,\n",
       " 0.025624841451644897,\n",
       " 0.06042386591434479,\n",
       " 0.03657466918230057,\n",
       " 0.06942589581012726,\n",
       " 0.03641141206026077,\n",
       " 0.02352631278336048,\n",
       " 0.03262648731470108,\n",
       " 0.03730877488851547,\n",
       " 0.0378599613904953,\n",
       " 0.06391929090023041,\n",
       " 0.01608644798398018,\n",
       " 0.047542110085487366,\n",
       " 0.03311774507164955,\n",
       " ...]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "55c210f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2203fb6a90>]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT5hJREFUeJzt3XlcVOX+B/DPsCvCpKIsiUjmlpglpIKhmUqaLbbcLPuZ3ZsVpRVR3TJbzG7pbTHtlpbZZmVaqW2airnhrghKbrkhiCCCCAiyzZzfHzjjmZkzM+cMM5yB+bxfL17JcM6ZZw4T5zPPeZ7voxEEQQARERGRSrzUbgARERF5NoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVT5qN0AOvV6P06dPIygoCBqNRu3mEBERkQyCIKCiogIRERHw8rLe/9Eswsjp06cRGRmpdjOIiIjIAXl5eejUqZPVnzeLMBIUFASg4cUEBwer3BoiIiKSo7y8HJGRkcbruDXNIowYbs0EBwczjBARETUz9oZYcAArERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhUxTBCREREqmIYISIiIlV5dBgpu1iHTzYeQ/75i2o3hYiIyGN5dBh5eVk2Zv5xCPfM3ap2U4iIiDyWR4eR9CNnAQCF5dUqt4SIiMhzeXQYISIiIvUxjBAREZGqGEaIiIhIVR4dRjQajdpNICIi8ngeHUaIiIhIfQwjREREpCqPDiO8S0NERKQ+jw4jREREpD6GESIiIlIVwwgRERGpyqPDCIeMEBERqc+jwwgRERGpj2GEiIiIVMUwQkRERKry6DDCcvBERETq8+gwQkREROpjGCEiIiJVMYwQERGRqhhGiIiISFUeHUY4fJWIiEh9DoWRuXPnIjo6GgEBAYiNjUV6errVbTds2ACNRmPxdejQIYcbTURERC2H4jCyZMkSpKSkYOrUqcjMzERiYiJGjRqF3Nxcm/sdPnwYBQUFxq9u3bo53GgiIiJqORSHkVmzZuGRRx7BxIkT0atXL8yePRuRkZGYN2+ezf06duyIsLAw45e3t7fDjSYiIqKWQ1EYqa2tRUZGBpKSkkweT0pKwtatW23ue/311yM8PBzDhg3D+vXrbW5bU1OD8vJyky9XYM0zIiIi9SkKI8XFxdDpdAgNDTV5PDQ0FIWFhZL7hIeHY/78+Vi6dCmWLVuGHj16YNiwYdi0aZPV55kxYwa0Wq3xKzIyUkkziYiIqBnxcWQn8zLqgiBYLa3eo0cP9OjRw/h9fHw88vLy8N5772Hw4MGS+0yZMgWpqanG78vLyxlIiIiIWihFPSMhISHw9va26AUpKiqy6C2xZeDAgThy5IjVn/v7+yM4ONjkyzV4n4aIiEhtisKIn58fYmNjkZaWZvJ4WloaEhISZB8nMzMT4eHhSp6aiIiIWijFt2lSU1Mxfvx4xMXFIT4+HvPnz0dubi6Sk5MBNNxiyc/Px8KFCwEAs2fPRpcuXdC7d2/U1tbi22+/xdKlS7F06VLnvhIiIiJqlhSHkbFjx6KkpATTp09HQUEBYmJisHLlSkRFRQEACgoKTGqO1NbW4vnnn0d+fj5atWqF3r17Y8WKFbj11lud9yqIiIio2dIIgiCo3Qh7ysvLodVqUVZW5tTxI3H/WYviCzUAgJyZo512XCIiIpJ//fbotWmIiIhIfR4dRlj0jIiISH0eHUaIiIhIfQwjREREpCqPDiO8S0NERKQ+jw4jREREpD6GESIiIlIVwwgRERGpimGEiIiIVMUwQkRERKry6DDComdERETq8+gwQkREROrz6DCiYaURIiIi1Xl0GCEiIiL1MYwQERGRqhhGiIiISFUMI0RERKQqjw4jnNpLRESkPo8OI0RERKQ+hhEiIiJSFcMIERERqcqjwwiHjBAREanPo8MIERERqY9hhIiIiFTFMEJERESqYhghIiIiVXl0GNGw6hkREZHqPDqMEBERkfoYRoiIiEhVDCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhU5dFhhDN7iYiI1OfRYYSIiIjUxzBCREREqmIYISIiIlUxjBAREZGqGEaIiIhIVR4dRjibhoiISH0eHUaIiIhIfQwjREREpCqPDiMa8D4NERGR2jw6jBAREZH6GEaIiIhIVQwjREREpCqPDiOc2ktERKQ+jw4jREREpD6GESIiIlIVwwgRERGpyqPDCIeMEBERqc+hMDJ37lxER0cjICAAsbGxSE9Pl7Xfli1b4OPjg+uuu86RpyUiIqIWSHEYWbJkCVJSUjB16lRkZmYiMTERo0aNQm5urs39ysrK8NBDD2HYsGEON5aIiIhaHsVhZNasWXjkkUcwceJE9OrVC7Nnz0ZkZCTmzZtnc7/HH38c48aNQ3x8vMONJSIiopZHURipra1FRkYGkpKSTB5PSkrC1q1bre735Zdf4tixY3j99ddlPU9NTQ3Ky8tNvoiIiKhlUhRGiouLodPpEBoaavJ4aGgoCgsLJfc5cuQIXnrpJXz33Xfw8fGR9TwzZsyAVqs1fkVGRipppmwaVj0jIiJSnUMDWM0v4oIgSF7YdTodxo0bhzfeeAPdu3eXffwpU6agrKzM+JWXl+dIM4mIiKgZkNdVcUlISAi8vb0tekGKiooseksAoKKiArt370ZmZiYmT54MANDr9RAEAT4+PlizZg1uvvlmi/38/f3h7++vpGlERETUTCnqGfHz80NsbCzS0tJMHk9LS0NCQoLF9sHBwcjOzkZWVpbxKzk5GT169EBWVhYGDBjQuNYTERFRs6eoZwQAUlNTMX78eMTFxSE+Ph7z589Hbm4ukpOTATTcYsnPz8fChQvh5eWFmJgYk/07duyIgIAAi8eJiIjIMykOI2PHjkVJSQmmT5+OgoICxMTEYOXKlYiKigIAFBQU2K05QkRERGSgEQRBULsR9pSXl0Or1aKsrAzBwcFOO+7N723A8eJKAEDOzNFOOy4RERHJv3579No0XJyGiIhIfZ4dRoiIiEh1DCNERESkKoYRIiIiUhXDCBEREamKYYSIiIhU5dFhhJNpiIiI1OfRYYSIiIjUxzBCREREqvLoMKLR8EYNERGR2jw6jBAREZH6GEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpyqPDCOfSEBERqc+jwwgRERGpj2GEiIiIVMUwQkRERKry6DDCAqxERETq8+gwQkREROpjGCEiIiJVeXQY0XByLxERkeo8OowQERGR+hhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqcqjwwiLnhEREanPo8MIERERqY9hhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhVHh1GNJzbS0REpDqPDiNERESkPoYRIiIiUpVHhxHepCEiIlKfR4cRIiIiUh/DCBEREamKYYSIiIhUxTBCREREqmIYISIiIlV5dBhhzTMiIiL1eXQYISIiIvUxjBAREZGqGEaIiIhIVR4dRjhmhIiISH0eHUaIiIhIfQwjREREpCqHwsjcuXMRHR2NgIAAxMbGIj093eq2mzdvxqBBg9C+fXu0atUKPXv2xAcffOBwg51Jw6XyiIiIVOejdIclS5YgJSUFc+fOxaBBg/Dpp59i1KhROHDgADp37myxfWBgICZPnoxrr70WgYGB2Lx5Mx5//HEEBgbisccec8qLICIiouZLIwiCoGSHAQMGoF+/fpg3b57xsV69emHMmDGYMWOGrGPcfffdCAwMxDfffCNr+/Lycmi1WpSVlSE4OFhJc226/X+bkZ1fBgDImTnaacclIiIi+ddvRbdpamtrkZGRgaSkJJPHk5KSsHXrVlnHyMzMxNatWzFkyBCr29TU1KC8vNzki4iIiFomRWGkuLgYOp0OoaGhJo+HhoaisLDQ5r6dOnWCv78/4uLiMGnSJEycONHqtjNmzIBWqzV+RUZGKmmmbM/f0sMlxyUiIiL5HBrAqjEr0CEIgsVj5tLT07F792588sknmD17Nr7//nur206ZMgVlZWXGr7y8PEeaaVfndq0BAEH+iofOEBERkZMougqHhITA29vbohekqKjIorfEXHR0NACgT58+OHPmDKZNm4YHHnhAclt/f3/4+/sraZpDDPFJ0aAZIiIicipFPSN+fn6IjY1FWlqayeNpaWlISEiQfRxBEFBTU6PkqV2CFViJiIjUp/j+RGpqKsaPH4+4uDjEx8dj/vz5yM3NRXJyMoCGWyz5+flYuHAhAODjjz9G586d0bNnTwANdUfee+89PPXUU058GY2jcEIREREROZHiMDJ27FiUlJRg+vTpKCgoQExMDFauXImoqCgAQEFBAXJzc43b6/V6TJkyBSdOnICPjw+6du2KmTNn4vHHH3feq3AQi54RERGpT3GdETW4qs5IbkkVBr+7Hq39vHFg+kinHZeIiIhcVGekpeGYESIiIvV5dBgxcP++ISIiopaLYYSIiIhUxTACQGClESIiItV4dBjhmBEiIiL1eXQYMeCYESIiIvV4dBgxrKdTU69HvU6vcmuIiIg8k2eHEdG/v9qao1YziIiIPJpHhxGxLUeL1W4CERGRR/LoMCIewFqv58ARIiIiNXh0GBHTcxQrERGRKjw6jIgXyqvXMYwQERGpwaPDiJiOt2mIiIhU4dFhhGNGiIiI1OfRYUSMPSNERETq8OgwIq4zwp4RIiIidXh0GBGnET3DCBERkSo8O4yI1OtZDp6IiEgNHh1GxFN72TFCRESkDo8OI0RERKQ+jw4j4qm9REREpA6PDiNiAsvBExERqcKjwwg7RoiIiNTn0WFEjP0iRERE6vDoMKIRDRrhXRoiIiJ1eHYYEf1bYN8IERGRKjw6jIixZ4SIiEgdHh1GxFN7GUaIiIjU4dFhhIiIiNTn0WFEXA6edUaIiIjU4dFhhIiIiNTn2WFEPGZEvVYQERF5NM8OIyK8S0NERKQOjw4jJrNp2DdCRESkCo8OI2LsGSEiIlKHR4cR0wqsREREpAbPDiNcm4aIiEh1Hh1GiIiISH0eHUY0Jt+xa4SIiEgNHh1GxHibhoiISB0eHUY0LHpGRESkOo8OI2Jcm4aIiEgdHh1GTBbKU7EdREREnsyjwwgRERGpz6PDiMmYEXaNEBERqcKjw4gYx4wQERGpg2HkEkYRIiIidXh0GNFwcRoiIiLVeXQYEWMWISIiUodHhxGTqb0cM0JERKQKjw4jREREpD6HwsjcuXMRHR2NgIAAxMbGIj093eq2y5Ytw4gRI9ChQwcEBwcjPj4eq1evdrjBziQeM1JZq0NlTb16jSEiIvJQisPIkiVLkJKSgqlTpyIzMxOJiYkYNWoUcnNzJbfftGkTRowYgZUrVyIjIwNDhw7F7bffjszMzEY33tmGvb9R7SYQERF5HI2gcLDEgAED0K9fP8ybN8/4WK9evTBmzBjMmDFD1jF69+6NsWPH4rXXXpO1fXl5ObRaLcrKyhAcHKykuTbV6/S4euofJo/lzBzttOMTERF5MrnXb0U9I7W1tcjIyEBSUpLJ40lJSdi6dausY+j1elRUVKBdu3ZKnpqIiIhaKB8lGxcXF0On0yE0NNTk8dDQUBQWFso6xvvvv4/Kykrcd999VrepqalBTU2N8fvy8nIlzZRNY1JohIiIiNTg0ABW84u4IAiyLuzff/89pk2bhiVLlqBjx45Wt5sxYwa0Wq3xKzIy0pFm2sUoQkREpD5FYSQkJATe3t4WvSBFRUUWvSXmlixZgkceeQQ//PADhg8fbnPbKVOmoKyszPiVl5enpJlERETUjCgKI35+foiNjUVaWprJ42lpaUhISLC63/fff4+HH34YixYtwujR9geI+vv7Izg42OTLFXiXhoiISH2KxowAQGpqKsaPH4+4uDjEx8dj/vz5yM3NRXJyMoCGXo38/HwsXLgQQEMQeeihhzBnzhwMHDjQ2KvSqlUraLVaJ74UIiIiao4Uh5GxY8eipKQE06dPR0FBAWJiYrBy5UpERUUBAAoKCkxqjnz66aeor6/HpEmTMGnSJOPjEyZMwFdffdX4V9AIHMBKRESkPsV1RtTgqjojANDlpRUm37POCBERkXO4pM4IERERkbMxjBAREZGqGEaIiIhIVQwjREREpCqGESIiIlIVwwgRERGpimGEiIiIVMUwQs1KaWUtqut0ajeDiIiciGGEmo3iCzW4/s00JMxcp3ZTiIjIiRhGqNnYdeIcAOBcZa3KLSEiImdiGKFmg0sJERG1TAwjREREpCqGEWpG2DVCRNQSMYxQs8HbNERELRPDCDUbNfV6tZtAREQuwDBCzcbT32eq3QQiInIBhhEiIiJSFcMIyaLTC1iZXYDCsmq1m0JERC0MwwjJsmhnLp78bg9uem+92k0hIqIWhmGEZNl4+CwAoLqOg0iJiMi5GEaIiIhIVQwjJAtrfBARkaswjBBJqK3XQxAEtZtBROQRGEaIzJwqrUL3V/7Acz/uVbspREQegWGEyMzXW3MAAMv25KvbECIiD8EwQrK425AR3kIhImo5GEbIqE5nfdquu136XZlFmHOIiJoWwwgBAGb8cRDdpv6BgwXlajdFFj0TAxFRi8EwQgCATzceBwC8t/qwyi2Rx5VRhDGHiKhpMYyQLO43ZqR5HpuIiCwxjDQTgiBg/Oc78MS3GWo3xS24822aA6fLkbI4E7klVWo3hYioWfBRuwEkz8mSKqQfKQbQMNDU19s1OZKVVhvv9o82Q6cXcLCgAqufHax2c4iI3B57RpoJcU8A84KLb9M0ctSITt+w/5GiCmc0h4ioxWMYMVNWVad2EyQJVv4tdvr8RezOOeeS53e3HpPGBgabx3bfO0BERC0Sw4iZvtPX4NjZC2o3wyZrF8uEmetw7yfbsDfvfJO2Rw16BgYiohaDYUTCoh25ajfBJnu9AhknS5uoJeppDhVY3b+FRETuwePDyOcT4iweu1inU6Eltomvvfauw+52S8UVeKEnImo5PD6MDOsVavGYTueOlzr5bWpcFpHeW+Nmw2ZdW2fEHX//REQtl8eHESn+vs37tGg8oGvElYGBUYSIqGk176uui/i5qIZHY/A2jSl2Xiin56hfInJT7nfVdQPufjG3N4C1Mc1399duwMuqMr/vO41r31iDDYeL1G4KEZEFhhEJ7v6p2277GpEorB1bzZCSW1KFb7efNHnMUATuUGE5/v3TXvx9xnkFxtz99++IyYsycaGmHg9/uUvtphARWWAYkeCOvdlyip4ZbPr7rCub4hQXauox8etdWJ55yu62g99dj1d+/svkMUNg+GjdUfyw+xQe+nyn09rmyoJqRERkiWHEzZ0orsQ7qw7hXGWt8THzwZt6vWCygF7agTMWx7lYq8Pt/9uM/646ZPP5mqoHZP7GY1h7sAjPLtnr0P6GwPD7vgIAQGF5tdPa1hJ7RoiI3BkXypPgDp+Mp/26H+cqa7H24BlU1erw277Txp+Zt27b8RL88VehzeMtz8xHdn4ZsvPL8OLIniY/q63XS+5zsKAcT3+fieeSujv0Gmw5V1VrfyMbyi/WYd1B0/EPR4su4OqObRp1XCIianoMIxLU/mQsCAK+2ppj8ljeuYtWt6+pt1+krV4vHTjeWnEAn6WfkPzZpEV7cPxsJZK/3YNb+4TZfQ4lGnuOh8/aZPHY1OXZWPJ4vMPHPH3+IooqaoyrIzeW2u8jIqLmgmHEDensDFpp7EXufFUtrmjtBwAWQUR8l6aypt5pz2lOfLjFO3Oh0QB39+sE30ZMq67TSQcuOfLOVSHxnfUO709ERI7jmBEJalfgtDuA1uzncpor3uY7F6y905hz9tKybLy4NBvTfzvgxBYps+1YiWrPTUTk6RhGJKg9m0Zv58KuZExLVW09DhWWmzwmd5Cq3BLwZRfrkPjOerz5u/wwIfUSvzGbvqvUntzzjdqfiIjUwTAiwfxi35juf0c48zbN7f/bjJGz0y2KXdXp9PhdNCjWwNoigbYCzKIduThVehGfb5Yee9IYOcWVivfJO1dl9xwSEZH7YBiRIL7YHywoR/dX/sDMP2xPiXUm+z0j8h0723AxX3/4cu0RDTT4YvMJTF6UabG9I4M37bVXmv191h44g5ve26DoqL9k5SPxnfV4erHla7OmTqfH2Qs1ip7HoLpOJ/sW1fpDRUhZnImK6jqHnouIqKViGLHjnVWHIAjAJxuPNdlzWpn4YrTnZCl+2J3XqOf485D9suCurDki5/rtyG2buesbfk8rLtUfkXK2ogYzVh7EiUu9Lnd+tAXvrj6s+LkKy6rR89VVeOLbPbK2/+dXu/Bz1ml8+OcRxc9FRNSSORRG5s6di+joaAQEBCA2Nhbp6elWty0oKMC4cePQo0cPeHl5ISUlxdG2NhlndPCXV9fhm205OFuh/BO3zs6VeuLC3fj3T/uw43jDoEulHRMaDeDlpmvQZJw8hy1Hi1FY5lgRMzkB6tklWfh003Hc8dFmAMCBgnI7e0gzBMJV+23XeDFXWO5YLwwRUUulOIwsWbIEKSkpmDp1KjIzM5GYmIhRo0YhN1d6hkZNTQ06dOiAqVOnom/fvo1ucFMwXNz1esHk9oYSLy3dh1d/2Y8JX8gvU36+qhbPLslC+hF5zzl2/nacLFE+pkIDwEvGVVu8xb5TZYqfxxZrAeqeedvw4IIdGDjjT6c8T965Kvx31SEUVVwONxknSwEAFdX11nZzKTfNgUREqlEcRmbNmoVHHnkEEydORK9evTB79mxERkZi3rx5ktt36dIFc+bMwUMPPQStVtvoBjcFwxiA1TY+8c7bcAwPf7nTavXS1fsbSrIr+dT99sqDWJ6Zj2cWZ8ne5/FvMuxvJEFOGBE7VWq96NoJGYNM1+wvxKq/rN86cRaN2esa++k2zNtwDJO+k3crxVGllbWYv+kYipxYlp6IyFMoCiO1tbXIyMhAUlKSyeNJSUnYunWr0xpVU1OD8vJyk6+mZPjUnnuuyuo2/111CBsOn8Vvey1npACOffqVc1E3l+NIz4hG3u0M8wu7lF+y8vFThu3F7qrrdHjsmwwkf7sHZRcbBm+6quS+eYtPX7rdsyun1KHjZeaWYszHW4y9KdY8syQLb688hP/7fIf9NrJrhIjIhKIwUlxcDJ1Oh9DQUJPHQ0NDUVio7L65LTNmzIBWqzV+RUZGOu3YctTrBby/5jAOFZouS3///G34JSvf5LEqB6bCWlOrU36BdrTWmNKeESnl1XUWvTjVdTr85/cDxvEsAFBTd7n36GJtw/lqLqXS7/1kG7LyzuOeeZZh+7NNx43/NqyU/PeZC03WNoIx3BJR8+bQAFbzT8yCIMj6FC3XlClTUFZWZvzKy2vczBGllu45hf+tO4rlmabBY/vxc5a3UKxcVeUWDBOrs3LLxxZHLuoaaJwygLVc4kLw6cbjWLD5BMbO3y65j5IekY1/Kx+vY+9teLFWZ7WWihRr9Uoyc0tRUePYmBOpJh4tqjBZmdmeoopqVNWqM+bFXSzakYu+b6zB/E1NN9ONiFxDURgJCQmBt7e3RS9IUVGRRW9JY/j7+yM4ONjkq7lxJJs5Ulyt1oF9GmbTKGugVHiRCqAniiV6BiT2dVXHiL2XZd6z5agiB2ZJWXOiuBLDZ21CvzfTZD53Nfq/9Seuny5v+5bq5eXZAIC3VzZdDSAicg1FYcTPzw+xsbFISzP9I5iWloaEhASnNqy5sHZRdew2jWOVXv86rXymi9KerMbc1nF0mq4j7PVINbaa7uKdubj5vQ0OzWIyMD/3u3LOKdp/z8nzAIAaB3rSiIjckeJVe1NTUzF+/HjExcUhPj4e8+fPR25uLpKTkwE03GLJz8/HwoULjftkZWUBAC5cuICzZ88iKysLfn5+uOaaa5zzKlQkvk1SVVuPvHMX0SMsSNFtmqKKauzLK7M6M8eerLzzFo/V1Ovg7+NtdR85t2nElUW9vDQOLdqz7VgJHvjs8i0bwyFdNWbE1YNDX1rm/E/jPu5a9IWIqIkoDiNjx45FSUkJpk+fjoKCAsTExGDlypWIiooC0FDkzLzmyPXXX2/8d0ZGBhYtWoSoqCjk5OQ0rvVuQHzBHv3hZpworsTCf/U3uSheqKlHG3/rp3rErE2NGogndSl7e8VBvHFnjOT2P2flw9fbfqeYuPiat8RVXup5S0TjHqrrdCZBpCmI23S0yPKW0Yli6zOkmor5efNWGEbEv4q/z1Sge2iQ1W1r6/UMO0Tk9hwawPrkk08iJycHNTU1yMjIwODBg40/++qrr7BhwwaT7QVBsPhqCUHEnGFq7m97T5tccF78aZ/N/VwxI8BWKfW/8suRKWOFW/EdDbk9DuK1bQwzZ6S4amqv+NbF8FkbLX7+xRbnL+bXWErDiFjSB5us3nq6WKtD7H/SMGbuFoeP70nyzlU5NL2eiBqPa9M0ktQlVYDpGIsV2QWoVjCDwxmcsWiteAE8qTEjjtwSESz+4Vzm07Hdktl5E/c6yV10T8za7KA9uaWoqK53evXclkivF5D4znoMfW8DFzIkUgHDSCNJXTsEARYXnNlrXbc4mqMl663Zf7oMOr2AetEnbqngYe+62UxKibicIAjIzLVeNE3cM2JtKrGY+a/CkSnhZKpedN6dOVOKiORhGHGAuOS31KVj6Z5TFuuerD9UhLQDZ9D/rbXYeqxYYi/3MfrDzXh75UGT3hVH1nHRS6QVwyd/TwoqP+zOw11zLxdNMx/cLA4jdQ4Uvqu2Ekaaw0iRrceKMWftEeid0ZXXCOLbhs3hvBG1NAwjDuj/tuUibjX1tm/DVFTX4dGFu1FUUYOHPpe/eJ5aPt98wu40WHu3aaQuMM2l8qoz/bDbdrl8kzCiV97LcdLaOIdmcFUd99kOfLD2b/zspPovjhK/L+VMe9fpBUz8ejdmrTnswlYReQ6GkUYSBAFTlu1Dj1dW2dzutKjWRr3KnwLlslXHol6ntzvYTyfZM2L4b/M4B87g72P6v5n5tU4cRupl9IyYXyzHLdhh8zZQc2BrHShn2HG8BHfP3YK/8qXHz5iEERnH23TkLNYePIMP1x11TgOJPBzDiBN8v1NZuXpf72bwkdWGX/eexqMLd2PcZ7YXhZMa/2DoDlcjisgZj+EKAb7W670AwLI9l3sFHC3KJrVYoSNLErja1qPFmPj1Lpw+b30VaFcYO3879uSex3grCxmKbynKGZhd08QD0olaOsV1RsiUIx/wfbyaJgO66uL7yvJslMsYQyJ1x2FXTilC2vi7oFX23S2x2F1TCPA1/X0LArA75xx6hQfj/MU6kzWQDGGkqKIax89WYuBV7WU9h9QF1NZFdcmuXCxIP4GEru1xrqoOfa4Mxn1xkbiitZ+s53PUuAUNYaC6bh++nTjA+HhTdZSVVknPlDEJIzJCXDPp3CRqNhhGVODTRD0jvV+3fevIUXL/DkuNf3j+x734ZlsOIq5o5dxGybBXolJtUzCvhLt0zyks3XMKPcOCMOf+601+ZhjA+uBnO3Ck6AI+eygOI65pWPdJEAS8+stfOFVq2augtBfkxaUNlWSPXCoM99ve0/h9XwF+nXyjouM4Kv/8RZt1aJR67oe9yDtXhe8fG+hQ3Rbxe9rVVXyJyBLDSCO9tfKg4n2aqiJmdZ26Uz6HvW9ZdAwA9p4qw95mWPtCPItKrkEz1yHfyi2JQ4UVFr0mhunUhpCwcFsONv19FgOvao/gVj74dnuuxXGssfYue+XnbMnHm7IeyYniSvR67XJYvuDgCsgGS/c03KbKzC1FXJd2ivcXFP6v4kFDnmSprKnHf1YcwK19wpHYrYPazaFmiGNGVODj7YWyi3WqjWForJb0h/isgpoSjpS2txZEDJ5ZnGXyvfliielHivHN9pOYtGgPcmwMGD4nKsNvYG1WiJJA01Q+33zCKYNwHX1rKh0zcrCg3MFnapn+t+4ovt+Zh/HNYKYguSeGETT9QmVnK2qQMONPTPx6V5M+r7M09lOsO7nhrbWytz121vmlws0XObQ1m2bNgTNWf7YiuwCnSqtQW69XvWaHo6b9ul/2ttbeg47+nyxVE8eazNxSfLSes2jE8krVX/OJmjeGETTdGA6xylod1h8+iw2Hi5r8ucl91duoM2KvJ23FvgLEvpmGez5pGKjb3MY+7D1VhkOF8nocSiV6ggDHX/O6Q/L/P3R2xWMiYhgBAFkr2LrKw182z94Rco2qWh2KKqTHptgLIztOnENFTb1xEUR3yyJy1mea8EVju/kde9WfbDxm/HdLug3ZVNztvUbND8MIgHfuuVbtJhABAMZ/vhP937Ks8AvYv0gqudWghl9kVFk9U15jddbTwYJy4wrX1npAHO0ZkVN11bitY09hVZ1Oj0cX7sa8Dcfsb0zUQjGMABjVJ1ztJhDZJdgZninOIt9sy3G72zS2KvqKSRVEyzhZilFz0nHjf9cBsB4eHH3JtaK2Kc10764+5OCzNvjjr0KkHTiD/646hCW73G9wsRxKwhyRFIYRomZiV47t2Sbia+irv+xHZU3j63hsPVqMxHfWYfORplvcUerCtu5Qw+Bdews2OnpRFJejN4S+A6fL8e32k3YHBH+8/pisW1DWVIoG4xrqvxB5GoYRohZi09+mAysdmTp+oaYeBWWXeybGLdiBvHMX8X+iMurL9pzCxK93WZ3RotcLFmXt/z5TgcOFFbLaIDW5zby3wtraRs74fG449K0fpuOVn//Cb/tOmz6HxJM4eousuk6HKcvUCyBFFdX455c7jWHPEfnnL+K3vaftb6hA8YWaZjsrjBzDMELUQs1K+1vxPv3eTEP8jHUmgcRc6g97sfZgERakH5f8+f3ztyNh5jpjb0FNvQ5JH2zCdzvk3YKQqqBqflly5fAYAaZ1Ww7IqCniaM2g+Zukz6GxLYLg0npEb/x6AOsPn8W/vtpt8vjRogosSD9udzVyAHj+h71ObdPmI8WI+89aPLU406nHJffGCqxELVS2lRVqbTGMndiVU4o7+tou2X/eyjovO3POAQAyc8+jQ5AfvtiSo6gNXnZutTyzOBNj4yId2leOt1YcRHb+eas/lyq9b2NGtk32Vise++l2lFTWYHXKYPi4YNbfGStVhYfP2gQAqKzR4Znh3WweI6fEufV35m1sqOGyYl8BPh7n1EOTG2PPCDVLPzwer3YTWrSnv8+0+ES+/XiJyfdSF37x7RMvDTBqTjoWyewRMbCXJ37JOm1ccM/c67/+pei5pKw9eAZnyq1X5pVqn636MLbYGtSr1wvYmXMOx85WuqTgHmC/Ym1Wnv2quHIHJsvlzF6v6jodthwtNhmg7GnqdXrcPXcLnv/RuT1YzsYwQs3Oa7ddg/7RytcfIWVOFF8w+f7++abl8KXGdojL2Xt7aYwL/ykhHXLk7bsn97zTKwTLWYTQ0Vsptga+1ouO6apSSNbG3hh/LuMYzr7QOzOMpCzOwoMLdmDGH5ZriP2RXYBfnTzWxR3tyinFntzz+CnjlNpNsYlhhJqdfw7qonYTCJcX8xMTX5gcndnS2Fstrq63ItU6nYPPWa+TV3HXGbefpDjjTDk9jDjQqo/XH8XU5dkW4WrV/kIAwJdmtwpr6/V44rs9ePr7TKvVfFsKd68/ZMAxI9TssKZB05j5h2X9jGeXZBn/vfFvy7Lo4gtTRbX0mBJ7vC59RHprxQH8lHEKke1aI+ZKrUPHaiq21hRyVJ3o1o8hjNTr9PD20jjt/wHxdWp3zjl8seUEpo6+RvLn1rj6YnemvBptW/vBz8f6Z+d3Vx8GADzQv7Os94r4tlplbT3aBvo1vqFuqrn8tWQYITLjpQE4qxBYe9ByvZblmbarqIpv0zRmqYOTJZX4LP0EAKC0qgz7TskfjOvsa6Oc676jF2SpUDFi1ka8cEsP3NDl8q1Iby8NKmvqceN/1+G6yCvw5T/7O/R85sStvveTbQCkV4C2xfwlnD5/ERFX2B78LNfBgnKMmpOOXuHB+OOZRLvby5n943GaSRrhbRoiM107tFG7Cc3GnwfP4PFvdhu7up3SZS80blCkeRukxkWszC7AI1/tcqiLXiqcJH+7BzvMBvia+++qQ+j3ZhryJSrMih0puoDHvskw6RkBgPWHi1BaVefchfokzk3eOdvtsyfPzgwhe8RN+iWrYUzHQRnTqx19DnIPDCNEZlxZ16GleeTr3Vi9/wy+2NLQi+GMMLInt9S4Bo0jXlq6z+T79RIrYz/53R78eagI76cddvh5xA4WlGOs2QBfsbKLdZi34RjOVdbi/Uu3FOp1epRcsD5rR3zrRy8ILrmA2juknKc0H+Brvs8Pu/Jw77ytNl+rtf3lDNw1LY4mrxvAk/4PF/9+7A1YVhNv0xCZMf9ESvZlXVrczhnTPN9bo7xYm9ifhxrCx6nSKnz45xH8fcZ0oK24OmzJBfk9I2UX69DK19uhNv0lqvlimO3zf5/vwF4bt5/EoVgvuOcF9PT5iya35gDLXod/XwqHs9cewZtjYuwfVLS/t4x7ZOJZR3KH0rjzRdmVBMHxxSRdjT0jTeiefp3UbgLJUFfvmj9Undu1dslx3UFNXcMFyfzCpKbkbzPww+5TxqBk0OvVVcZ/y70mlVyoQd831mDYrA0ODR4VB4s1B85g85FibD9+zuY+4tDU0DPi/PelvUPae853VlkOcra2T6XMKdfi2TReUvPHzTgyXseTOj/Fb1d3nlnDMHLJq7ddY3+jRmoX6Ovy5/B0KcO7YcljAxt1DFcNgnPnPwSNZbiAuFNxqYMF0mvhiD9JC7BcR8fcvA3HMOPSzCJHxlMUVVTjvNltJ/FaP9aIA0xjzuu6Q2fwzqpDkmu9ODKNVkwqfFo9op1codML+PdPe00WhJTTMyI+T3Jjoqf2jLhzCGMYuSTI3/V3rJr7+/+nZNtVT++/QbpEd1Ma2qMjBlzVvlHHUHqrYVjPjrK2a+6/f1t25ZRi/+kytwojci5Mq/efweB31tvdTknBqK1Hi3Hnx1uw/3QZSitr0f+tP/H098rXWREXjBvz8RbF+xv866vdmLvhGJ7/aa9F0HbFe/L0+Yv4eP1Ri8HBhrELOr2AIoky9Kv3F+KH3abneZ3EeB9z4hovO07Y7m0yaMxFubZej+d/3Ovw4oCLd+bizo8242yFvDE0jfHWigN49OvL6w658wcihhGVOFLOvG1rdXtW4rrYrnoaHRLo8LG7dWyDiTdGS/5sSPcOxn+HBQdIbhMU0BAmu3Zs/EwYJWHk1duuwQf3XydrW0MbnSkuqq3Tj+mo0R9udq8wIvNjckGZ9PosjjhypgLjFuzA3rzz+NdXu2QtsmeN+BN/Tb2+0ReSZXvy8ebvB0wekzqkeLaPvVsrUtVpX/hpH95dfRipP2SZbntp04e/3In+b/+JHcdLUFhWjSnLsnGosFwyoGTmnrf5/ACgE4W2mX8cQmau/RL24p4RW6e1tLIW32zLMQlWi3fl4qeMU3jKgYAJAC8ty8beU2V4f41jg6dPllRi4bYc1NTr7PbifpZ+AhWi36EbZxGGEaNGDOppJ7Ngjvh90D+6HRYrvJ3QMyzY7jZKj+ksHYL8G/Vp49Y+4egZbvn6xg3ojC8fvsH4/QP9O0vuv2vqcOx9PQltLvVwPRQf5XBblMymeeTGaAQHyAuJcV2cHxym3dHb6cdsDKmqrGrIP39RVhl3Z3voi53Gf5+rrG1UC5QOpBYEwe4spG+3m64TZO+dvkcUBvR6Ae+uPoSMk/J6HzYdKZZ8PP3S4wu3n8SzS7Lw/c5cjJqTjot1jgVZ8+q3W4/ZnmINyO8ZmbRoD179ZT8mLdpjfKzYST0albWO3Q6+6b0NeO2X/ejxyir0eGWVrPBlwJ6RZsDRcsv7piXh4YQuDu17VQdlPQleot9WGyu3lbw0GqT/e6hD7WmMVc8k4sarQxze39r/Im/f1QdeXhq894++GNazIyYmXu49Seh6+XZMgK83tK0uh4LGDBZ9aVRPh/c1+Ees5WDlSUOvbvRxzYlfszv4r8SARjUMmrnOZYNpbY0xEfeyaKBp1Icc81Bs7zoy7df96PvGGmwWhQCpcSLi9XCUjJ1IfGc9Pl5/DPfM2yZre/Njm58KDYBDheWXtgUu2linBwByiqUXCzR/jeUyKv+K22brAm0INrYCTvapMmw5Kh285LZB2X6m38+QqJRsDcNIM3BrnzB0btcaA6+yvBVhq3vdS6PBnddFOPSc7VorK0EsJzD1CAtCpMIL8cqn7Vc2tKd9G3/06aTF70/diKdvdv5F997YTvj84RsQKAphnz0UB20rX5NQYiD+f25k7zDZz/PXG7fg1pjwRrUVADoG+1s85ui0UGum3e76QddkyVfuqnUaeYvsWWMeesTvacMF+O8zFXh5eTYKy6rx9baTAIB3Rd3/hrVZxHpemk2k1ws4VCg9yFeKvWJt5swve+cv1pkURKuu06G0qs7ke1setLJSs3nPiFRpfvM/neItlF6fzTe//aPNeHDBDhSU2T8/J0tcsPqygvZzAGsz0NrPBxtfuAnv33edxc9sfeLXAIhqH4is10Yofk4fBUtxpgzvZndK4TPDuhk/KSddEyrruBuevwnXRNi//SNXzJVapAzvjg5Blhdje27tE4ZObeWXkQ7098HuV4bju4kDLH42+NI4k9Z+3ggJkh/62vj7oHP71njypq7Gx7xlTC80N6ir5XvGkeOY6yrqTZMz7ZGcT25vlAaNq+lw4LTpeJOdosGZhk+4t/1vMxbtyDUZICt+ytM2AkS2qPaJK5hf5NMOnEGO6GJsvtzA/E3HbR4v//xFHDt7AUszTpn0KpiHD8P/Z+IeEvO26M16Rsqr6/DGb/uRmVuKCzX1+L8FO/DdjpM222Pu9Hn7Y4+SPtik6JjO5s6ziBhGRDQajeRUspl3X2tjn4b/XiGjl8PH2/LY4vEmUtOLr2jtiwPTb0HK8O6SS7aLtW9z+Vifjo/F3f2utNumLmaDTn28NHhldC+L7Yb3khdugIaL5IBo24NdpbT288GmF5TdYvL19pIMaT3CgrDuuSHY/vIwPH1zN3Ru1xpR7VsjpI3l7+nwf0biwQGd8cXDccbH/j2yJ468NQq/P3UjHk28SnZ7+ke3w9InEhArMT7EGWFEjFFEHYUyB7xqGneXBv9ZYbrs/ZLdecZ/Gz7hGgYM/3VaebCwN6XZnqraepMF5+T4aN3RRj3nsPc34rkf9+JX0UwW81sPu3LOobKm3qISr4FOL2DRjstjZ/QC8P7qw/hySw7umrsVX2w+gc1HizF1+V8KW2f/Qu+MooCWzyr9vFLBw/C+0eldU7emMRhGzHhJnBGtjVksSrph/SR6QgxjC/pHt8MjN0YjpI1pj4KPlwat/RpuTYiDkgYNM3LEhdTEAyk1Go2icTA/Jsejz5Va/JAcj4lmF9/nk7pj/vhY2ccCpC+85mNk4iWm4Drz0/5VHdogOMAXHYMDsOnfQ7HxhaHYNXW4xXb+Pt54664+uLmnaeDy9fZCzJVaqyHw3Xsvh9QfHo/H3ddfiXkP9kNsVFvJ37UziGtkQKORPXianGfexmOyttPAeavrmjO/AFc5MBhS7qWoqKIaLy/PNnnsXGUt+r6xBqv3n1H0nHKn3tojnmWTcbLU4mf//GoXVmZb3qICgKUZp/A/USg6W1GDo2cvD7wutzMIWHzq5c7KASC7HL6zSN2S0QsCauv1GPzOekxoxEKWrsBy8GbkFNkRU7K51AUqNak74rq0wwCJsSoAMGXU5V6K+/t3Npa6BhoCTP/odojr0hY7T5zDbdc6Ptbhhi7t8NtTNxq/bxfoZ1y9M6SNv9WQMOKaUEyWGJg5qGuIcZGrF27pgXBtAHqGBePWD9ON24RfIT1N15U0Gg36Rl6BvZeqcka2s39b6GqJ6cJz7r8Od153uefJ8LsQP4+51n4++EdsJ/woqlnRPbSNRblyW8RTZzVouFW1KiURI2enW9+JnErubCuNxnVF4J77YS/u7y9d1ycr7zwEQcB3O3KRaVZ9VkzuB+OXl/2FtQdNQ8ebvx8wqYPS1KpqL09XTf1hr8XPd9oIPdvMFjR84LPtxtu69p7z8W8yTG5v6UwK6Nk27TezadV2tp+74Si0rXzx4ADbMwOt/R6lBqvW6fTo/sofABpuewmC4LLArBTDiBnxJ/q+kVfgtj6NH8xo4OdjGUb8fbwxwsr4jp0vD0NHUV0Na9s90L+z1Smvjvrh8YEYPqvh/qat/2k+eyhO8vF7YzshwM8b10deYTKg9udJg4wFnPR6AX7eXqjV6TGk++UxFinDu2H22iN4dnj3xr8QCYsmDsDzP+5FfNf2uP8G++dtzHVXoqiiBjd0aWucSSBnVPrTw7rhwz+PmDz27j/6GsPIoKvb49tHBiB6ykrJ/f19vCy6dXuEBRlnbBh6vuRM+aamV1Wrk1Vp1RErsguwIrvA6s9f/eUvi2m8Ftv8LO82hGHGi9jyzHxZ+7rKD7tP4Z17+yre7+utOZJt9xH93bd2bf5m20njtGQDnYyekdp6PbLzz+NvBYOFc0uq8M6qhoHI9sKIsS16Ab9k5SMuqh06t28tGZoNHxCNbdPp4e/j3IH1jmIYMSPuAZgz9jqLMRXmFPWMSIQRS5ffQB2tFPiSa/LQq21WjrQ1C+jqjkHGf190oAvYy0uDO/paHv+6yCuM/9YLwI6Xh+FU6UX06aQ1Pv7MsG64N7YTrrxC/mBWJQL9fTDv/+TfdvLy0iB5SFeTx+Tcbk8d0R0P9I/EmI+3YFx/yz8oQf6+Fp9KxsZF4oWRPVBaWYvpvx8w/vFb+XQivtl+EinDu2HA238CAPpHu0/BM3Iv9oLI6A/TcfiMvIvjqVLlJfCbQlF5NYoU1vx4/df9ko/LuaUtVQBOPGTmvk+34Zlh3fDsiO4oLKvGp5uOYVz/zliQfsJkvI8c4sG3er1gvC5Ns9J+APhxdx5eWtZwOy1n5mjJcHS+yvQWVHUtw4jbEidkOZ2Q1saMDO8VitPnL5pUYBwVE443fjuAvqILstQRZZGxWZeQQMy8u4/xDSqWOqI7nripq8Reli7IXOBKKb0goG2gH9qajXvQaDTo1Na9F5WTO003XNsK26cMMwkdfj5eqK3XY0iPhq7hRRMH4Ld9p/Hyrb0QdGncT0gbf5N9rokIxoy7+wAAMl4ZjrMXakwC47v3XosXfpIesCfH44Ovwqd2ZjM4y/NJ3aFt5YtPNh5XPF2UnGP/acveDlf4ROb4Gkc88vVuVNY652+T+O/+Z+knJLeRup1hPq14zp9H8OyI7njiuwxk5p7Hl1tyGt02nSDA69If/K+2Wh5v98lSrN5faHJrqqZeh6V7LD+Imv8+qurqoYV71CriAFYz4oQs7orfNuVm/DJpEGLNym9bC9QLJsRhaE/T+5Bh2gDsm5aEpTbWePl0fD9oW/maDI5sDGtjPXpHBMuul9CYMu+2OLvuRlN47bZrMLpPOG7pLX92kfkfsU0vDMUn/9cPY+Ma7vknXB2CGXdfawwiBs+NaLhNNcGsmmz7Nv4Wt2b+EReJnJmjrdaMufv6K02mK5v798ie+F00ZsiVJt/cDePju7ikPD65l5kKCnIplZ1fZlwturG8JWY6mpPqPbE2fkhOGXsIwKy0v7FGohaMOOMYnsPWWKXHv8mAv+jv6dz1x/CKjNtwF2t1OFdZi1lrDrumBooC/GtgRjxmRDxSOlzbCuHaVljwUBz25JYi71wV/H29TS7o/aPbmaRTqYu9vdLhsVHtkPXaCLuDihxZnbJrh0AcO1t56XH7+/7+1I3IOFmK0U4cNwMAM+/ug+925OKFW3o49bhN4V83RuNfVtbQkStMG4CRWvvntG/kFTg4fSRa+ckPbdZqxswaex10egHbjpdY/KG8LvIKeHtpEHOlFg8ndJH89OUK/k4Ko+LB1uRZlPSs2SqV7yNjFp/UZzepCrfrD9lf3A8A/jx0xjju58hbo/Dj7lPYdrwE/xkTYzJdt17fUOa/yk4vUIDv5QbOMRurZs3FOh3e+nEv/jxUhB92n8L2l4fJ2s8V2DNiRjybRuqC3TbQD8N6heLhQdEWg0bNxzjIrtRoxpmjm8X/ryx+7HKPjJx1UmKu1GJCQheT3hV5415su79/Z/z21I2NHhPjCZQEEXu8vTRY/uQg4/dXhQRix8vD8KOop+7126/BmOsinN5rJbXI45t39oavt0YylMZcGYyYK4Ox/MkEu8d+Lsk1A52lKvtS8zVlmfXbmHIWS5Salmx+mwYA/vmVvCmz1aJeneGzNuLl5dn4be9pJH2w0fQ59AL6vrEG8TPW2Tze7/usD2i25mKtDhv+PgsAKJRYqLApMYyYEV94r1RQDRQApo7uhX/EdsLSJxr+gAY68UJiYFgH56VRloXJpIhvNXUI8sff/xmF7GlJsoq0Sdn9ynDWtmgmDMHxrbtiJH8e2a41QoMDTEKzRqPB7PuvR/a0JASLbqOMH2h6q8jWJ8n2Eu+Pr/7ZH0N7dMAyUbi4ttMVODB9JCYNvdrkePPHx+K3yTfit8k34vrObe0OZL7/hs54xE5vlSMrXjtSu0OOayQWhCTXs1Z3BLA9FdjAfCYNIN0z4oiTJZfL5J8przHp6Vu80/ZgZIOzDizg99H6o4oWBnUlhhEJ2dOSkPnqCGOxMblC2vjj3X/0NY4r+UecdB2Axnj99muw9aWbMW6AvKm85u8zPx8vi7EJSgQH+DZUGI1qi88nSE/rJXUZ6qL8mToEOTNHW0wN/DE5HqOvDcd/77E+LsnH28skmL85xjTQrHl2MIICfOAv0VNmXrjvita+6B0RjC//2R/9Opv2yBmC0KODGwrtDe/VEUm9w6DRXC4Y9uvkQZg0tCuG9+qITS8MtVj7yNtLI1m9WMyR1Y3lzCJ7+64+io87/yFlBQTJfX27XVnJeLleFk06ULIQnlIbDp912bGVYhiREBTgazHDwxGB/j54cWTDCrDOqgOi0WgQoWDKq7OSu1h0SCCWPpGAYQpKxFPT+eOZROx5dYTVBRNv6NIOH4/rhzCt7dtk1vo+4qLa4qoObZDxygh8+fANxscTu4Xgl0mDTAZ1t/L1xp+pQ+yuw5Q6oju+/ld/zLn/eouftW/jjxdu6YkFE25A5/atkZrUQ/G07+tszmCTdrFOh9dtLEaY8cpwjBvQ2WJxzccHW18+ILFbCNqa9UpqW/miR2iQlT3InX3YyPL21pyWueRAS8Iw4mLJQ67C2tQheGuMdFe5q7nzktHkGr7eXk65lWat9oJhTRM/Hy/UiAqufPPIAPSNvAJTL61tpNEAG164Ce3b2F800dfbC0O6dzBZldkWJcOqggN80DHIMngtuFSwL8IslBkq6b44sqfF7SmD7VOGGV/XKLNVnh9JlL5l9J8xMfhg7HUmbf/zuSHIem0EVj87WN6LIWqhGEZcTKPR4OqObVRbYTWxW0Nl0+Y4jZbUZe2CL77NZ7glKV53KLFbB2RPS8KJGaMR2oSDlNemDsELt/TAp+Nj8X8DO2PQ1Q0DUL/6V3+08vPG67dfA1/RFM7h14Riy0s3Y4PZ4oxLHhuInVOHYfS14ZJrLK1KSTTpVRp7g+nt2CtaSQfB/xsYhZA2/gjw8TbOfIhs29p4O+rWPmEAgP5d2mH22OtM9vXSAKHB/i6rSiwWrHDKta2eICK5OLW3hbu6YxA2PH8T2kmsVktky6OJV2HGH4eMyxAsfmwgPl5/FG+Ixl8EB/hi/xu3WIwdacy4JDmkgtLVHdvg6o4N40lu6d1wYa/T6Y3jUv45KBr3xUViQfoJjLp04Tfc7rm9bwR+23sa98V1gkajMfakaDQaPJzQBbnnqtAzLAgJXUMsarwE+HrjyitaIf/8Rfh6a+Dn44WdLw/DjhPn8NT3mRbt9PLSIOu1JOgFwWR22rv39sUdfSMwuHsHtPbzwSs//4ULNfWIbNcKa1OHGCtlfrD278acOqNwbYDFLJLVKYPRMcgf17+ZJvs4rhoAGdW+NcK1Adh+XP7ield1CMTxs+rWy2iunDFTsjE0grutIyyhvLwcWq0WZWVlCA7mSHSipqDXC/jrdBl6hAW5Tclog/+uOoR5G46ha4dA/PncTY0+XnWdDjtOnMOA6HYIcKAX8WhRBWb+cRjPDOtmsrRBVt55PP/jXkwd3QtDe3RUdMzDhRWYlXYYz47obhKAury0wmS7pGtCseaA9Oq5m14Yitb+3nj6+0xsPdawQNyc+6/DN9tO4r1/9MVN720A0NBzuvnFocZbT4bn6BDkjyB/H3w0rp/JIpdiqSO6Y/ORYvj5eCFleDfc+8k2Ra/TXFhwAArLq/H+P/oisVsIPlh7BEm9Q/FPGavM5swcje5T/0CtnPUayMKJGbc6feE8uddvh8LI3Llz8e6776KgoAC9e/fG7NmzkZgoXfkRADZu3IjU1FTs378fERER+Pe//43k5GTZz8cwQkRiNfU6rNl/Bgld28sak9KSiMNIaz9v7Jo6HL1fX22yTed2rfHr5EHGKfyCIGD1/obAMjImzLjdnLVH8NXWE1j25CCTSsvfbD+J/fllePuuPtBoGnqIDhaU49Wf/8Luk6Umz5X56ghc0fryOksfrTuCRTty8d2jAzH0UtgBgJt6dMChggqLehZv3NEbi3fl4WBBOZ4b0R0PDoxCdn4ZEq8OMbm9/UtWPrJPlWHBZuly7bFRbbH0iQT0eOUPiwUmc2aORm395RVr1fSvQdH4Yov0a3CVlU8nmoTJFU/fiNEfbrbYzjBT0pnkXr8V98ssWbIEKSkpmDp1KjIzM5GYmIhRo0YhN1d6LvSJEydw6623IjExEZmZmXj55Zfx9NNPY+nSpUqfmogIQMNq17f3jfC4IAI0XNSBhgG22dNuQaC/D+Kvahgf80D/SBx/+1ZsfOEmk1pCGo0GI2PCTIIIADwzvBsyXhlhseTD+IFRmHnPtfDyujzFuld4MH56IgFbX7oZYZfGAv2YHI+2gX4mn6Yn39wNW166GdEhgfC7dIts8WMD8cWEG7BgQhx6hgUZqzo/N6I7JiR0wZLHB+LLh29A8k1d0S7QD0O6d7AYZ3fndVfilduuwcjepq/B4PtHBwIAPp9wA7StfPHhA9djzv3XYdOlMUHmtyEeNCuPMCC6HTa/OBTDe4Vi3XNDTMYL7ZCoTPrKaHm1nswZBkgDwA1d2kpOjzewtlK7veMveWyg8XttK19cExGMZU8m4N7YTtj58jD0jtBi3XNDLMYSitdSa2qKe0YGDBiAfv36Yd68ecbHevXqhTFjxmDGjBkW27/44ov49ddfcfDgQeNjycnJ2Lt3L7Ztk9edx54RIqIG9To98s9fRFT7ywGioroOW46W4KYeHRy6zeQqhWXVOFVahbgu7Sx+JgiCQ7cEjhZV4Pb/bcG1nbTGqqh/PjcEXTu0sXvsmX8cwt9nKvDWXTEICw7Aop25mPbrfqxNHWJyPgHgp4xTeP7HvXg4oQum3dHbpEdq9LXh+HhcP+NjV3dsgzb+Ppg89Gos2pmLdaKS8DFXBuOn5ARsOFyEQVeHINDPB7d+mI46nR5pzw6BRgP8uPsUiiqq8d6av6HRXK7+nTNztMVtOXM+XhoE+HobFzS9o28EPnzgehSWVeOb7TmYeONVVktVCIKAmno95m44hnBtgNNKUIi55DZNbW0tWrdujR9//BF33XWX8fFnnnkGWVlZ2Lhxo8U+gwcPxvXXX485c+YYH1u+fDnuu+8+VFVVwdfXcqBbTU0NamouV5MrLy9HZGQkwwgRERkHJm84XISyi3W487orXfI8p0qrEKFtBS8vjUko2PziUHRq2xrHz17AgYJy3HZthMl+7685jPzSiwj098GTQ7siXCu/Lk51nQ73fboNcVHt8Nrt12Dar/vx1dYcrE0d3NALdqks/GODr0J1nQ6v394b9Xo9dp44h++252L6mN6SU9nVIjeMKJpNU1xcDJ1Oh9BQ066j0NBQFBZKl9otLCyU3L6+vh7FxcUID7dcMGzGjBl44403lDSNiIg8hGGG1E0KBwUr1ant5cKBq1MGIzO3FGNviDT2ulzVoQ2uEvXIGDyX5PgioAG+3vh18uUVtKfd0dukgvDa1MHIK71oMiDa28sbid06ILGb6UrxzYlDc3nMu7/sdbdJbS/1uMGUKVNQVlZm/MrLy3OkmURERE7RIywI9/fv7PTZJkpd3TFI8cys5kBRz0hISAi8vb0tekGKioosej8MwsLCJLf38fFB+/bSq2L6+/vD39/zBqYRERF5IkU9I35+foiNjUVammlBnLS0NCQkSC/1HR8fb7H9mjVrEBcXJzlehIiIiDyL4ts0qampWLBgAb744gscPHgQzz77LHJzc411Q6ZMmYKHHnrIuH1ycjJOnjyJ1NRUHDx4EF988QU+//xzPP/88857FURERNRsKS4HP3bsWJSUlGD69OkoKChATEwMVq5ciaiohgWlCgoKTGqOREdHY+XKlXj22Wfx8ccfIyIiAh9++CHuuece570KIiIiarZYDp6IiIhcwmUVWImIiIiciWGEiIiIVMUwQkRERKpiGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSleIKrGow1GUrLy9XuSVEREQkl+G6ba++arMIIxUVFQCAyMhIlVtCRERESlVUVECr1Vr9ebMoB6/X63H69GkEBQVBo9E47bjl5eWIjIxEXl4ey8w3AZ7vpsNz3XR4rpsOz3XTcda5FgQBFRUViIiIgJeX9ZEhzaJnxMvLC506dXLZ8YODg/nGbkI8302H57rp8Fw3HZ7rpuOMc22rR8SAA1iJiIhIVQwjREREpCqPDiP+/v54/fXX4e/vr3ZTPALPd9PhuW46PNdNh+e66TT1uW4WA1iJiIio5fLonhEiIiJSH8MIERERqYphhIiIiFTFMEJERESq8ugwMnfuXERHRyMgIACxsbFIT09Xu0nNyrRp06DRaEy+wsLCjD8XBAHTpk1DREQEWrVqhZtuugn79+83OUZNTQ2eeuophISEIDAwEHfccQdOnTrV1C/FLW3atAm33347IiIioNFo8PPPP5v83Fnnt7S0FOPHj4dWq4VWq8X48eNx/vx5F78692LvXD/88MMW7/WBAweabMNzbd+MGTNwww03ICgoCB07dsSYMWNw+PBhk234vnYOOefand7XHhtGlixZgpSUFEydOhWZmZlITEzEqFGjkJubq3bTmpXevXujoKDA+JWdnW382TvvvINZs2bho48+wq5duxAWFoYRI0YY1xoCgJSUFCxfvhyLFy/G5s2bceHCBdx2223Q6XRqvBy3UllZib59++Kjjz6S/Lmzzu+4ceOQlZWFVatWYdWqVcjKysL48eNd/vrcib1zDQAjR440ea+vXLnS5Oc81/Zt3LgRkyZNwvbt25GWlob6+nokJSWhsrLSuA3f184h51wDbvS+FjxU//79heTkZJPHevbsKbz00ksqtaj5ef3114W+fftK/kyv1wthYWHCzJkzjY9VV1cLWq1W+OSTTwRBEITz588Lvr6+wuLFi43b5OfnC15eXsKqVatc2vbmBoCwfPly4/fOOr8HDhwQAAjbt283brNt2zYBgHDo0CEXvyr3ZH6uBUEQJkyYINx5551W9+G5dkxRUZEAQNi4caMgCHxfu5L5uRYE93pfe2TPSG1tLTIyMpCUlGTyeFJSErZu3apSq5qnI0eOICIiAtHR0bj//vtx/PhxAMCJEydQWFhoco79/f0xZMgQ4znOyMhAXV2dyTYRERGIiYnh78EOZ53fbdu2QavVYsCAAcZtBg4cCK1Wy9+BmQ0bNqBjx47o3r07Hn30URQVFRl/xnPtmLKyMgBAu3btAPB97Urm59rAXd7XHhlGiouLodPpEBoaavJ4aGgoCgsLVWpV8zNgwAAsXLgQq1evxmeffYbCwkIkJCSgpKTEeB5tnePCwkL4+fmhbdu2Vrchac46v4WFhejYsaPF8Tt27MjfgcioUaPw3XffYd26dXj//fexa9cu3HzzzaipqQHAc+0IQRCQmpqKG2+8ETExMQD4vnYVqXMNuNf7ulms2usqGo3G5HtBECweI+tGjRpl/HefPn0QHx+Prl274uuvvzYOgnLkHPP3IJ8zzq/U9vwdmBo7dqzx3zExMYiLi0NUVBRWrFiBu+++2+p+PNfWTZ48Gfv27cPmzZstfsb3tXNZO9fu9L72yJ6RkJAQeHt7W6S2oqIii0RO8gUGBqJPnz44cuSIcVaNrXMcFhaG2tpalJaWWt2GpDnr/IaFheHMmTMWxz979ix/BzaEh4cjKioKR44cAcBzrdRTTz2FX3/9FevXr0enTp2Mj/N97XzWzrUUNd/XHhlG/Pz8EBsbi7S0NJPH09LSkJCQoFKrmr+amhocPHgQ4eHhiI6ORlhYmMk5rq2txcaNG43nODY2Fr6+vibbFBQU4K+//uLvwQ5nnd/4+HiUlZVh586dxm127NiBsrIy/g5sKCkpQV5eHsLDwwHwXMslCAImT56MZcuWYd26dYiOjjb5Od/XzmPvXEtR9X0te6hrC7N48WLB19dX+Pzzz4UDBw4IKSkpQmBgoJCTk6N205qN5557TtiwYYNw/PhxYfv27cJtt90mBAUFGc/hzJkzBa1WKyxbtkzIzs4WHnjgASE8PFwoLy83HiM5OVno1KmTsHbtWmHPnj3CzTffLPTt21eor69X62W5jYqKCiEzM1PIzMwUAAizZs0SMjMzhZMnTwqC4LzzO3LkSOHaa68Vtm3bJmzbtk3o06ePcNtttzX561WTrXNdUVEhPPfcc8LWrVuFEydOCOvXrxfi4+OFK6+8kudaoSeeeELQarXChg0bhIKCAuNXVVWVcRu+r53D3rl2t/e1x4YRQRCEjz/+WIiKihL8/PyEfv36mUx5IvvGjh0rhIeHC76+vkJERIRw9913C/v37zf+XK/XC6+//roQFhYm+Pv7C4MHDxays7NNjnHx4kVh8uTJQrt27YRWrVoJt912m5Cbm9vUL8UtrV+/XgBg8TVhwgRBEJx3fktKSoQHH3xQCAoKEoKCgoQHH3xQKC0tbaJX6R5sneuqqiohKSlJ6NChg+Dr6yt07txZmDBhgsV55Lm2T+ocAxC+/PJL4zZ8XzuHvXPtbu9rzaVGExEREanCI8eMEBERkftgGCEiIiJVMYwQERGRqhhGiIiISFUMI0RERKQqhhEiIiJSFcMIERERqYphhIiIiFTFMEJERESqYhghIiIiVTGMEBERkaoYRoiIiEhV/w/AATTrYnjQjgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4e8139c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'rhur-uc'\n",
    "project = 'simple-sequence-imitation'\n",
    "run_id = 102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1a97b5e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.22.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hurra/Projects/survey-ops/toy_models/notebooks/wandb/run-20251110_152654-102</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rhur-uc/simple-sequence-imitation/runs/102' target=\"_blank\">102</a></strong> to <a href='https://wandb.ai/rhur-uc/simple-sequence-imitation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rhur-uc/simple-sequence-imitation' target=\"_blank\">https://wandb.ai/rhur-uc/simple-sequence-imitation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rhur-uc/simple-sequence-imitation/runs/102' target=\"_blank\">https://wandb.ai/rhur-uc/simple-sequence-imitation/runs/102</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epsilon</td><td></td></tr><tr><td>loss</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epsilon</td><td>0.02631</td></tr><tr><td>loss</td><td>0.01041</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">102</strong> at: <a href='https://wandb.ai/rhur-uc/simple-sequence-imitation/runs/102' target=\"_blank\">https://wandb.ai/rhur-uc/simple-sequence-imitation/runs/102</a><br> View project at: <a href='https://wandb.ai/rhur-uc/simple-sequence-imitation' target=\"_blank\">https://wandb.ai/rhur-uc/simple-sequence-imitation</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251110_152654-102/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=project, id=str(run_id), config=config) as run:\n",
    "    found_id = True\n",
    "    loss_hist_wandb = train_agent(\n",
    "        agent=agent,\n",
    "        eps_scheduler=exponential_schedule,\n",
    "        wandb_run=run,\n",
    "        **config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d356e73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "run = api.run(f\"{entity}/{project}/{run_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "442a1abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_hist = run.history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cc1c8238",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_step', '_runtime', 'epsilon', '_timestamp', 'loss'], dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_hist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "d064bbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2474"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_hist_wandb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "782d342d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(run_hist['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "125f2c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~np.isnan(run_hist['loss'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da22a82",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "26267668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=7, reward=0, next_obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([4., 8., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 8., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 6., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 5., 1., 0., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32), action=1, reward=0.25, next_obs=array([5., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([1., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 0., 1., 1., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True, False, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 0., 1., 1., 0., 1., 1., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True, False, False, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 6., 0., 1., 1., 0., 1., 1., 1., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([5., 9., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 9., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), action=7, reward=0.25, next_obs=array([7., 7., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 7., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([8., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 2., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False, False, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), action=1, reward=0.25, next_obs=array([5., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False, False, False, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False, False, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 8., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 5., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=7, reward=0, next_obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 0., 0., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 1., 0., 0., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), action=1, reward=0.25, next_obs=array([5., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 1., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 8., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 2., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([4., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 3., 1., 1., 1., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 6., 0., 1., 0., 0., 0., 1., 1., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True, False, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 2., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True, False, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 4., 0., 1., 1., 0., 1., 1., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 3., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([5., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([7., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 0., 1., 0., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 2., 0., 1., 1., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 6., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 6., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True,  True, False, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 3., 0., 0., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 0., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([7., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 7., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 2., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([5., 9., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 9., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([7., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 4., 1., 1., 1., 0., 1., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 7., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 2., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False, False,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 3., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False, False,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 0., 1., 1., 1., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 0., 0., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 5., 0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([7., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=5, reward=0, next_obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 1., 0., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 8., 0., 1., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([6., 2., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 2., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([7., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 0., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 0., 1., 0., 1., 1., 0., 0., 0., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 5., 0., 1., 0., 1., 1., 1., 0., 0., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 0., 1., 0., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 8., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([8., 7., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 7., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([7., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 6., 0., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([5., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 0., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([1., 2., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 2., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 7., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=4, reward=0, next_obs=array([0., 4., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 4., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 1., 0., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 5., 0., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([3., 3., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 3., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 2., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([3., 2., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 2., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([7., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=7, reward=0, next_obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([3., 3., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 3., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 5., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([7., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([3., 2., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 2., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 4., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 0., 1., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=8, reward=0.25, next_obs=array([4., 8., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 8., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([5., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 0., 1., 1., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=7, reward=0, next_obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 6., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 8., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=7, reward=0, next_obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 4., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 6., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False, False,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False, False,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False,  True, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 2., 1., 0., 1., 1., 0., 1., 1., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False,  True, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 0., 1., 1., 0., 1., 1., 0., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([7., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([9., 7., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 7., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=2, reward=0.25, next_obs=array([3., 2., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 2., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False, False,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False, False,  True, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 5., 1., 0., 1., 1., 0., 1., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False, False,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 8., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 4., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([9., 9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 5., 1., 1., 0., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 8., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 6., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 4., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 7., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=5, reward=0, next_obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([4., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 4., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([7., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 1., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 1., 0., 1., 0., 1., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 6., 1., 0., 0., 1., 0., 1., 1., 1., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 8., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([9., 9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([1., 2., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 2., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False, False,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 3., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False, False, False,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 0., 0., 1., 1., 1., 0., 1., 0., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False, False, False,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 0., 1., 1., 1., 0., 1., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False, False, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 7., 0., 0., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 1., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 4., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 7., 1., 1., 0., 0., 1., 1., 1., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 4., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 0., 0., 1., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 0., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([8., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 0., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 1., 0., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 8., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 5., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 8., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 1., 1., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 1., 1., 1., 0., 0., 1., 1., 0., 0., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 4., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([9., 7., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 1., 0., 0., 1., 0., 1., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 2., 0., 1., 1., 0., 1., 0., 1., 0., 0., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 3., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 7., 0., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([3., 3., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 3., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 7., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 4., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 1., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 2., 1., 1., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 8., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 3., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 1., 1., 0., 1., 0., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 7., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=4, reward=0, next_obs=array([0., 4., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 4., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 8., 0., 0., 0., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 3., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([5., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 0., 1., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([1., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 2., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([ True, False, False,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([3., 3., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 3., 0., 1., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([4., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 7., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([6., 2., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 2., 1., 1., 1., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([1., 4., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 4., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 0., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([4., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([6., 2., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 2., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 1., 1., 1., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 7., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([3., 3., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 3., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 1., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 3., 1., 1., 0., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 0., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([6., 2., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 2., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 6., 1., 1., 0., 1., 0., 0., 1., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 7., 1., 1., 0., 1., 0., 0., 1., 1., 1., 0.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 4., 1., 1., 0., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=5, reward=0, next_obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 0., 0., 1., 0., 1., 0., 0., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False,  True, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 6., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 4., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True, False, False, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 2., 0., 0., 1., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 1.], dtype=float32), action=7, reward=0.25, next_obs=array([7., 7., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 7., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 4., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 7., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 2., 1., 1., 1., 0., 1., 0., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([6., 8., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 8., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 5., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True, False, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 4., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 7., 0., 0., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([5., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=7, reward=0, next_obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 7., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([3., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 3., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), action=1, reward=0.25, next_obs=array([5., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 5., 1., 1., 1., 1., 0., 1., 0., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=5, reward=0, next_obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0.25, next_obs=array([4., 8., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 8., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 5., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 8., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 5., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 7., 1., 1., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 7., 1., 0., 1., 0., 1., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 0., 1., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 0., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 2., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 1., 1., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([9., 7., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=6, reward=0, next_obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 6., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 0., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 7., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 5., 0., 0., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 1., 0., 1., 0., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([7., 8., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 8., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 5., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 4., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 2., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 0., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0.25, next_obs=array([7., 7., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 7., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 2., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 0., 1., 0., 0., 0., 0., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True,  True,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 3., 1., 0., 1., 1., 0., 0., 0., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([5., 8., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True,  True,  True, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 8., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 5., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True,  True, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 2., 1., 0., 1., 0., 0., 0., 1., 1., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False,  True, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 4., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 3., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 7., 1., 1., 0., 1., 0., 0., 1., 1., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False,  True, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 4., 1., 1., 0., 1., 1., 0., 1., 1., 0., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=5, reward=0, next_obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([1., 4., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 4., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 6., 0., 0., 0., 0., 1., 1., 1., 0., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False, False, False,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1., 0.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False, False, False,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True, False, False, False, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 3., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([8., 7., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 7., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([1., 4., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 4., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 3., 1., 0., 0., 1., 1., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 7., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 6., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0.25, next_obs=array([1., 9., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 9., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 5., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 1., 1., 0., 1., 0., 1., 1., 0., 0., 1.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False,  True,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 7., 1., 1., 0., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 0., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 0., 1., 0., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([4., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 0., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([8., 7., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 7., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([9., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=5, reward=0, next_obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 0., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 3., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 8., 1., 0., 0., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 2., 1., 0., 1., 1., 0., 0., 0., 0., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 0., 1., 1., 1., 0., 0., 0., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), action=7, reward=0.25, next_obs=array([7., 7., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 7., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=4, reward=0, next_obs=array([0., 4., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 4., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 6., 1., 1., 0., 0., 1., 0., 1., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([4., 8., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 8., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 2., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 1., 1., 1., 0., 1., 0., 1., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([7., 7., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 7., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([9., 9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=2, reward=0, next_obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 2., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 1., 0., 1., 0., 1., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 7., 1., 0., 1., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 6., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 0., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 3., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 7., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 3., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 6., 1., 1., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([9., 9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 5., 1., 0., 0., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 4., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 3., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([9., 9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 3., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False, False, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 4., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0.], dtype=float32), action=1, reward=0.25, next_obs=array([5., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 1., 1., 1., 0., 1., 1., 1., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 7., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 7., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 4., 1., 0., 0., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), action=1, reward=0.25, next_obs=array([5., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 1., 1., 1., 0., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 0., 1., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=1.0, next_obs=array([9., 3., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=3, reward=0, next_obs=array([1., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 3., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 7., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([2., 4., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 4., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 6., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True, False, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 0., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([5., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 0., 1., 0., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 5., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([7., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=6, reward=0, next_obs=array([3., 6., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 6., 0., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([4., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 2., 1., 1., 1., 0., 0., 0., 1., 1., 1., 0.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 5., 1., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([8., 9., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 9., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([4., 5., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 5., 1., 0., 0., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([1., 4., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 4., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 7., 1., 0., 0., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=2, reward=0.25, next_obs=array([3., 2., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 2., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False, False,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 1., 0., 1., 1., 0., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([6., 9., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False,  True, False,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 9., 1., 1., 1., 0., 1., 1., 0., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 1., 1., 1., 1., 0., 1., 0., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False,  True, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([9., 8., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=1.0, next_obs=array([2., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 7., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 2., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False,  True,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 4., 0., 1., 1., 0., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False, False,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([9., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([ True, False, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), action=1, reward=1.0, next_obs=array([3., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([4., 4., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 4., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([5., 9., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 9., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([6., 2., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False,  True, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 2., 1., 1., 1., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False,  True, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([9., 7., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([3., 5., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 5., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 0., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([6., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 0., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=1, reward=0.25, next_obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=7, reward=0.25, next_obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 7., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "               True]), next_action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=0, reward=0.25, next_obs=array([3., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True, False,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 1., 1., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 0., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 4., 1., 1., 0., 1., 1., 1., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([9., 6., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=6, reward=0.25, next_obs=array([2., 6., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 6., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0.], dtype=float32), action=4, reward=0, next_obs=array([3., 4., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True, False,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 4., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([5., 9., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "               True]), next_action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 9., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 7., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([8., 3., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 3., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([2., 3., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 3., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 1., 0., 0., 1., 0., 0., 0., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 0., 0., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 4., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=1.0, next_obs=array([7., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 6., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 1., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([1., 5., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 5., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([3., 9., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 9., 0., 0., 0., 1., 0., 1., 0., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([4., 2., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 2., 0., 0., 1., 1., 0., 1., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([5., 7., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 7., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0.25, next_obs=array([6., 6., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 6., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([8., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=8, reward=0, next_obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 8., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 5., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([6., 4., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 4., 1., 0., 0., 0., 1., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([8., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 2., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=3, reward=0.25, next_obs=array([5., 3., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True, False,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 3., 1., 0., 0., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True, False,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([8., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 5., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=9, reward=0, next_obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([0., 9., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32), action=5, reward=0, next_obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "              False]), next_action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([1., 5., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), action=0, reward=0, next_obs=array([2., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 8., 1., 0., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([4., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True,  True, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 1., 1., 1., 0., 0., 0., 1., 0., 0., 1., 1.], dtype=float32), action=4, reward=0, next_obs=array([5., 4., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True,  True, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True,  True, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 4., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True,  True, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), action=2, reward=0, next_obs=array([7., 2., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False,  True, False, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 2., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False, False, False,  True,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 1., 1., 1., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([9., 7., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False, False, False, False,  True, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=1.0, next_obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 8., 1., 0., 0., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False])),\n",
       "       Experience(obs=array([2., 9., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([3., 7., 1., 0., 0., 0., 0., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([4., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 6., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=2, reward=1.0, next_obs=array([5., 2., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 2., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=1.0, next_obs=array([6., 5., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False,  True,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 5., 1., 0., 1., 0., 0., 1., 1., 1., 1., 1.], dtype=float32), action=3, reward=0, next_obs=array([7., 3., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 3., 1., 0., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=1.0, next_obs=array([8., 4., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 4., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=2, reward=0, next_obs=array([1., 2., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 2., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=1, reward=0, next_obs=array([2., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0, next_obs=array([3., 8., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False, False, False,  True,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 8., 1., 1., 1., 0., 0., 0., 0., 0., 1., 0.], dtype=float32), action=3, reward=0, next_obs=array([4., 3., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False,  True,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 3., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0.], dtype=float32), action=5, reward=0, next_obs=array([5., 5., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([5., 5., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([6., 7., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True,  True, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([6., 7., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0.], dtype=float32), action=9, reward=0, next_obs=array([7., 9., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True, False, False,\n",
       "               True]), next_action_mask=array([False, False, False, False,  True, False,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 9., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([8., 6., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False, False, False, False,  True, False,  True, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 6., 1., 1., 1., 1., 0., 1., 1., 1., 1., 1.], dtype=float32), action=4, reward=0.25, next_obs=array([9., 4., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False, False, False,  True, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=3, reward=0, next_obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 3., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.], dtype=float32), action=4, reward=0, next_obs=array([1., 4., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 4., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.], dtype=float32), action=8, reward=0.25, next_obs=array([2., 8., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False, False,  True,  True,  True, False,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 8., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0.], dtype=float32), action=7, reward=0, next_obs=array([3., 7., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False,  True,  True,  True, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False, False,  True,  True, False, False,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 7., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0.], dtype=float32), action=9, reward=1.0, next_obs=array([4., 9., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False,  True,  True, False, False,\n",
       "               True]), next_action_mask=array([ True,  True,  True, False, False,  True,  True, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([4., 9., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1.], dtype=float32), action=6, reward=0, next_obs=array([5., 6., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False,  True,  True, False, False,\n",
       "              False]), next_action_mask=array([ True,  True,  True, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 6., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([6., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True,  True,  True, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False,  True, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 1., 0., 1., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32), action=5, reward=0.25, next_obs=array([7., 5., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False,  True, False, False, False,\n",
       "              False]), next_action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 5., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=0, reward=0, next_obs=array([8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([ True, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 0., 1., 1., 0., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=2, reward=0.25, next_obs=array([9., 2., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False, False,  True, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([-1., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "             dtype=float32), action=0, reward=1.0, next_obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), done=False, action_mask=array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32), action=6, reward=0, next_obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([1., 6., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0.], dtype=float32), action=5, reward=0, next_obs=array([2., 5., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([2., 5., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), action=2, reward=0.25, next_obs=array([3., 2., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True,  True,  True,  True, False, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True, False, False,  True,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([3., 2., 1., 0., 1., 0., 0., 1., 1., 0., 0., 0.], dtype=float32), action=7, reward=0, next_obs=array([4., 7., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False, False,  True,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True, False, False, False,  True,\n",
       "               True])),\n",
       "       Experience(obs=array([4., 7., 1., 0., 1., 0., 0., 1., 1., 1., 0., 0.], dtype=float32), action=9, reward=0, next_obs=array([5., 9., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False, False, False,  True,\n",
       "               True]), next_action_mask=array([False,  True, False,  True,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([5., 9., 1., 0., 1., 0., 0., 1., 1., 1., 0., 1.], dtype=float32), action=3, reward=0, next_obs=array([6., 3., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False,  True,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False,  True, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([6., 3., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.], dtype=float32), action=4, reward=0, next_obs=array([7., 4., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False,  True, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False,  True,\n",
       "              False])),\n",
       "       Experience(obs=array([7., 4., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1.], dtype=float32), action=8, reward=0, next_obs=array([8., 8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=False, action_mask=array([False,  True, False, False, False, False, False, False,  True,\n",
       "              False]), next_action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       Experience(obs=array([8., 8., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), action=1, reward=0, next_obs=array([9., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32), done=True, action_mask=array([False,  True, False, False, False, False, False, False, False,\n",
       "              False]), next_action_mask=array([False, False, False, False, False, False, False, False, False,\n",
       "              False])),\n",
       "       ...],\n",
       "      maxlen=100000)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.replay_buffer.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ca8bb645",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer, log = agent.predict(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "4bfa00ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 8, 7, 1, 9, 2, 5, 6, 4, 3]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[exp[1] for exp in buffer.buffer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e21df1e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 8, 7, 1, 9, 2, 5, 6, 4, 3])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_fields"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmo_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
