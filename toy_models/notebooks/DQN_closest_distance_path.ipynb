{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c564147-dfec-4075-963e-541d9e9a0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../environments')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Dict\n",
    "\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from neural_nets import DQN, exponential_schedule, linear_schedule\n",
    "from buffer import ReplayBuffer\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# import wandb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea164b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_matrix(X,Y):\n",
    "  \"\"\"\"\"\"\n",
    "  return cdist(X,Y,metric='euclidean')\n",
    "\n",
    "def get_distance(point1,point2):\n",
    "    \"\"\"Compute Euclidean distance between two points.\"\"\"\n",
    "    return np.linalg.norm(point1 - point2)\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca5828c",
   "metadata": {},
   "source": [
    "# Setup experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ac689a1-e71c-4886-abf0-15e03f0f28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = 'ToyEnv_v2'\n",
    "\n",
    "OUTDIR = f'results/{env_name}/'\n",
    "if not os.path.exists(OUTDIR):\n",
    "    os.makedirs(OUTDIR)\n",
    "    \n",
    "SEED = 10\n",
    "seed_everything(SEED)\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else\n",
    "    \"cpu\"   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3221b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 100_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51bcf6e",
   "metadata": {},
   "source": [
    "# Simulate train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bccfe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_fields(coords, distance_matrix, data_dict):\n",
    "    \"\"\"\n",
    "    Given a list of coordinates, picks the field closest to the origin first, then \n",
    "    always picks the field closest unless it has already been visited\n",
    "    \"\"\"\n",
    "    ordered_indices = np.argsort(distance_matrix, axis=1) # low to high\n",
    "\n",
    "    start_ind = np.argmin(np.sum(coords**2, axis=1))\n",
    "    target_indices = [start_ind]\n",
    "\n",
    "    last_ind = start_ind\n",
    "    for _ in range(len(coords) - 1):\n",
    "        j = 0\n",
    "        current_ind = ordered_indices[last_ind][j]\n",
    "        while current_ind in target_indices:\n",
    "            j += 1\n",
    "            current_ind = ordered_indices[last_ind][j]\n",
    "        target_indices.append(current_ind)\n",
    "        last_ind = current_ind\n",
    "    return target_indices, coords[target_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41e84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(n_datasets=100):\n",
    "    \"\"\"\n",
    "    Generates\n",
    "    \"\"\"\n",
    "    grid_max = 10\n",
    "    ra_range = (-grid_max, grid_max)\n",
    "    dec_range = (-grid_max, grid_max)\n",
    "    n_points = grid_max\n",
    "    \n",
    "    # generate random coords\n",
    "    ra_list = np.random.randint(ra_range[0], ra_range[1], size=(n_datasets, n_points))\n",
    "    dec_list = np.random.randint(dec_range[0], dec_range[1], size=(n_datasets, n_points))\n",
    "    coords = np.stack([ra_list, dec_list], axis=2) # shape (num_ep, nra_points, ndec_points)\n",
    "    coords_dict = {f'night-{i}': coord for i, coord in enumerate(coords)}\n",
    "\n",
    "    data_dict = {}\n",
    "    \n",
    "    distance_matrices = np.empty(shape=(n_datasets, grid_max, grid_max))\n",
    "    full_target_fields = []\n",
    "    full_target_coords = []\n",
    "    # get distance matrices\n",
    "    for i in range(n_datasets):\n",
    "        distance_matrices[i] = get_distance_matrix(coords[i], coords[i])\n",
    "        np.fill_diagonal(distance_matrices[i], np.inf)\n",
    "        target_fields, target_coords = get_target_fields(coords[i], distance_matrices[i], data_dict)\n",
    "        full_target_fields.append(target_fields)\n",
    "        full_target_coords.append(target_coords)\n",
    "        data_dict.update({f'night-{i}': {'step_num': , 'coords': ,'nvisits': }})\n",
    "        # full_target_coords.append(coords[i][target_fields])\n",
    "    return np.array(full_target_fields), np.array(full_target_coords), coords_dict, coords\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7220f58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_fields, target_coords, coords_dict, coords = generate_dataset(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067803a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "54d28dd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44169a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = {\n",
    "    'target_fields': target_fields,\n",
    "    'target_coords': target_coords,\n",
    "    'stepnum': np.array([np.arange(10, step=1, dtype=int) for i in range(len(target_fields))])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0c7c0b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_nvisits = np.empty(shape=(len(target_fields), len(target_fields[0]), len(target_fields[0])))\n",
    "for i, (night_fields, night_coords) in enumerate(zip(target_fields, target_coords)):\n",
    "    nvisits = np.zeros(len(target_fields[0]))\n",
    "    for j, (field_id, c) in enumerate(zip(night_fields, night_coords)):\n",
    "        nvisits[field_id] += 1\n",
    "        full_nvisits[i,j] = nvisits.copy()\n",
    "\n",
    "data_dict = {\n",
    "    'target_fields': target_fields,\n",
    "    'target_coords': target_coords,\n",
    "    'stepnum': np.array([np.arange(10, step=1, dtype=int) for i in range(len(target_fields))]),\n",
    "    'nvisits': full_nvisits\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dcd6c454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset 92228')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAysAAAJjCAYAAAAMK47pAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAkPRJREFUeJzs3Xd8VfX9P/DXvTe5N/tmJ5C9SQghJCAElCFLxIECinWgIlUUq3ZqbSttf9X2a22x1m1lKDhRUaZhCigz7BEImZAdknsz7/z8/qCcck2ABHJz7ng9H4/70Pu5597zuhBuzvt+lkIIIUBERERERORglHIHICIiIiIi6gqLFSIiIiIickgsVoiIiIiIyCGxWCEiIiIiIofkIXcAIiIiIpKPxWKByWSSOwa5KU9PT6hUqks+zmKFiIiIyA0JIVBdXY2mpia5o5CbCwwMRGRkJBQKRafHWKwQERERuaELhUp4eDh8fHy6vFAksichBNra2lBbWwsA6NevX6djWKwQERERuRmLxSIVKiEhIXLHITfm7e0NAKitrUV4eHinIWGcYE9ERETkZi7MUfHx8ZE5CdH/fg67mjvFYoWIyEEtXrwYCoVCunl5eSEyMhLjxo3DSy+9JHWbX41jx45hwYIFKC0t7b3A1+D777/HggULejR2fv369Rg1ahS8vb2h1Wpx66234ujRozbH6PV6/OUvf8HYsWMRGRkJPz8/DBo0CH/729/Q0dFhc+y+ffvwxBNPYNCgQfD390dERAQmTJiATZs2dTr3e++9h2nTpiE+Ph7e3t5ITk7GvHnzUFVV1elYvV6P559/HqmpqfDx8UFUVBRmzpzZKSuRHDj0ixzB5X4OWawQETm4RYsW4YcffkB+fj5ef/11ZGdn429/+xvS09OxYcOGq3rNY8eO4Y9//KNDFSt//OMfu12srFy5ElOmTEF4eDhWrFiBt956C6dOncINN9yA06dPS8eVl5dj4cKFyMnJwTvvvIOvv/4aM2bMwIIFC3DLLbdACCEd+9FHH2H37t14+OGHsXLlSrz33nvQaDQYP348li5danP+F154AX5+fnjxxRexbt06/PrXv8aqVauQm5uLmpoam2NvvfVWLFy4EHPnzsXq1avx17/+FQcOHEBeXh7Kysqu/g+NiMgdCCIickiLFi0SAMSePXs6PVZWViZiYmKEv7+/qK6u7vFrf/bZZwKA2Lx5cy8kvXYvv/yyACBKSkq6dXxaWprIysoSVqtVaistLRVqtVr85Cc/kdpaWlpES0vLJc+3bds2qa2mpqbTcWazWWRlZYmkpCSb9q6O3bNnjwAg/vznP0ttp06dEgDE7373O5tjv//+ewFA/OMf/+jGuyXqfe3t7eLYsWOivb1d7ihEl/15ZM8KEZETio2NxSuvvILm5ma8/fbbUvvevXsxa9YsaXhSfHw87rnnHptv8BcvXoyZM2cCAMaNGycNM1u8eDEAID8/H7fffjuio6Ph5eWF5ORkPProo6ivr7fJUFdXh5/+9KeIiYmBRqNBWFgYRo0a1am3Z8OGDRg/fjwCAgLg4+ODUaNGYePGjdLjCxYswK9+9SsAQEJCgpRny5YtXb73hoYGFBYWYsqUKTZDB+Li4pCZmYmvvvoKFosFAODr6wtfX99Or3HdddcBACoqKqS28PDwTsepVCrk5ubaHHepY3Nzc6FSqWyO9fT0BABotVqbYwMDAwEAXl5eXb5HIrq0sWPH4umnn5Y7hg1HzOQquBoYEZGTuvnmm6FSqfDdd99JbaWlpUhLS8OsWbMQHByMqqoqvPnmmxg2bBiOHTuG0NBQTJ06FS+++CJ++9vf4vXXX0dOTg4AICkpCQBw+vRp5OXl4ZFHHoFWq0VpaSn+8Y9/4Prrr8fhw4elC/D7778fBQUF+Mtf/oLU1FQ0NTWhoKAADQ0NUp4PP/wQDzzwAG6//XYsWbIEnp6eePvttzF58mSsX78e48ePxyOPPIJz587htddewxdffCEtXZmRkdHl+zYajQAAjUbT6TGNRoO2tjacPn0aqampl/yzuzAPZeDAgZf9Mzabzdi2bdsVjwOArVu3wmKx2BwbFxeH22+/Hf/85z+Rm5uLYcOG4cyZM/jZz36G2NhYzJo164qvS0T2YTQaoVar5Y5BVyJDTw8REXXD5YaBXRARESHS09Mv+bjZbBYtLS3C19dXvPrqq1J7d4eBWa1WYTKZRFlZmQAgVq5cKT3m5+cnnn766Us+t7W1VQQHB4tbb73Vpt1isYjBgweL6667TmrryTAwi8UigoODxfjx423aGxsbhb+/vwAgvv/++0s+/+DBg8Lb21vccccdVzzX888/LwCIr7766rLH6fV6kZ6eLmJiYkRzc7PNY0ajUcydO1cAkG5ZWVndHvJGZA/OOgxs9uzZNv+WLnxumM1m8fDDD4v4+Hjh5eUlUlNTxcKFCzs99/bbbxcvvvii6Nevn4iLixNCCLFjxw4xePBgodFoRG5urvjyyy8FALF//37puUePHhVTpkwRvr6+Ijw8XNx3332irq7uspm68vrrr4vk5GSh0WhEeHi4mD59uvSY1WoVf/vb30RCQoLw8vISWVlZ4rPPPrN5/urVq0VKSorw8vISY8eOlX5PNDY2CiGEeOGFF8TgwYNtnvPPf/5Teq8XvP/++2LAgAFCo9GItLQ08frrr0uPlZSUCABixYoVYuzYscLb21tkZWV1+lzdvn27GD16tPD29haBgYFi0qRJ4ty5c91+Lxe73M8jixUiIgfVnWIlPDzcplhpbm4Wv/71r0VSUpJQqVQ2vzwfe+wx6bjLFSs1NTXi0UcfFdHR0UKpVNq8xl//+lfpuBtvvFEEBgaKP//5z+KHH34QRqPR5nXy8/MFAPH5558Lk8lkc/vNb34jFAqFNJ+kp3NWfv/73wsA4k9/+pOoqakRp06dElOnTpXe886dO7t8XklJiYiJiRGpqamioaHhsud49913BQDxi1/84rLHtbe3iwkTJggfH58uzztnzhwRHBws/vnPf4qtW7eKTz75RAwdOlQkJCSI0tLSbr1fot52uYtDg8EgDAaDzZwws9ksDAaDMJlMvX5sTzQ1NYm8vDwxd+5cUVVVJaqqqoTZbBZGo1H84Q9/ELt37xbFxcXiww8/FD4+PuKTTz6Rnjt79mzh5+cn7r//fnHkyBFx+PBhodfrRXBwsLjvvvvE0aNHxZo1a0RqaqpNsVJZWSlCQ0PFc889J44fPy4KCgrExIkTxbhx4y6b6cf27NkjVCqVWL58uSgtLRUFBQU2XyL99re/FQMGDBDr1q0Tp0+fFosWLRIajUZs2bJFCCFEeXm50Gg04qmnnhInTpwQH374oYiIiOhxsfLOO++Ifv36iRUrVoji4mKxYsUKERwcLBYvXiyE+F+xMmDAALFq1SpRWFgoZsyYIeLi4qS/0/379wuNRiPmzZsnDhw4II4cOSJee+01qYC70nv5MRYrRERO6ErFSktLi1CpVDY9DLfeeqvw8fERL730ktiwYYPYvXu32LNnjwgLCxOzZ8+WjrtUsXKh1yMsLEz861//Eps3bxa7d+8WO3fuFADECy+8IB1bV1cnnnrqKREXFycASBcBVVVVQgghPvzww07fNv74Vl5eLoToebFiMpnEM888I9RqtfRaU6dOFY888ogAICoqKjo9p7S0VMTHx4uEhIQuH7/Y+++/L5RKpfjpT39qc2H1Yx0dHeKmm24SXl5eYsOGDZ0eX7t2rQDQ6RvFxsZGodVqxYMPPtit90vU2y53cbhgwQKxYMECm8Uptm7dKhYsWGDTuyqEEH/5y1/EggULpItlIYT44YcfxIIFC8SKFStsjv2///s/sWDBApsFKvbu3dvj7GPGjBFPPfXUFY97/PHHbXouZs+eLSIiIoTBYJDa3nzzTRESEmLz53Dhi4oLxcrvf/97MWnSJJvXrqioEABEYWFhtzOtWLFCBAQECL1e3+mxlpYW4eXl1an3Ys6cOeKee+4RQgjx3HPPifT0dJvPpN/85jc9LlZiYmLE8uXLbY7585//LPLy8oQQ/ytW3nvvPenxo0ePCgDi+PHjQggh7rnnHjFq1Kgu32d33suPXe7nkXNWiIic1OrVq2GxWDB27FgAgE6nw6pVq/DCCy/g2WeflY4zGAw4d+5ct17zyJEjOHjwIBYvXozZs2dL7UVFRZ2ODQ0NxcKFC7Fw4UKUl5fj66+/xrPPPova2lqsW7cOoaGhAIDXXnsNI0aM6PJ8ERER3X27Njw8PPCPf/wDf/rTn1BSUoLQ0FD069cPkydPRkJCAqKjo22OLysrw9ixYyGEwJYtWzo9frFFixbhkUcewezZs/HWW29dcv1/g8GAadOmYfPmzVi5ciXGjx/f6ZgDBw4AAIYNG2bTHhgYiOTkZBw5cqSH75yILuWtt97Ce++9h7KyMrS3t8NoNCI7O9vmmEGDBtnMUyksLERWVpbNYhcXFuC4YN++fdi8eTP8/Pw6nfNK8+MuNnHiRMTFxSExMRE33XQTbrrpJtxxxx3w8fHBsWPH0NHRgYkTJ9o8x2g0YsiQIQCA48ePY8SIETafSXl5ed069wV1dXWoqKjAnDlzMHfuXKndbDZ3WggkKytL+v8Lcwlra2sxYMAAHDhwQFqo5ce68156gsUKEZETKi8vxy9/+UtotVo8+uijAM5vqiWE6DTx/L333pNWx7rgwjHt7e027Rd+Cf74NS5ecawrsbGxmD9/PjZu3IgdO3YAAEaNGoXAwEAcO3YM8+fPv+zzL5XnSi5s8ggABQUF2LhxI1555RWbY8rLyzF27FhYLBZs2bIFcXFxl3y9xYsX45FHHsF9992H995777KFyh133IFNmzbhiy++wOTJk7s8rn///gCAnTt32py3oaEBJ0+e7LLAIZLbc889B+B/q9kB5/89jxgxAkql7UKyv/zlLzsdO2zYMOTk5HQ69qmnnup07I+Liav16aef4plnnsErr7yCvLw8+Pv74+WXX8auXbtsjvvx6oBCiE7/zsVF+y8BgNVqxa233oq//e1vnc574SK+O/z9/VFQUIAtW7bg22+/xR/+8AcsWLAAe/bsgdVqBXD+S6ioqCib5134fPxxrq4olcpOx128K/yF87z77rsYPny4zXEqlcrm/sV/Txf+jC4839vb+5IZuvNeeoLFChGRgzty5AjMZjPMZjNqa2uxbds2LFq0CCqVCl9++SXCwsIAAAEBARg9ejRefvllhIaGIj4+Hlu3bsV//vMfaancCzIzMwEA77zzDvz9/eHl5YWEhAQMGDAASUlJePbZZyGEQHBwML755hvk5+fbPF+n02HcuHH4yU9+ggEDBsDf3x979uzBunXrcOeddwI4X0i89tprmD17Ns6dO4cZM2YgPDwcdXV1OHjwIOrq6vDmm28CgFRwvPrqq5g9ezY8PT2RlpYGf3//Lv9MtmzZgj179iArKwtCCOzevRt/+9vfcNNNN9kURrW1tRg3bhyqqqrwn//8B7W1taitrZUej46OlnpZPvvsM8yZMwfZ2dl49NFHsXv3bptzDhkyRPpFO2PGDKxduxbPP/88QkJCsHPnTum4gIAAaSWzO++8E3/4wx8wb948nDlzBjk5OaiqqsLLL7+MtrY26eKNyJF0tUKWSqXqdDHbW8deTb4ffwGzbds2jBw5Eo8//rjUdvEGsZcyYMAALFu2DAaDQfr3vXfvXptjcnJysGLFCsTHx8PDo+tL564ydcXDwwMTJkzAhAkT8MILLyAwMBCbNm3CxIkTodFoUF5ejjFjxnT53IyMDHz11Vc2bRd/9gBAWFgYqqurbYqwCz28wPne7KioKBQXF+Pee++9Yt5LycrKwsaNG/HHP/6xy5xXei890uXAMSIikt2FOSsXbmq1WoSHh4sxY8aIF198UdTW1nZ6zpkzZ8T06dNFUFCQ8Pf3FzfddJM4cuSIiIuLs5mzIoQQCxcuFAkJCdKk9EWLFgkhhDh27JiYOHGi8Pf3F0FBQWLmzJmivLzcZs5KR0eHeOyxx0RWVpYICAgQ3t7eIi0tTbzwwguitbXV5jxbt24VU6dOFcHBwcLT01NERUWJqVOndprH8dxzz4n+/ftLk/ovt1LZjh07xPDhw0VAQIDQaDQiMzNT/P3vf+80yX/z5s2XnTNz8Rycrlb0ufh28Xyayx03ZswYmwxVVVVi/vz5Ijk5WXh5eYn+/fuLqVOnih9++OGS74/I3px1NTAhhJg7d64YNmyYKCkpEXV1dcJisYiFCxeKgIAAsW7dOlFYWCh+97vfiYCAAJv5GxdWA7uYTqcTwcHB4oEHHhDHjh0T69atEwMGDBAAxIEDB4QQQpw9e1aEhYWJGTNmiF27donTp0+L9evXi4ceekiaSN9Vph/75ptvxKuvvir2798vSktLxRtvvCGUSqU4cuSIEOL86oMhISFi8eLFoqioSBQUFIh///vf0sT3srIyoVarxTPPPCNOnDghli1bJiIjI23mrBw7dkwoFArx17/+VRQVFYl///vfIigoyGbOyrvvviu8vb3FwoULRWFhoTh06JB4//33xSuvvCKE+N+clYtXQ2tsbLT5XC4sLBRqtVrMmzdPHDx4UBw/fly88cYb0gT7K72XH+MEeyIiIiKSOHOxUlhYKEaMGCG8vb2lLxI6OjrEgw8+KLRarQgMDBTz5s0Tzz777BWLFSHOf/mRlZUl1Gq1yM3NFcuXLxcAxIkTJ6RjTp48Ke644w4RGBgovL29xYABA8TTTz8tTXbvKtOPbdu2TYwZM0YEBQVJywFfvFqZ1WoVr776qkhLSxOenp4iLCxMTJ48WWzdulU65ptvvpGWPr7hhhvE+++/b1OsCHF+0YCYmBjh6+srHnjgAfGXv/yl09LFy5YtE9nZ2UKtVougoCAxevRo8cUXXwghulesCCHEli1bxMiRI4VGoxGBgYFi8uTJUo7uvJeLXe7nUSFENwbAEREREZHL6OjoQElJCRISEmwmlxOwbNkyPPTQQ9DpdJedm+EItmzZgnHjxqGxsbHTcF9ncrmfR+UlnkNERERE1C26NhN+/flB6NpMVz7YwSxduhTbt29HSUkJvvrqK/zmN7/BXXfd5fCFirvgBHsiIiIiuibfHKrEp3vPYHBMIO4dfukV9xxRdXU1/vCHP6C6uhr9+vXDzJkz8Ze//EXuWPRfHAZGRERE5GZ6exjYPe/sxA/FDRiZFILlc7veV4noUjgMjIiIiIjsorHViF0lDQCAncUNaGozypyIXAmLFSIiIiK6avnHa2D97zgdqwDyj9XIG4hcikPPWbFaraisrIS/v/8ldxEmIiIiop4xGo2wWq2wWCzd2szwclYdrIRScb5QUSmAVYcqceeQ/r2UlFyVEAJWqxWenp6XPc6hi5XKykrExMTIHYOIiIjIpcTFxeGtt95Ce3v7Nb1Oq8mK7UX1Us+KRQDbT9Vjx+598PHkAB66sqysrMs+7tDFir+/PwCgoqICAQEBMqchIiIicg1GoxE1NTWIj4+/pgn2Kw9UwirqbNosAmjQ9MOowexdoUuzWCw4dOgQlEolrFbrJY9z6GLlwtCvgIAAFitEREREvaSjowN1dXVQqVRQqVRX/TrrjtZApVTAYv3f4rIqpQLrjtbgjhyOjqEru9JUD/bPEREREVGPtRrM2FxYa1OoAIDFKrD5RB3ajGaZkpErYbFCRERERD22pbAOJkvX2/UZLVZsKazr8jF7efDBBzFt2rRee72xY8fi6aef7rXXo6vj0MPAiIiIiKjv3PLadhw9q+vWsQLoNATsApVSgceXFaC7a7kOjNJi1ZPXdz+oHZlMpiuuUEV9hz0rRERERAQAeHhUPDxVSgjgijcAXRYqF7d353XUHko8PCq+2xk///xzDBo0CN7e3ggJCcGECRPwq1/9CkuWLMHKlSuhUCigUCiwZcsWAMBvfvMbpKamwsfHB4mJifj9738Pk8kkvd6CBQuQnZ2N999/H4mJidBoNJg9eza2bt2KV199VXq90tLSbmek3sOeFSIiIiICANyZE42saC3mfViAoroWiK5rkV6hVADJ4X54494cJIf7d+s5VVVVuOeee/B///d/uOOOO9Dc3Ixt27bhgQceQHl5OfR6PRYtWgQACA4OBnB+ddnFixejf//+OHz4MObOnQt/f3/8+te/ll63qKgIn376KVasWAGVSoW4uDicOnUKmZmZ+NOf/gQACAsL6+U/AeoOFitEREREJEkO98c3T16Pl9Ycx5IfyqDA/3pSesOF13sgLx7PThkAL8/ur0ZWVVUFs9mMO++8E3FxcQCAQYMGAQC8vb1hMBgQGRlp85zf/e530v/Hx8fjF7/4BT755BObYsVoNOKDDz6wKUjUajV8fHw6vR71LRYrRERERGTDy1OFP96eiRtSwvDzTw+g1Wi55JCvnlApFfBVq/CPu7IxISOix88fPHgwxo8fj0GDBmHy5MmYNGkSZsyYgaCgoEs+5/PPP8fChQtRVFSElpYWmM3mTltixMXFsefEQXHOChERERF1aUJGBL59ZgyGxl26GOiJoXFB+PaZMVdVqACASqVCfn4+1q5di4yMDLz22mtIS0tDSUlJl8fv3LkTs2bNwpQpU7Bq1Srs378fzz//PIxGo81xvr6+V5WH7I89K0RERER0SZFaLyyfOwJvbT2NV74tBAD0pJNF+d8lwX4xKQ2PjUmCStndNcK6plAoMGrUKIwaNQp/+MMfEBcXhy+//BJqtRoWi8Xm2B07diAuLg7PP/+81FZWVtat83T1etT3WKwQERER0WWplAo8MS4Z1yUEY+ZbP/TouVYBfP5YHobGB19zjl27dmHjxo2YNGkSwsPDsWvXLtTV1SE9PR0dHR1Yv349CgsLERISAq1Wi+TkZJSXl+Pjjz/GsGHDsHr1anz55ZfdOld8fDx27dqF0tJS+Pn5ITg4GEolByX1Nf6JExEREVG3mCzWq3xe70zRDwgIwHfffYebb74Zqamp+N3vfodXXnkFU6ZMwdy5c5GWloahQ4ciLCwMO3bswO23345nnnkG8+fPR3Z2Nr7//nv8/ve/79a5fvnLX0KlUiEjIwNhYWEoLy/vlfdAPaMQwp6L0l0bvV4PrVYLnU7XaSIUEREREV2djo4OlJSUICEhAV5eXt1+3h9WHsGyXeU9mmyvUipw3/BY/PH2zKuJSi7KYrFg//79GDJkCEwm0yV/HtmzQkRERERXZLUKrDpU1eNVwSz/fZ61F1YTI/fDYoWIiIiIrqigvBHnWo1dPqZQ2P73xxpajdhf0WinZOTKWKwQERER0RWtPVLd5UpeKqUC/hoP/GpyGvw1Hpc8Zu3h6r6ISS6GxQoRERERXZYQAqsOVXY5BGxYfDA2/HwMnhiXjPyfj8GwLvZksVgFvjlUCQeeKk0OisUKEREREV3W4bM61OgN0n2V4vz+Kb++KQ3LHxmO8IDzk6IjArywbO4I/PqmNCgV/9tjBQBq9AYcOavv6+jk5LjPChERERFdUnGbAYuPVAJaNaxWAaUC0Pqq8dzNA5AWGYAjre2dnnN9bn+ERvnhr2tO4FyrEVYBKJUKLDp6FvODvZDoo5HhnZAzsnuxcvbsWfzmN7/B2rVr0d7ejtTUVPznP/9Bbm6uvU9NREROwGxuRUXF+zhb+TEMhlpoNOGI6j8LMTEPw8PDV+54RG6tuM2AkbuOAxoAI8Kk9koAT56pBs5cYR5KVqDN3eUwYvmu4/h+eDoLFuoWuxYrjY2NGDVqFMaNG4e1a9ciPDwcp0+fRmBgoD1PS0RETsJsbkXB/p+gufkYgPObzRkM1Sgu+Rfq6jcgZ8hyFixEMmqxWJzqdcn12LVY+dvf/oaYmBgsWrRIaouPj7fnKYmIyIlUVLxvU6j8jxXNzcdQUfE+EhKelCMaERE5ALtOsP/6668xdOhQzJw5E+Hh4RgyZAjefffdSx5vMBig1+ttbkRE5LrKyj9E50LlAivOnP2oL+MQkZtasGABsrOz5Y5BXbBrsVJcXIw333wTKSkpWL9+PR577DH87Gc/w9KlS7s8/qWXXoJWq5VuMTEx9oxHRER96MyZM9iwYQPKysqkNovl3GWfYzTW2TsWERE5MLsWK1arFTk5OXjxxRcxZMgQPProo5g7dy7efPPNLo9/7rnnoNPppFtFRYU94xERkZ0IIVBbW2vTduDAAezYsQPHjh2T2jSa8Mu8BqBR/+/xXbt24dNPP0VpaWmv5yUiIsdk12KlX79+yMjIsGlLT09HeXl5l8drNBoEBATY3IiIyLlYLBb885//xJtvvommpiapfcCAAcjKykJiYqLUFtV/Fi71q0ihUCIqapZ0/9ChQzh+/Djq6+ttzmUymXr9PRCR4xJC4P/+7/+QmJgIb29vDB48GJ9//jkAYMuWLVAoFNi4cSOGDh0KHx8fjBw5EoWFhTav8de//hURERHw9/fHnDlz0NHRIcdboW6wa7EyatSoTj8cJ0+eRFxcnD1PS0REfaS+vh5r167F+vXrpTaVSoXAwEB4enqiru5/w7iSk5Nxxx13IC0tTWqLiXkY/v4Z6PzrSAl//wzExDwstdxyyy0YNWoU0tPTpbaioiK8/PLLWLduXa+/NyJyTL/73e+waNEivPnmmzh69CieeeYZ3Hfffdi6dat0zPPPP49XXnkFe/fuhYeHBx5++H+fJZ9++ileeOEF/OUvf8HevXvRr18/vPHGG3K8FeoGu64G9swzz2DkyJF48cUXcdddd2H37t1455138M4779jztEREZAcWiwWVlZXw9/eXlqDv6OjA7t274eXlhYkTJ0KpPF90TJ8+HX5+flCpVJd9TQ8PX+QMWd6tfVb69euHfv362Ty/uLgYJpMJCoXCpv306dOIi4uDhwf3PiZyJa2trfjHP/6BTZs2IS8vDwCQmJiI7du34+2338ZPf/pTAMBf/vIXjBkzBgDw7LPPYurUqejo6ICXlxcWLlyIhx9+GI888ggA4P/9v/+HDRs2sHfFQdn1U3zYsGH48ssv8dxzz+FPf/oTEhISsHDhQtx77732PC0REdnB119/jUOHDmHMmDEYO3YsAKB///647rrrEB8fDyGEdKxWq+3263p4+CIh4cmrWqL4pptuQlZWFnx8fKS2+vp6fPjhh/D29sbPf/5zFixELuTYsWPo6OjAxIkTbdqNRiOGDBki3c/KypL+/8KXHLW1tYiNjcXx48fx2GOP2Tw/Ly8PmzdvtmNyulp2/wS/5ZZbcMstt9j7NERE1EssFgtWrVqF0tJS/PSnP4W3tzcAIDY2FqdOnbI5VqlUYsqUKXLEBAAoFApERUXZtOl0OgQEBCA8PNymUNm1axcCAwORlJTEAobISVmt55c6X716dad/+xqNBqdPnwYAeHp6Su0Xel4vPJecCz+tiYjcmMlkQnl5OQwGg7QgikqlQkVFBZqamlBaWirNEcnOzkZOTk6nIVeOJikpCU8//bTNkA6j0YgNGzbAbDbjpz/9aafhZETkHDIyMqDRaFBeXi4N87rYhWLlctLT07Fz50488MADUtvOnTt7NSf1HhYrRERuxGq1wmq1Sj0LJSUl+OijjxAYGIj09HSpEJkwYQI8PT0RGxsrPfdK808ciUKhkHqEgPNFWW5uLqqrqxEZGSm179ixA/X19Rg2bBj69+8vR1Qi6gF/f3/88pe/xDPPPAOr1Yrrr78eer0e33//Pfz8/Lq1iNNTTz2F2bNnY+jQobj++uuxbNkyHD161GalQnIcLFaIiNzEd999h507d2Ls2LG47rrrAADx8fEICgpCXFwcLBaLVMQMGDBAzqi9ztfXFzfddJNNmxACBQUFOHfuHBITE6VixWKxAHCu4ozInfz5z39GeHg4XnrpJRQXFyMwMBA5OTn47W9/262hXnfffTdOnz6N3/zmN+jo6MD06dMxb948m1UNyXEoxMUzIh2MXq+HVquVxh8TEdGVWa1WFBYWoqSkBJMnT5Yuurdt24ZNmzYhIyMDM2fOlDml/IQQKC8vx7Fjx3DjjTdCo9EAAA4ePIj169dj+PDhXQ4zIXIFHR0dKCkpQUJCAry8vC553KHmNkzae7LXz//t0FRk+ftc+UByWRaLBfv378eQIUNgMpku+fPInhUiIidnsVjQ3NwsLSesUCiwatUqtLW1YeDAgdKwiKysLMTHx3ealOquFAoF4uLiOg0bOX36NNrb221WNxNCoLS0FHFxcdLyzEREZH8sVoiInFhxcTE+/vhjhIaGSvsLKBQK6Zuqi5f01Wq1PVpS2F1NmzYNQ4YMQXBwsNRWWVmJpUuXIjAwEE8++SQLFiKiPsJihYjISZw6dQpHjhxBRkaGtAt8WFgYTCYTmpubYTKZpOU6J0yYIGdUp6ZUKpGQkGDTptPp4O3tjejoaJtCZdeuXQgPD2ePCxGRnbBYISJyQEajEWVlZUhOTpZW6CopKcGhQ4egVCqlYsXf3x9PPPEEQkJCHH5JYWeWkZGBAQMGoL29XWpra2vD+vXrIYTA/PnzERISImNCIiLXxGKFiMjBWK1W/OMf/4DBYMC8efMQHh4O4PwFs0qlQmpqqs3xoaGhcsR0O0qlEr6+vtJ9k8mE7OxsNDU12RQqW7duRWtrK4YNG4awsDA5ohIRuQwWK0REMqqursbWrVuhUqkwY8YMAOcviqOjo9HQ0ICWlhapWImOjkZ0dLSccekiWq0Wt912m02b1WrF3r170dLSguTkZKlYsVgsUCqV7P0ih3OlpX797LSEt71el5zT5X4OWawQEfWRtrY2FBcXIywsDBEREQDOFyYnTpyAh4cHzGaztM/JXXfdBbVaLWdcukq33XYbTpw4gaSkJKlt37592L59O0aNGoXhw4fLmI7oPLVaDaVSicrKSoSFhUGtVndZTPdXApuzE9FqufL+Jd3lq1Kiv1Kgo6Oj116TnM+FPa30ej0aGhqgVCq7/L3HYoWIyE4uLj4AID8/HwcOHMDIkSMxceJEAOcnyE+cOBFxcXE2mxCyUHFOSqUSKSkpSElJsWk/deoUmpubbb49tFqtqKysRFRUFHtcqM9dWEiiqqoKlZWVVzze94pH9ExJL78eOR+r1Yq6ujp4e3vDz88PsbGxXS5UwmKFiKiXWa1WLF++HGVlZfjZz34Gf39/AEBiYiIqKyul+8D5ZYZHjhwpV1TqIxd2zO7fv7/UVlpaig8++AD9+vXD3LlzWbBQn1Or1YiNjYXZbJa+5SbqKy0tLbj55puxf/9+BAUFXfIzkMUKEdE1aGtrw4kTJ2A2m3HdddcBOP+NZVtbG8xmM8rKypCZmQkAyMzMxKBBg+SMSzLx8PCQVnC7oKmpCWq1Gv369bP5Jb1r1y7ExMR0aieyB4VCAU9PT2nZc6K+YjQaUV5eDg8Pj8t+1rFYISLqgY6ODggh4O3tDQCora3FN998A19fXwwbNkz6wJ0yZQq8vLxsVurihSddLCcnB4MGDYLRaJTampqasG7dOgDAL37xC/j5+ckVj4jIIbBYISLqpvz8fPzwww+48cYbcf311wM4v0JXfHy8NJTiwreTMTExckYlJ/Hjb7QtFgsGDhwIo9FoU6hs2rQJVqsVubm5CAoKuqZzFrcZ0NKLQ378VCok+mh67fWIiC7GYoWI6EesVit2796NkpISTJ8+XZrsHhAQACEE6uvrpWM9PDwwe/ZsuaKSiwkJCcGMGTMghJDazGYzdu/eDYPBgNTUVKlYuZrlkIvbDBi563iv5/5+eDoLFiKyCxYrROT2WlpaoNfrpcnPCoUCO3fuhE6nQ1lZmbSyU1ZWFgYMGACtVitnXHIDFxcgCoUCt956K4qKimx67L7//nscPHgQN9xwAwYPHtyt1+3NHpW+eF0iIhYrROTWioqKsGzZMoSGhuKJJ54AcP7icMSIEbBYLNKGjADg7e0tzVUh6isqlQoDBw7EwIEDbdoLCwvR0NBgs4qTyWRCY2Ojzc8tEZEzY7FCRG7j0KFDKCgoQHZ2NrKzswEAUVFRUCqV8PT0hMlkkuYPjBgxQsakRFd2//334+TJkzabTxYVFeHTTz9FcnIy7r33XhnTERH1DhYrRORyhBBobGxESUkJhgwZIm0yde7cOZSVlcHPz08qVry9vfGrX/0KXl5eMiYm6jmNRtNpKezGxkaoVCqEhYXZtO/atQuJiYmAV29v7UdEZF8sVojIJVgsFmkHeCEE3nnnHRgMBkRGRiIqKgoAkJGRAV9fX5tvogGwUCGXMXLkSOTk5NgMDautrcW6deugUqlw07z5MqYjIuo5FitE5NTOnj2L1atXQ61W48EHHwRwflPG5ORktLS02Fy0hYeHcyw/ubwfF98WiwUpKSnw8PCQVrYjInIWLFaIyGnU1dXh1KlTiI6ORmxsLADAx8cHVVVVUCqVMBqN0sXY9OnTuQkjEYB+/frhJz/5CYQQONzSLnccIqIeYbFCRA5Lr9cjICBAur9nzx7s2bMHQ4cOlYqVoKAgzJgxA7GxsTbfGrNQIbLFfxNE5IxYrBCRw7FarXj77bdRW1uLJ598EsHBwQCA1NRUNDU1ddod/sdLuhIREZFrYLFCRLLS6XTYv38/LBYLxo8fD+D8nBNvb28oFApUV1dLxUpycjKSk5PljEtERER9iMUKEfUZIQTq6+uh0Wik4V2tra3YunUrNBoNxo0bJy0zfMstt8DX15ebMBIREbkxFitE1GdWr16Nffv2YfTo0Rg3bhwAIDIyEoMHD0ZsbCysVqtUrISGhsoZlYiIiByAUu4AROR6rFYrvv32W7z99ttob//f6kNRUVFQqVQwGAxSm1KpxLRp05CTkwMPD35/QkRERP/DKwMiuiZWqxXV1dVoaWlBamoqgPMFSFFREerq6lBSUoKMjAwAQGZmJjIzM+Hp6SlnZCIiInISLFaIqMcuHq5VXFyMZcuWISAgACkpKdLyqKNHjwYAJCQkSM9jkUJEREQ9wWKFiLpt9+7d2LlzJ6677jqMGDECABAXFwcfHx/069cPJpNJ2uskMzNTzqhERETkAlisEFEnQgiUlZWhuLgYo0ePluaSmEwmNDY2oqSkRCpWPD098ctf/pIbzhEREVGvY7FCRBBCoK2tDb6+vlLbihUr0NLSgoSEBGko18CBAxEWFoa4uDib57NQISIiIntgsULk5ioqKvDJJ5/A398fjz76KIDzxUdmZiZaW1uh0WikYwMDAxEYGChTUiIiInI3LFaI3Eh5eTmOHj2KpKQkaeWuoKAgtLa2wmg0wmAwSMXJ5MmT5YxKRHbgp1I51esSEbFYIXJRVqsVlZWViIqKkoZpnTx5Ert374bBYJCKFT8/P8yZMweRkZHc54TIxSX6aPD98HS0WCy99pp+KhUSfTRXPpCI6CrwyoTIBQkhsHDhQjQ3N+Oxxx5DREQEACAtLQ0dHR0YMGCAzfHR0dFyxCQiGbCwICJnwmKFyMk1NDRg+/btEEJg2rRpAM7POYmIiIDJZEJTU5NUrMTExCAmJkbGtERERETdx2KFyImYTCaUl5cjICAAYWFhAM4P9zpw4ABUKhWmTp0qbbw4bdo0eHt7S5s3EhERETkbFitEDkwIYbMs8Lp161BQUIARI0ZIE+BDQ0MxevRoxMTE2BQmFy9DTEREROSM+JUrkQMSQmDFihX4+9//Dr1eL7UnJCTA39/fZjlhhUKBcePGITk5GSquyENEREQuhD0rRDIzGAwoLi5GR0cHhgwZAuB8AXLu3Dm0tbWhuLgY2dnZAICMjAwMHDiQmzASERGRW2CxQtTHLBYLLBYL1Go1AKCmpgaffvopfHx8kJ2dLRUi48ePh4eHB6KioqTncv4JERERuRMWK0R96LvvvsP27dtxww034IYbbgAAREVFoV+/foiOjobRaJSGeCUmJsoZlYiIiEh2LFaI7EAIgUOHDqGkpARTpkyRChBvb2+YTCacPXtWOlalUuGnP/2pXFGJiIiIHBaLFaJeYDQaodPppOWEFQoFtm7disbGRmRkZEi7xWdkZCAmJkba94SIiIiILo3FCtE1Kisrw9KlSxEUFIT58+dL7bm5uWhvb0dwcLDU5uvryyWFiYiIiLqJxQpRDxQWFuLAgQNIT09HVlYWACAiIgJCCFgsFnR0dMDLywsAMGrUKDmjEhERETk9FitEl9DW1oaSkhKkp6dLq3BVV1fjxIkTUCqVUrHi5eWFp59+Gv7+/lxSmIiIiKgXsVgh+q+Ld4sXQuDf//432tvbMWfOHERHRwMABgwYAIVCgeTkZJvnBgQE9HleIiIiIlfHYoXcXk1NDb799lsIIfDAAw8AOD9BPiEhAfX19TAYDNKxERERnBxPRERE1EdYrJBb0ev1OH36NMLCwqTeEi8vLxQXF0OhUNjMObnzzjuhUqnkjEtERETk1liskEszGAxQq9XS8K4dO3Zg9+7dyM3NlYoVrVaLW2+9FdHR0dJ+KABYqBARERHJrM+KlZdeegm//e1v8dRTT2HhwoV9dVpyIQaDATt37sS+ffvQ3NwMf39/5ObmYsSIETZFBnB+zsnSpUtRVlaGJ554AiEhIQCA5ORkVFZWIjw83Ob4nJycPnsfRERERNQ9fVKs7NmzB++88460ehJRTxkMBixevBjV1dUQQgA4P6Rry5YtOHbsGLKysmCxWDB69GgAsJkoX1FRIRUrKSkpSElJkedNEBEREVGP2L1YaWlpwb333ot3330X/+///T97n45c1M6dO20KlQuEEKitrUV+fj40Gg1GjRolDd+aPHkyvLy8EBgYKENiIiIiIrpWSnuf4IknnsDUqVMxYcKEKx5rMBig1+ttbkQAsG/fvk6FygVCCHh4eGD06NGwWCxSe2RkJAsVIiIiIidm156Vjz/+GAUFBdizZ0+3jn/ppZfwxz/+0Z6RyEk1Nzdf9nGLxcId44mIiIhcjN16VioqKvDUU0/hww8/lJaCvZLnnnsOOp1OulVUVNgrHjkZf3//a3qciIiIiJyP3YqVffv2oba2Frm5ufDw8ICHhwe2bt2Kf/3rX/Dw8LAZrnOBRqNBQECAzY2ovLwcQ4YMkSbN/5hCoUBubm4fpyIiIiIie7PbMLDx48fj8OHDNm0PPfQQBgwYgN/85jfcw4K65cSJE/jss8+QkJCAiIgI1NTU2MxdUSgUiIyMxIgRI2RMSURERET2YLdixd/fH5mZmTZtvr6+CAkJ6dROdClqtRpKpRI+Pj6YMWMGdu3a1a19VoiIiIjI+XEHe3JoiYmJeOSRRxAWFgalUokxY8ZgzJgxcsciIiIioj7Qp8XKli1b+vJ05KSKi4sREREBX19fAEBERITMiYiIiIhIDnbfZ4WoJ4qKirB8+XIsWbIEbW1tcschIiIiIhmxWCGHEhwcDF9fX4SFhXEeChEREZGb45wVcijBwcGYM2cOfH19uWIcERERkZtjzwrJ7vTp06iurpbuBwQEsFAhIiIiIhYrJK/y8nJ89NFHWLp0KRoaGuSOQ0REREQOhMPASFbh4eGIjIyEn58fAgMD5Y5DRERERA6ExQrJysvLC/fffz88PDw49IuIiIiIbHAYGPW5kpISHD9+XLqv0WhYqBARERFRJyxWqE/V1NRg+fLl+Oyzz1BaWip3HCIiIiJyYBwGRn0qLCwMGRkZaGtrQ3R0tNxxiIiIiMiBsVihPqVUKnH77bfDarXCw4M/fkRERER0aRwGRnZXVlaGbdu2SfeVSiULFSIiIiK6Il4xkl01Nzdj+fLlMBqNCAgIwODBg+WOREREREROgj0rZFf+/v4YM2YMEhMTkZGRIXccIiIiInIi7Fkhuxs5ciRGjBgBpZK1MRERERF1H68eqdedOXMGK1euhMVikdpYqBARERFRT7FnhXqV0WjERx99hLa2NgQGBmLMmDFyRyIiIiIiJ8Wvu6lXqdVqTJs2DUlJScjLy5M7DhERERE5MfasUK8QQkChUAAAUlJSkJycLN0nIiIiIroa7Fmha1ZZWYmlS5eira1NamOhQkRERETXisUKXROr1Yovv/wSpaWl2Lhxo9xxiIiIiMiFsFiha6JUKnHXXXchPT0dkyZNkjsOEREREbkQzlmhq3LxHJWwsDDcddddMiciIiIiIlfDnhXqserqarz55puoq6uTOwoRERERuTAWK9Rj+fn5qKurw4YNG+SOQkREREQujMUK9diMGTMwZMgQ3HHHHXJHISIiIiIXxjkr1C1msxkeHud/XLy9vXHbbbfJnIiIiIiIXB17VuiKamtr8dprr+HkyZNyRyEiIiIiN8Jiha5o9+7d0Ov12LZtG4QQcschIiIiIjfBYWB0RVOmTIG3tzdGjhzJnemJiIiIqM+wZ4W61N7eLv2/SqXC+PHj4e3tLWMiIiIiInI3LFaok/r6erzxxhvYsWOH3FGIiIiIyI2xWKFOTp06hZaWFhw6dAgmk0nuOERERETkpjhnhTrJy8uDp6cn0tPT4enpKXccIiIiInJT7FkhAIBer4fVapXuDx06FL6+vjImIiIiIiJ3x2KFcO7cObz33nv46quvbAoWIiIiIiI5sVgh1NXVobW1FVVVVejo6JA7DhERERERAM5ZIQBpaWm45557EBkZCR8fH7njEBEREREBYLHitpqamuDl5QUvLy8AQHJyssyJiIiIiIhscRiYG2pqasLixYvx4YcfctgXERERETksFituyGAwwGg0oqOjg/uoEBEREZHD4jAwNxQREYHZs2fD29sb/v7+cschIiIiIuoSixU3odPpYDabERISAuB8wUJERERE5Mg4DMwN6PV6LFmyBEuWLEFDQ4PccYiIiIiIuoU9K25ApVLBw+P8X/WF/xIREREROTpeuboBX19fzJ49G2azGVqtVu44RERERETdwmFgLqq5uRmlpaXSfV9fXxYqRERERORUWKy4oNbWVixZsgTLli1DSUmJ3HGIiIiIiK4Kh4G5II1Gg5CQEJjNZgQFBckdh4iIiIjoqrBYcUEeHh6466670NraioCAALnjEBERERFdFQ4DcxEtLS04dOiQdF+lUrFQISIiIiKnxp4VF2AwGLB06VLU1dXBbDYjJydH7khERERERNeMxYoLUKvVSEtLQ0dHB+Lj4+WOQ0RERETUK1isuACFQoEbb7wReXl58PHxkTsOEREREVGv4JwVJ9XW1obvvvsOQggA5wsWFipERERE5ErsWqy89NJLGDZsGPz9/REeHo5p06ahsLDQnqd0C1arFR9++CE2b96MDRs2yB2HiIiIiMgu7FqsbN26FU888QR27tyJ/Px8mM1mTJo0Ca2trfY8rctTKpXIy8uDv78/hgwZInccIiIiIiK7UIgL44j6QF1dHcLDw7F161aMHj36isfr9XpotVrodDouw9sFk8kET09PuWMQEREREfVId6/z+3TOik6nAwAEBwd3+bjBYIBer7e50Xnt7e1YvXo1jEaj1MZChYiIiIhcWZ8VK0II/PznP8f111+PzMzMLo956aWXoNVqpVtMTExfxXN4n3/+Ofbu3YuvvvpK7ihERERERH2iz4qV+fPn49ChQ/joo48uecxzzz0HnU4n3SoqKvoqnsO78cYbERwcjLFjx8odhYiIiIioT/TJnJUnn3wSX331Fb777jskJCR0+3mcs2LLarVCqeRq00RERETk3BxizooQAvPnz8cXX3yBTZs29ahQcXcdHR347LPP0NTUJLWxUCEiIiIid2LXq98nnngCH374IZYvXw5/f39UV1ejuroa7e3t9jytS1izZg2OHTuGTz/9FH24YBsRERERkcOw6zAwhULRZfuiRYvw4IMPXvH57jwMTK/X47PPPsPUqVMRGRkpdxwiIiIiol7T3et8D3uGYI/A1QsICMDDDz98yYKPiIiIiMjVcRKEgzAYDFi2bBnKysqkNhYqREREROTOWKw4iG3btqGoqAhffPEFzGaz3HGIiIiIiGRn12Fg1H1jxoxBU1MTRo4cCQ8P/rUQEREREfGqWEZCCGmol6enJ2bMmCFzIiIiIiIix8FhYDIxGo344IMPUFBQIHcUIiIiIiKHxJ4VmRw8eBAlJSWorKzEgAED4OPjI3ckIiIiIiKHwmJFJkOHDoVer0dqaioLFSIiIiKiLrBY6UNmsxkqlQoKhQIKhQLjx4+XOxIRERERkcPinJU+YjKZ8NFHH2Ht2rXcLJOIiIiIqBtYrPSR0tJSFBcX48CBAzh37pzccYiIiIiIHB6HgfWRlJQU3H777QgKCkJISIjccYiIiIiIHB57VuzIbDbDZDJJ97OzsxEXFydjIiIiIiK6Gro2E379+UHo2kxXPph6DYsVOzGbzfj000/x0Ucf2RQsREREROR8vjlUiU/3nsGqw5VyR3ErLFbspL6+HmVlZaioqEBtba3ccYiIiIjoGqw+VGXzX+obnLNiJ5GRkbj33nthNpsRFRUldxwiIiIiukqNrUbsKmkAAOwsbkBTmxGBPmqZU7kH9qz0IovFgpaWFul+bGwsEhMTZUxERERERNcq/3gNrP/decIqgPxjNfIGciMsVnqJxWLBZ599hkWLFkGv18sdh4iIiIh6yepDVVApzv+/SgGsPsyhYH2FxUovaWtrQ01NDXQ6HRoaGuSOQ0RERES9QN9hwvaielj+27NiEcD2U/Vo7uACSn2Bc1Z6ib+/P2bPno1z584hISFB7jhERERE1As2Ha+F5cIYsP8yWwU2najF7dmcl2xv7Fm5BhaLBfX19dL9wMBAzlEhIiIiciFrDldBpVTYtKmUCqzhULA+wWLlKlksFnzxxRd47733cObMGbnjEBEREVEvazWYsbmwc8+KxSqw+UQd2oxmmZK5DxYrV8lisaC1tRUmkwltbW1yxyEiIiKiXralsA4mi+jyMaPFii2FdX2cyP0ohBBd/w04AL1eD61WC51Oh4CAALnjdGI0GlFVVYW4uDi5oxARERFRN9zy2nYcPavr1rEC54d8/bhnBRe1Kzo/rUsDo7RY9eT13Q/q4rp7nc8J9ldgNVjQsv0sWndVwdJshPBRQTsyGn7XR0GtUbNQISIiInIiD4+Kx7MrDsNosXbr+K4KlYvbu/Otv8ZDiYdHxXczIV2MxcplWA0W1L19EKaqVuknUdFqgS6/DO1H6xH26GAoNSp5QxIRERFRt92ZE42saC3mfViAoroW2HOMkVIBJIf74Y17c5Ac7m+/E7kwzlm5jJbtZ20KlQsUAExVrWjZflaWXERERER09ZLD/fHNk9fjgRHnR8h0dyhXd114vQfy4vH1/OtZqFwDFiuX0bqr6tJ9e+K/jxMRERGR0/HyVOGPt2fivQeGwt/Lo9PyxFdLpVTA38sD7z0wFAtuGwgvT47CuRYsVi7D0my8pseJiIiIyLFNyIjAt8+MwdC4oF55vaFxQfj2mTGYkBHRK6/n7lisXIbKX31NjxMRERGR44vUemH53BH41eQ0KBXn55r0xIXn/GpyGpbPHYFIrZd9grohFiuX4Tu836UHMSr++zgREREROT2VUoEnxiXjk0fzcIkFwC7JKoBPH83DE+OSe204GZ3HYuUy/K6Pgmc/X5uCRUAACsCzny/8ro+SLxwRERER9TpTN5c07vw8h9260KmxWLkMpUaFsEcHI2BCHFQBakABeARoEDAhjssWExEREbmgdUeqe9w7olIqsO4IF16yB+6zcgVKjQoB42MRMD6202NmsxkeHvwjJCIiInIFVqvAqkNVl9wI8lIs/33eC7cOhJLDwHoVe1augtFoxLp16/D666/DaOSKYERERESuoKC8EedaL3Vtd76AUVyiFmloNWJ/RaN9grkxFitXQalUorCwEE1NTTh+/LjccYiIiIioF6y9xBCw83uneOKZGxPhr+l6TxaVUoG1h6v7IqZb4Rimq+Dh4YFbbrkFAJCUlCRzGiIiIiK6VkIIrDpU2eUQsGHxwfjXrGyEB3hh1ogEPPXRfuwsOWdzjMUq8M2hSjw/NR2KS3W/UI+xZ+UqJSUlsVAhIiIichGHz+pQozdI91X/3Tvl1zelYfkjwxEecH7vlIgALyybOwK/vqnzniw1egOOnNX3dXSXxmKlF5jNZjQ3N8sdg4iIiIiu0prD/xsCplQA4QFeWDFvJB4fm4zq6irs2LEDhYWFAM4P+Xp8bDI+nzcSEQFeUsGiUiqwhquC9SoWK9eovLwc//73v/HVV19BCK6vTURERORshBBYdfB/Q8CmDuqH9c+MxpDYIABARUUFNmzYgCNHjtg8Lyc2COufGY2bB53fKNxiFfjmYCWvCXsRi5Vr5O/vj5aWFtTX16O1tVXuOERERETUQ4U1zTjT1A6NhxIvz8jCv+4ZggAvT+nx0NBQDB48GLGxnbeyCPDyxGv3DMHLM7Kg8VDiTGM7Tta09GV8l8YJ9tcoKCgI9957L6Kjo+Hp6XnlJxARERGRQ/FVe+C2wf3x1IQUJIX5dXr8SnOVFQoFZg6NQU5cEF7dcAo+am4c3lsUwoH7qfR6PbRaLXQ6HQICAuSOQ0REREREvaC71/kcBtbLiouLYTAYrnwgERERERFdFouVXrR27Vp88MEH2L59u9xRiIiIiKiX7N27F3/961+xcuVKuaO4HRYrvSghIQFKpRJWq1XuKERERETUSywWCwwGA8xms9xR3A7nrPQiIQR0Oh0CAwPljkJEREREvaS9vR1tbW1Qq9Xw9/eXO45L6O51PlcD60UKhYKFChEREZGL8fb2hre3t9wx3BKHgdlJc3Mztm/fzk2BiIiIiIiuEntW7MBkMuGtt95CW1sbQkJCkJ6eLnckIiIiIrpKNTU1KC8vR3Bw8GX3W6Hex54VO/D09ERubi6io6Oh1WrljkNERERE16C0tBRr1qzBgQMH5I7idtizYidjxozBuHHjoFAo5I5CRERERNcgODgYGRkZiIqKkjuK22GxYicqlUruCERERETUC1JSUpCSkiJ3DLfEYWB2ZrVasXfvXnz33XdyRyEiIiIicirsWbGzsrIyrF69GkqlEoMGDUJQUJDckYiIiIiInAKLFTtLSEjAoEGDEB0d7RQbWxIRERGRrYKCAmzZsgVpaWmYOnWq3HHcCouVPnDnnXfKHYGIiIiIrpLJZEJzczM6OjrkjuJ27D5n5Y033kBCQgK8vLyQm5uLbdu22fuUDk0IwY0iiYiIiJxIZmYmHn30UYwfP17uKG7HrsXKJ598gqeffhrPP/889u/fjxtuuAFTpkxBeXm5PU/rsM6ePYvFixfj6NGjckchIiIiom7y9fVFZGQkAgMD5Y7iduxarPzjH//AnDlz8MgjjyA9PR0LFy5ETEwM3nzzTXue1mEVFRWhvLwcW7duZe8KEREREdEV2G3OitFoxL59+/Dss8/atE+aNAnff/99l88xGAwwGAzSfb1eb694shg5ciTa2towatQobhZJRERE5CTq6upw9uxZBAYGIj4+Xu44bsVuPSv19fWwWCyIiIiwaY+IiEB1dXWXz3nppZeg1WqlW0xMjL3iycLT0xNTpkzhqmBERERETqS4uBgrV67Evn375I7iduw+wf7HPQhCiEv2Kjz33HPQ6XTSraKiwt7xZNXe3i53BCIiIiK6Aq1Wi+Tk5E5fwpP92W0YWGhoKFQqVadelNra2kv+RWs0Gmg0GntFchhWqxX5+fnYt28ffvrTnyI0NFTuSERERER0CQMGDMCAAQPkjuGW7NazolarkZubi/z8fJv2/Px8jBw50l6ndQpKpRKNjY0wmUxcGYyIiIiI6BLsuinkz3/+c9x///0YOnQo8vLy8M4776C8vByPPfaYPU/rFCZOnIihQ4ciOTlZ7ihERERERA7JrsXK3XffjYaGBvzpT39CVVUVMjMzsWbNGsTFxdnztE4hJCQEISEhcscgIiIiois4ePAgvvvuO6SkpOCmm26SO45bsWuxAgCPP/44Hn/8cXufxqmZzWY0NDRw0hYRERGRA+ro6MC5c+fQ2toqdxS3Y/dihS6vrq4Oy5Ytg9Vqxfz586FWq+WOREREREQXycjIQL9+/eDj4yN3FLfDYkVmQUFB0lLO586dQ2RkpMyJiIiIiOhi/v7+8Pf3lzuGW2KxIjMPDw/cc889CAoKgqenp9xxiIiIiIgcBosVBxAeHi53BCIiIiK6hIaGBlRXV0Or1SI6OlruOG7F7jvYU8+UlJSgrq5O7hhERERE9F9FRUX4/PPPsWvXLrmjuB0WKw5kx44dWLp0KdatWwchhNxxiIiIiAjn56zExcUhNDRU7ihuh8PAHEh6ejq2bt2KkJAQWK1WqFQquSMRERERub2MjAxkZGTIHcMtKYQDf4Wv1+uh1Wqh0+kQEBAgd5w+0d7eDm9vb7ljEBERERHZTXev8zkMzMGwUCEiIiIiOo/FioNqbm7G2rVrYTAY5I5CRERE5NYOHz6Mt956Cxs2bJA7itvhnBUHJITARx99hKqqKmg0Gtx4441yRyIiIiJyW21tbaipqUFYWJjcUdwOixUHpFAoMHr0aOzYsQMpKSlyxyEiIiJya2lpaQgNDYWfn5/cUdwOixUHlZaWhrS0NCgUCrmjEBEREbm1wMBABAYGyh3DLbFYcVAsUoiIiIjI3XGCvYOzWq3Yu3cvPvvsM24USURERCSDpqYmnDp1ClVVVXJHcTssVhxcS0sL1q9fj2PHjuHUqVNyxyEiIiJyO4WFhVi+fDm+//57uaO4HQ4Dc3ABAQEYO3YsPDw8kJSUJHccIiIiIrfj6+uL/v37c96KDLiDPRERERER9SnuYO+ihBCwWCxyxyAiIiIisjsWK06kuroaS5YswcaNG+WOQkRERERkdyxWnEhzczPKyspQUFAAg8EgdxwiIiIit3D06FG8//772Lx5s9xR3A4n2DuR5ORkTJgwAZmZmdBoNHLHISIiInILLS0tqKiogFarlTuK22Gx4kQUCgVGjRoldwwiIiIit5KSkgKtVgt/f3+5o7gdFitO7MLqCdztnoiIiMh+goODERwcLHcMt8Q5K05q8+bNeO2113D06FG5oxARERER2QWLFSelVCphsVhQXFwsdxQiIiIil6bX61FaWoq6ujq5o7gdDgNzUnl5eYiKikJycrLcUYiIiIhc2vHjx7Fu3TpkZmZi+vTpcsdxK+xZcVJqtZqFChEREVEf8Pb2RmhoKCfYy4A9Ky7AbDajvLwciYmJckchIiIicjlZWVnIysqSO4ZbYs+Kk2tvb8frr7+OZcuWob6+Xu44RERERES9hsWKk/P29kZ4eDh8fX2h1+vljkNERERE1Gs4DMwF3HrrrdBoNPD09JQ7ChEREZHLOXHiBPbs2YP4+HjccMMNcsdxKyxWXICfn5/cEYiIiIhclk6nQ3FxMXx8fOSO4nZYrLiYkpISmEwmpKamyh2FiIiIyCUkJSXhjjvuQGBgoNxR3A6LFRdy9OhRfP755/D398eTTz7JYWFEREREvSA0NBShoaFyx3BLnGDvQtLS0hAcHIwBAwbAYrHIHYeIiIiI6JqwZ8WFeHh4YN68efDw4F8rERERUW9paWmBTqeDt7c3goOD5Y7jVtiz4mJYqBARERH1rqNHj+K9997D5s2b5Y7idlisuKjm5mZ88803qKmpkTsKERERkVNTq9XQarXw9vaWO4rb4dfwLio/Px+HDx+GTqfDfffdJ3ccIiIiIqc1ZMgQDBkyRO4YbonFiosaO3YsdDodRo8eLXcUIiIiIqKrwmLFRQUHB+Ohhx6SOwYRERER0VVjseImhBBQKBRyxyAiIiJyOidPnkRBQQFiY2MxcuRIueO4FU6wd3FWqxX79u3D22+/DYPBIHccIiIiIqfT2NiIwsJCVFVVyR3F7bBYcXFCCHz//feoqanB3r175Y5DRERE5HQSEhJwyy23cJK9DDgMzMWpVCpMnjwZ586dw7Bhw+SOQ0REROR0wsPDER4eLncMt8RixQ2kpqbKHYGIiIiIqMc4DMzNCCHQ0dEhdwwiIiIip9HW1oa6ujro9Xq5o7gdFitupKGhAUuWLMHHH38MIYTccYiIiIicwuHDh/HGG28gPz9f7ihuh8PA3IiHhwfOnDkD4HzhEhoaKnMiIiIiIsfn4eEBHx8fqNVquaO4HYVw4K/Y9Xo9tFotdDodAgIC5I7jEo4ePYro6GhotVq5oxARERGRm+rudT57VtzMwIED5Y5ARERERNQtnLPixhobGznZnoiIiIgcFosVN7Vr1y68/vrr+O677+SOQkREROTQioqK8MUXX2D37t1yR3E7LFbcVHBwMCwWCxoaGrgyGBEREdFlNDQ04PDhw6ioqJA7ituxW7FSWlqKOXPmICEhAd7e3khKSsILL7wAo9For1NSDyQnJ+Phhx/GrFmzoFAo5I5DRERE5JgMLcioW4Vn1Utx5+FHgH+kA1v/DzC0yJ3MLdhtgv2JEydgtVrx9ttvIzk5GUeOHMHcuXPR2tqKv//97/Y6LXWTQqFATEyM3DGIiIiIHJehBVh8M/yrDwPCer5NXwlseQk4sQp4cA2g8ZM3o4vr06WLX375Zbz55psoLi7u1vFcurhvmM1mHD16FFlZWexlISIiIrpg6/+dL0wuFCoXUyiBsc8BY37d97lcgEMuXazT6RAcHHzJxw0GAwwGg3Rfr9f3RSy3ZrVa8e6776K2thYeHh5c2piIiIjogn2Lui5UgPPt+xaxWLGzPptgf/r0abz22mt47LHHLnnMSy+9BK1WK904TMn+lEol0tPT4e/vD6WS6y0QERERSZqrr+1xumY9vjpdsGABFArFZW979+61eU5lZSVuuukmzJw5E4888sglX/u5556DTqeTblxxoW+MGjUK8+fPR3p6utxRiIiIiByHf+S1PU7XrMfDwObPn49Zs2Zd9pj4+Hjp/ysrKzFu3Djk5eXhnXfeuezzNBoNNBpNTyPRNfL09JQ7AhEREZHjyX3o8nNWch/q+0xupsfFSmhoKEJDQ7t17NmzZzFu3Djk5uZi0aJFHGbkBEpLS1FdXY0RI0bIHYWIiIhIXiMeP7/q18WrgQHnC5XIQecfJ7uy2wT7yspKjB07FrGxsfj73/+Ouro66bHISHaZOaLq6mosWbIESqUSKSkpCAkJkTsSERERkXw0fueXJ975xvnJ9M3V54d+5T50vlDhssV2Z7di5dtvv0VRURGKiooQHR1t8xh3THdMkZGRSEtLg7+/P7y8vOSOQ0RERCQ/jR+KY2bgqD4d/fv3R25urtyJ3Eqf7rPSU9xnpe8JIbjXChEREdFFdu3ahXXr1iEzMxPTp0+XO45LcMh9VsjxsVAhIiIishUdHY1x48YhLCxM7ihuh8UKdamlpQWbN29GXFwcsrKy5I5DREREJJuoqChERUXJHcMtcXku6tLBgwdRUFCAjRs3wmKxyB2HiIiIiNwQe1aoS8OHD8fZs2cxYsQIqFQqueMQERERycZkMsFoNMLDw4N7AvYxFivUJQ8PD9x1111yxyAiIiKSXUFBASfYy4TDwKhbOBSMiIiIiPoae1bosoQQ2L9/P7Zs2YL77rsP4eHhckciIiIi6lPDhw/H8OHD5Y7hltizQpelUChQVFSE5uZm7Ny5U+44RERERORG2LNCVzRhwgTExMTguuuukzsKEREREbkRFit0RcHBwcjLy5M7BhEREZEsysrKcPz4cfTr1w+DBw+WO45b4TAw6hEhBPR6vdwxiIiIiPpMdXU1du3ahaKiIrmjuB0WK9Rtzc3NWLp0Kd59910YjUa54xARERH1if79++P6669HWlqa3FHcDoeBUbf5+PhAp9Ohvb0dFRUVSEpKkjsSERERkd3FxMQgJiZG7hhuicUKdZtKpcKdd94JPz8/BAYGyh2HiIiIiFwcixXqkejoaLkjEBEREfUpi8UCq9UKhUIBDw9ePvclzlmhq9bY2IiGhga5YxARERHZ1d69e/Hiiy9i5cqVckdxOyxW6KocOXIEr7/+OlatWgUhhNxxiIiIiMgFsR+LrsqF4WAKhQJGoxEajUbmRERERET2MXToUAwZMgRKJb/n72ssVuiqBAYGYt68eQgODoZCoZA7DhEREZHdqFQqqFQquWO4JRYrdNVCQkLkjkBERERELox9WXTNzGYzdu7ciY6ODrmjEBEREfW6iooKbNy4EUeOHJE7itthsULX7NNPP8X69euxbds2uaMQERER9brKykps374dhYWFckdxOxwGRtds6NChqKqqQnh4uNxRiLrN2GHGwY0VOLqtEm06A3y0Ggy8oT8Gj4+B2osfjURE9D+RkZEYPnw4+vXrJ3cUt6MQDrzurF6vh1arhU6nQ0BAgNxx6BKEEDCbzfD09JQ7ClG3GDvM+Oof+1Ff0YyLPwEVCiA0xh/Tfj6EBQsREZEddfc6n8PA6JopFAoWKuRUDm6s6FSoAIAQQH1FMw5urJAnGBEREdlgsUK9qqysjBtFksM7uq2yU6FygRDnHyciIiL5cZwD9Zr29nYsW7YMJpMJCQkJGDhwoNyRiLrUpjNc0+NERORedu3ahXXr1iEzMxPTp0+XO45bYbFCvcbb2xvXX3899Ho94uPj5Y5DdEk+Wg1am7ouSAQEfLWaPk5EREREXWGxQr1q9OjRckcguqKBN/TH7m+KASg6PaZQKDDwhigA5xeP+OGHH5CRkYHAwMC+DUlERA4jJycHmZmZ3MVeBpyzQnbFuSvkiAaPj0FojH+ndoUCCIvxx+DxMQCA8vJy5Ofn44033oDRaOzrmERE5CA8PT3h6+sLLy8vuaO4HfaskF20tLRg8+bNUKvVmDx5stxxiGyovTxwxy9yrrjPiqenJxITExEYGAi1Wi09v7KyEpGRkVAq+X0PERGRPbFYIbuora1FQUEBlEolRo4cCX//zt9iE/W16upqVFdXIzs7G2ovDwybmoBhUxMueXz//v1x//33w2q1Sm16vR7/+c9/oNVqMXfuXHh7e/dFdCIiktHZs2dRXFyMsLAwDBgwQO44boXFCtlFYmIiRo4cidTUVBYq5BCMRiM+//xzNDQ0wGAwYPjw4d1+7sU9KLW1tVCr1QgICLApVMxmMzw8+JFKROSKzpw5g02bNiEzM5PFSh/jb1aym4kTJ8odgUji6emJrKws7N+/H4MGDbrq10lOTsYzzzyD1tZWqc1sNuO1115DfHw8Jk+eDB8fn96ITEREDiIsLAxDhgxBVFSU3FHcDosV6hNGoxGenp5QKDqvvkTUFxQKBUaPHo28vDx4enpe02up1WqbOSynT5+GXq9HaWkpNBoue0xE5GoSExORmJgodwy3xNmhZHeHDh3Ca6+9hsOHD8sdhdxQS0uLzap011qodCUtLQ1z587F1KlTbZa1/PLLL7Fv3z6YzeZePycREZE7YLFCdqfT6dDS0oL9+/fLHYXcjNFoxJIlS7Bs2TKbYVv20L9/f6Smpkr3KyoqcOjQIaxduxYdHR12PTcREZGr4jAwsrsRI0bAy8sLQ4YMkTsKuZnKyko0NTXBYOh6t3p7Cg8Px+TJk9HW1gY/Pz+pff/+/YiOjkZYWFifZyIioquzZ88e5OfnIyMjA9OmTZM7jlthsUJ25+npiWHDhskdg9xQfHw85s6dC4PBAF9f3z49t0ajwYgRI2zampubsWrVKlitVjzxxBMIDQ3t00xERHR1rFYrTCYTLBaL3FHcDosV6lNCCNTW1iIiIkLuKOQmwsPD5Y4gMZlMSE1NRXt7u02hUltbi5CQEJv5LkRE5Diys7ORlpZml3mPdHksVqjPmM1mLF++HKWlpXjssccc6iKSXIfJZMKqVaswduxYBAUFyR3HRnBwMO6++26bb+YsFgs++OADAMD999/PfxdERA5Io9FwtUeZcII99RkPDw9oNBoolUpUVlbKHYdc1MaNG3Ho0CEsW7bMZud5R3JxD0pDQwMUCgUUCgVCQkKkdg41ICIiAhTi4jU9HYxer4dWq4VOp0NAQIDccagX6HQ6CCEQGBgodxRyUTqdDl9++SVGjx7tNGviWywWNDQ02PSqLF68GN7e3pg4cSKCg4NlTEdERFVVVSgrK0NISAhSUlLkjuMSunudz54V6lNarZaFCtmVVqvF7NmznaZQAc73tFxcqNTX16OsrAwnT57k+GgiIgdQXl6O9evX49ChQ3JHcTucs0KyaWpqQmNjIxISEuSOQk7ObDajvr4ekZGRAM7vVu/MQkND8fjjj+Ps2bPw9/eX2jdt2gRvb2/k5ORw7DQRUR8KCQlBZmYmoqOj5Y7idliskCzKysrwwQcfwNvbG08++STUarXckciJrV+/Hvv378fNN9+MnJwcueP0irCwMJu9WFpaWvD999/DYrEgOjoaMTExMqYjInIvycnJSE5OljuGW2KxQrKIiopCQEAAAgMD0d7ezmKFrprVakVLSwssFotLz23z8vLCzTffjLKyMptC5eTJk/D19UVUVJSM6YiIiOyDE+xJNi0tLfD19XX6ITskPyEEKioqEBsbK3eUPmWxWPCvf/0Ler0es2bNQlpamtyRiIiIuoUT7Mnh+fn5sVChq3bx9ywKhcLtChUAMBqNSEhIQEBAAJKSkqT2xsZGGI1GGZMREbmWffv24eWXX8Y333wjdxS3w2FgJDuLxYLdu3cjISFBmiBNdCXffvstPDw8MG7cOCiV7vm9i7e3N6ZNmwaz2QwPj/99nK9cuRI1NTWYPn06x1gTEfUCs9mMtrY2fhEkAxYrJLv8/Hzs2rULCQkJuP/++9nbQldUU1ODnTt3AgCSkpIQHx8vbyCZXVyodHR0oLm5GUaj0WY5ZKvV6rZFHRHRtRo0aBASEhK4EqMMWKyQ7EaMGIHCwkJkZmbKHYWcREREBGbMmIG6ujq3L1R+zMvLC0888QSqq6ttxgCvWbMG586dw/jx4zkZn4ioh3x8fODj4yN3DLfEYoVkFxgYiCeffJLf+lKPDBw4UO4IDkupVKJ///7SfaPRiMOHD8NoNMJsNsuYjIiIqGd4dUgOgYUKdcfRo0c5XvgqqNVqzJs3DxMnTrRZiKCgoABbtmxBa2urjOmIiBxfbW0t9u3bh5KSErmjuB1eIZJDKSsrw7Jly9DR0SF3FHIwJ0+exOeff4733nuPBctVCAwMxMiRI6U5YVarFd999x22bt2KEydOyJyOiMixlZSUYNWqVSgoKJA7itthsUIOw2q1YtWqVSgqKsKOHTvkjkMORq1Ww8/PDwkJCdxEtJdMmDABycnJyMrKktrOnDmD4uJiOPAWXEREfarN1IYNrRuwPn49/tjyR0z4bALeOvgW2kxtckdzC32yKaTBYMDw4cNx8OBB7N+/H9nZ2d16HjeFdD8nT57EyZMnMXbsWPj5+ckdhxxMa2srNBqNzepX1LuWLl2KkpISTJgwAaNGjZI7DhGRrNpMbXhw3YMoPFcIK6xSuxJKpAWnYfFNi+HjyYn3V8OhNoX89a9/bTPZk+hSUlNTccstt7BQIcnFE8J9fX1ZqNiR1WpFaGgoNBqNzep8ra2taG9vlzEZEZE8lh5b2qlQAQArrCg8V4ilx5bKlMx92L1YWbt2Lb799lv8/e9/v+KxBoMBer3e5kbuzWq1XvkgclmnT5/Ga6+9hrKyMrmjuAWlUombb74Zv/jFL6DVaqX2LVu24J///Cf27dsnYzoior73+cnPOxUqF1hhxecnP+/jRO7HrsVKTU0N5s6diw8++KBba1O/9NJL0Gq10i0mJsae8ciBtbW1YdWqVVi6dCnHzrspIQS2bdsGvV6PI0eOyB3HrXh6ekr/L4RATU0NTCYTgoODpXar1cp/m0Tk8ura667pcbp2ditWhBB48MEH8dhjj2Ho0KHdes5zzz0HnU4n3SoqKuwVjxyc2WzGwYMHUVZWxp8DN6VQKPCTn/wEN9xwAyZPnix3HLelUCjw0EMP4eGHH7bZgHPPnj34z3/+g6KiIvnCERHZWZh32DU9Tteux8XKggULoFAoLnvbu3cvXnvtNej1ejz33HPdfm2NRoOAgACbG7mngIAATJkyBbNnz7bZF4Lci1qtxo033sh5KjJTKBSIiYmRlj0WQmDv3r04e/Ysmpqa5A1HRGRHM1JnQHmJy2UllJiROqOPE7mfHq8GVl9fj/r6+sseEx8fj1mzZuGbb76RfrkBgMVigUqlwr333oslS5Zc8VxcDYzI/ZSUlKCjowPp6elyR6HLaGlpQUFBAfLy8qRhYyUlJTh58iRGjBhhM+eFiMhZcTUw++nudb7dli4uLy+3mSBfWVmJyZMn4/PPP8fw4cMRHR19xddgsUIXGI1GCCGg0WjkjkJ21NrairfeegstLS248847MWjQILkjUQ988MEHKC4uxvDhw3HTTTfJHYeIqFe0mdqw9NhSfH7yc9S11yHMOwwzUmfggYwHWKhcg+5e59ttbMWPh+5cWIo2KSmpW4UK0QUnTpzA6tWrMXDgQF4AuTgvLy9kZWWhqKgIAwYMkDsO9dCIESMAAMOHD5fampqaUF1djdTUVCiV3IeYiJyPj6cPHhv8GB4b/BgOHTqEY8eOYUz4GBYqfYQDwcnheXp6oqWlBUVFRdJQQnJNKpUKEydOxNixY21WpCLnkJKSgpSUFJu277//Hnv27MGQIUNw2223yZSMiKh3nDhxAoWFhYiIiEC/fv3kjuMW+qxYiY+P5zKXdFWSkpIwY8YMpKWlsVBxUc3NzfDz85PmuLFQcR1+fn7w8vKy2WTSZDKho6MD/v7+MiYjIuq5IUOGIDIykvMq+5Dd5qz0Bs5ZIXJ9ra2tePvttxETE4PbbruN85JckNFohKenp1SM7t69G+vXr8eoUaNw4403ypyOiIjk0N3rfA4gJqcihEBpaSl76VxIRUUFWltbUVtba7N6ILkOtVpt83d79uxZWK1WaS4jcP7fNv9dExHRj7FnhZyGEAKffvopTpw4wZWiXMzZs2fh4eGBiIgIuaNQHzlz5gzCw8OhVqsBAMXFxVi3bh2uv/56ZGVlyZyOiOjSrFYrzp49i3PnzmHw4MFyx3Fa7Fkhl6NQKNC/f3+oVCo0NzfLHYd6UVRUFAsVNxMdHS0VKgCwZ88e1NXV4ezZszKmIiK6straWrz//vtYvXo1TCaT3HFcHlcDI6cyYsQIZGZmIigoSO4odA3a29uxdu1aTJw4kZOsCQBw++23IyYmxmbJ6sbGRmzfvh15eXkIDQ2VMR0R0f9EREQgIiICYWFh6Ojo4KIwdsZhYETU51asWIEjR44gJiYGDz30EOeqUJfWrVuHXbt2ISkpCffdd5/ccYiIJEII/u66RhwGRi6vqakJBw4ckDsGXYWxY8ciOjoaU6ZM4Yc9XVJGRgbS0tKQl5cntZlMJhw+fBgWi0XGZETk7vi7q+9wGBg5JZ1Oh9dffx0WiwVRUVEICwuTOxL1QEhICB5++GF+2NNlxcbGIjY21qbtwIEDWLNmDfbu3YuHHnpIpmREROe1tbUBAHx8uJu9vbBnhZySVqtFUlIS4uLi5I5C3dTR0YH6+nrpPgsVuhoqlQp+fn7IyMiQ2oQQaGpqki8UEbml/Px8vPzyy9i7d6/cUVwae1bIad155502G82R4xJC4Ouvv0ZRURGmTZtmc6FJ1BM5OTmdljYuLS3FBx98gEGDBmHatGn8TCCiPhEcHAwAaGhokDmJa2OxQk7r4mVPybGZTCYYDAZYLBZotVq545CT8/Cw/dVVVlYGIUSnzSc5AZaI7GngwIFITk7m7zU742pg5PQsFgv27NkDPz8/ZGZmyh2HLsFqtaKyshLR0dFyRyEXVFtbC41GI1006HQ6LF26FMOGDcPw4cNZtBARORiuBkZuY//+/Vi/fj3Wr18Po9Eodxy6yMXfhSiVShYqZDfh4eE2327u3bsX586dw8mTJ1moEBE5MQ4DI6eXnZ2NQ4cOITs7u9PwEJKPEAJfffUVwsLCMGrUKF4wUp8aPXo0AgMDERISIrWZTCasW7cOubm56N+/v4zpiMhVGAwGfPvttygrK8O8efOgUqnkjuRyeGVHTs/Dw4MbCzqgkpISHDp0CEqlEikpKYiIiJA7ErkRT09P5Obm2rQdOnQIBQUFOH36NH72s59BqeTgAiK6Nmq1GidPnkRLSwvKysqQmJgodySXw2KFXAIn1TqehIQE3HrrrTAajSxUyCHExMQgKysLUVFRUqEihMDRo0eRlpYGT09PmRMSkbNRKBSYNGkSfHx8Ou0LRb2DE+zJpZSXlyM/Px9Tp05FZGSk3HGIyMGVlZVh8eLFCAgIwM9+9jMO4SAi6iOcYE9uaffu3Thz5gy2bNkidxS3JITAoUOHYLFY5I5C1C1GoxFBQUFISUmxKVT0er2MqYiI6AIOAyOXMn78eHh5eWHs2LFyR3FLBw4cwNdff409e/bgoYce4pwAcngpKSlISkqCyWSS2vR6PV599VXEx8dj1qxZHB5GRFfU1NSEEydOwN/fHwMHDpQ7jkvhlQS5lKCgINxyyy3w8/OTO4pb8vX1hbe3N1JSUliokNNQKpXQaDTS/dLSUgghYLFYbAoVBx41TUQyO3nyJNavX4/du3fLHcXlsGeFXJrRaORO930oNTUV8+bNY7FITi0rKwsxMTE2+zaZzWa89957SE9Px8iRI9nbQkQ2UlNTceLECaSlpckdxeWwWCGXZDAYsGHDBpw4cQLz58+3+daUep/ZbJb2uPH395c5DdG1CwoKsrl/7Ngx1NTUoL29Hddff71MqYjIUQUGBuKBBx6QO4ZLYrFCLsnDwwMlJSVoaWnB8ePHkZ2dLXckl3Xo0CFs2bIFM2fORL9+/eSOQ2QXAwcOlJZEv3gifn5+PlJSUhAXF8cl04mI7IDFCrkklUqFW265BQAQHx8vbxgXZrVasX37djQ2NuLkyZMsVshlqVQqDBo0yKatoqIC33//PXbt2oWf//zn8PHxkSkdETkKs9mMsrIyxMfHcyn0XsJihVwWixT7UyqVeOihh7Br1y7ccMMNcsch6lP+/v4YOnQolEqlTaFy8uRJxMbGwsvLS8Z0RNTXhBB4/fXX0dTUhNmzZ/M6pJewWCG3YDQa0dbWhsDAQLmjuBxvb28uFU1uKTAwEFOnTrVpa25uxieffAKVSoX58+dzQ2MiN6JQKBAXFwez2YzW1la547gMFivk8srKyrBixQoEBQXhwQcf5LjyXnDixAl4enoiKSlJ7ihEDqW5uRmhoaHw8vKyKVRaWlq4Sh6RG5gyZQrUajWvNXoRixVyeUFBQWhvb4dKpUJLSwtXq7pGjY2N+PLLL2E0GnHfffexYCG6SP/+/fHYY4+hvb1darNYLHj77bcRGBiI6dOns4eXyIVx9dHex2KFXF5AQADuv/9+9O/fX1pel66en58fBg0ahLq6OiQkJMgdh8jhKBQKmzkslZWVaG9vh0KhsPmyRAjBb1+JXNjFy/rT1VMIB96SV6/XQ6vVQqfTcdwvkYPhhzBR97W0tKChoQFxcXFS2/LlyxEaGopRo0bB19dXxnRE1JsqKiqwZs0aeHt7c++Vy+judb6yDzMRyU4IgVOnTtkM0aDu0ev1NvdZqBB1n5+fn02hUllZiVOnTmH37t2wWq0yJiOi3ubr64vq6mqUl5fDaDTKHcfp8WqD3MratWuxZ88ejBgxApMnT5Y7jtNobGzE22+/jfT0dNx8883w9PSUOxKRU+vXrx/uuece1NfX2wwN++GHHxAcHIzU1FQOESNyUsHBwZg5cybi4+OhVqvljuP02LNCbiU1NRUqlYq9Aj1UWloKg8GA+vp6KJX82CC6VgqFAqmpqRg5cqTU1tLSgo0bN+Ljjz9GZWWljOmI6FplZGRwo9hewis2civJycl46qmnuCJYDw0ZMgSBgYEICgrijrxEdqJUKjF8+HDU1tYiKipKai8rK0NISAiXPiYit8RihdwOC5Wrw5W/iOzLx8cHEydOxMXr3lgsFqxYsQJtbW144IEHEBsbK2NCIuqJEydO4OjRoxgxYoTNFxDUMxzPQW5Lp9Nh8+bNcOAF8WSl0+nwxRdfoK2tTe4oRG7l4rkqLS0t0Gq18Pb2Rv/+/aX2trY2fnYRObijR4/iyJEjOH78uNxRnBp7Vsgtmc1mvPPOO2hra0NoaCgGDRokdySHs3LlSpSUlMBkMuHuu++WOw6RW9JqtZgzZw5aWlps5tp9+umnaGtrw+23385vbIkcVFZWFrRaLTIyMuSO4tRYrJBb8vDwwPDhw1FcXIzQ0FC54zikSZMmYdWqVZg0aZLcUYjc3sXzVZqbm1FVVQWz2cxhrUQOLCUlBSkpKXLHcHrcFJLcltVqhUKh4PKgl8EdtokcU0dHB8rLy5Gamiq1rVu3DmazGaNGjUJQUJCM6YiIroybQhJdgVKp5IX4j+j1ejQ1NUn3+edD5Ji8vLxsCpW2tjbs3bsX+/btQ3Nzs4zJiOhiQghUV1fj8OHDckdxWhwGRm7PYrFgz549aG1txfjx4+WOIxur1YoVK1agtrYWM2fORGJiotyRiKibvL29cd999+HkyZOIiYmR2o8cOQIhBDIyMrjsOJEMGhoa8Pbbb0OlUiEtLY2bRF4FFivk9s6ePYv169dDoVBg8ODBbjuHpaOjAxaLBVarFVqtVu44RNQDCoUC8fHxiI+Pl9qsVivy8/Oh1+thsViQnZ0tWz4idxUSEoLw8HAEBQWhra2NxcpVYLFCbi82NhY5OTno378/goOD5Y4jGx8fHzz00EOora1FSEiI3HGI6BpZLBbk5OTg2LFjyMzMlNpramqgVqs5r4WoDygUCjz22GMcVn0NOMGeyM1xEj2Ra/vxv/ElS5agrKwMt99+OwYPHixjMiJyZ5xgT3SVhBBus9ma1WrFRx99hD179rjNeyZyNxcXKiaTCSqVSho2doHBYIDVapUhHZH7MBqNaG9vlzuG0+EwMKKLVFRUYP369Rg6dKhbjO8+evQoTp06hdLSUqSmpnKuCpGL8/T0xH333Qe9Xm/zTWZ+fj5Onz6NKVOm2KwyRkS947vvvsN3332HUaNGYdy4cXLHcSosVoguUlFRgbNnz6KjowODBw92+eFRmZmZaGlpga+vLwsVIjdycaFisVhw6tQp6PV6Tv4lspOAgABYLBbU1NTIHcXpcM4K0UXMZjM2b96MvLw8mx2jiYhcmclkwokTJ5CZmSl9SbN7926cOXMGo0aNQkREhMwJiZxbR0cHmpubERoa6vJfhHYX56wQXQUPDw9MnDjRpQsVIQQOHDjA8elEJPH09MSgQYOkiyir1YoffvgBhw8fRkVFhczpiJyfl5cXwsLCWKhcBRYrRJfR2toqd4Ret337dqxcuRIff/wxJ9UTUZeUSiVmzpyJIUOG2KwYVlZWhr1798JkMsmYjojcCYsVoi4IIbBmzRr885//RHV1tdxxelVgYCDUajXS09P5DQ8RXVL//v1x2223wdPTU2r77rvvsHr1amzdulXGZETOyWQyYf369XjrrbdY8PcAJ9gTdUGhUKC1tRUWiwWFhYWIjIyUO1KvGTRoEOLj4116qBsR9T4hBFJSUtDY2IihQ4dK7Xq9Hh0dHQgPD5cxHZHj8/DwwLFjx6DX61FSUsKV97qJE+yJLqGxsRFNTU1ISEiQO8o1E0LAYrHAw4PfTxDRtfnxJpNr1qzBnj17MHr0aC7JSnQFBw8ehFqtRmJiIjQajdxxZNXd63xeuRBdQlBQEIKCguSO0St++OEHHDx4EDNnzkRoaKjccYjIif14+KjRaIRCoUBcXJzUZjabAYBfkBD9yMVzwKh7+ClC1A1GoxH19fXo37+/3FF6zGQyYdeuXdDr9SgtLWWxQkS9atq0aRg7dqzNXk0FBQXYtm0bxo0bh5ycHBnTEZGzs/sE+9WrV2P48OHw9vZGaGgo7rzzTnufkqhX1dXV4d///jeWL18Og8Egd5we8/T0xNy5czF+/Hjk5ubKHYeIXFBgYKBNj8uxY8fQ0tICi8UiYyoix9Ta2oqCggIcPXpU7ihOwa49KytWrMDcuXPx4osv4sYbb4QQAocPH7bnKYl6XXBwMDw9PWGxWNDY2OiUk+39/Pxw/fXXyx2DiNzE/fffj6NHj2LAgAFSW3FxMXbv3o2RI0ciNjZWxnRE8iosLMQ333yDqKgoDBw4UO44Ds9uxYrZbMZTTz2Fl19+GXPmzJHa09LS7HVKIrtQqVT4yU9+Aq1W61Tjrw8cOICQkBDExMTIHYWI3IxKpUJWVpZN2w8//ICioiJotVoWK+TWUlJSEBUVhdTU1E4LVlBndrvyKigowNmzZ6FUKjFkyBBUV1cjOzsbf//73y9ZRRoMBpthNnq93l7xiHokJCRE7gg9UlVVhW+++QZCCMydOxf9+vWTOxIRubnJkycjICAAI0aMkNqamppw7Ngx5OTkwMvLS8Z0RH3H398fjzzyiNwxnIbd5qwUFxcDABYsWIDf/e53WLVqFYKCgjBmzBicO3euy+e89NJL0Gq10o3fCJMjKioqcviNIoODg5GRkYG0tDSnHLZGRK4nNDQUt956q80qizt37kR+fj6++uor+YIRkUPrcbGyYMECKBSKy9727t0Lq9UKAHj++ecxffp05ObmYtGiRVAoFPjss8+6fO3nnnsOOp1OulVUVFzbuyPqZTt27MCyZcuwbt06OPAWRdBoNLjzzjsxffp0di8TkcOKiopCWFgYhg0bJrWZTCacOXNGxlREfcNqtaKiokJa6pu61uNhYPPnz8esWbMue0x8fDyam5sBABkZGVK7RqNBYmIiysvLu3yeRqNx+w1yyLFlZmZi27Zt6N+/P6xWK1QqldyRbOh0Omn5UIVC4VRzbIjI/QwaNAiZmZk2bQcOHMCaNWswaNAgriBKLu2dd95BTU0N7rvvPiQlJckdx2H1+EomNDS0W/s05ObmQqPRoLCwUFqFyGQyobS01GbjKCJnotVq8cwzzzhkUV1dXY3//Oc/GDp0KCZOnAil0u4rkxMRXbMf9/62tLRAqVQiKipKahNCwGQyQa1W93U8Irvp378/dDqd9AU/dc1uX7sGBATgsccewwsvvICYmBjExcXh5ZdfBgDMnDnTXqclsjtHLFSA8/PEzGYzzp07x6FfROS0xo0bh6FDh9p81paWluLTTz/FiBEjMGbMGBnTEfWeiRMnYurUqQ43SsPR2HWMyMsvvwwPDw/cf//9aG9vx/Dhw7Fp0yabyXVEzkqn02Hbtm0YP348vL295Y6DkSNHIjQ0FNHR0SxWiMip+fv729w/cuQIOjo60NraKlMiot7nCNcOzkAhHHiWsF6vh1arhU6nQ0BAgNxxiGy8++67qKysRF5eHiZNmiR3HCIilyWEwMmTJxEeHi594anT6fD1119j+PDhSE1NlTkh0bWxWq1uN3y7u9f57vWnQtSLxo0bh9jYWFl3n62trcVXX31lsz8REZGrUSgUSEtLsxmZsWvXLhQXF2Pnzp0yJiO6NlVVVVi0aBGWLl0qdxSHxaWCiK5ScnIykpKSZBtyJYTAF198gZqaGqhUKtx6662y5CAiksPw4cMBwGYVJZPJhB9++AE5OTnw8/OTKxpRt/n4+KC8vBwKhQIdHR3cHLULHAZG5MQqKirw7bffYtasWfD19ZU7DhGRrPbt24dVq1YhJCQETzzxBOfvkVM4fPgwYmNjpa0H3AWHgRH1EYvFgl27dmH58uV9vlFkTEwMHn74YRYqREQAAgMDERUVhdzcXKlQEUKgoqLCoTfyJfc2aNAgtytUeoLDwIiuUXt7OzZu3AiTyYTCwkIMGDDAruc7d+4c1Gq1NMSB3xwSEZ2XlJSExMREm8KkvLwcixcvRnR0NB5++GF+ZhI5GRYrRNfIz88P48ePh0qlsvuKNCaTCZ988glaW1sxa9YsREdH2/V8RETORqFQ2BQkDQ0N8PT0REREhE27yWSCp6enHBGJOikuLsbRo0eRnZ2NmJgYueM4FBYrRL3gwkRPe2tra5P+PzAwsE/OSUTkzHJycpCeng6LxSK16fV6vPHGGxg0aBBuuukmbspHsjt06BAOHjwItVrNYuVHWKwQ9TIhBCwWCzw8ev+fl1arxSOPPILGxkaudENE1E0/3nzvyJEjMBgMqKurY6FCDiEzMxNqtdruQ8mdEVcDI+pFVVVVWLNmDfr164ebb765115XCMFx1kREvUQIgdLSUnh6ekrDac1mMz755BMMHjwYGRkZbrdBH1Ff42pgRDLo6OjAmTNncOjQIXR0dPTKa5rNZixevBiHDx/uldcjInJ3CoUCCQkJNvP+Dh8+jKKiIuTn53PlMCIHwmFgRL0oISEBU6ZMQXp6eq9t7LRnzx6Ul5ejvr4eKSkp3DCKiMgOUlNTMXbsWPj5+UlDw4QQ2LlzJ9LT0zlPkPrEuXPnUFVVhYEDB8odxWGwWCHqZdddd12vvt7w4cPR0dGBmJgYFipERHbi6+uLMWPG2LRd2Hh38+bN+OUvfwm1Wi1TOnIHTU1NeO2116BUKpGUlMTf+f/FYoXIjs6dO4egoKBrmm+iVCoxbty4XkxFRETd4eHhgcTERGi1WptCpbKyEpGRkZzXQr0qMDAQERER8Pb2RmtrK4uV/+IEeyI72bRpE3bs2IFbb70V2dnZPXqu2WzGkSNHMHjwYE6sJyKSmdVqlQqT5uZmLFy4EIGBgXjkkUc6rTRGdC0u/llzdZxgTyQzjUYDq9WKioqKHj93w4YNWLlyJVauXGmHZERE1BMXXzzW1NRArVbDz8/PplAxm81yRCMX4y6FSk9wGBiRnQwfPhxRUVGIj4/v8XNDQ0Ph4eGB9PT03g9GRERXLTk5Gc888wxaW1ulNrPZjH//+9+Ij4/HpEmT4OPjI2NCcgUWiwUmk4lDwcBihchuPDw8rqpQAYChQ4ciLS0N/v7+vRuKiIiumVqttpnDUlxcDJ1Oh+LiYmg0GhmTkSvYuXMnNm/ejGHDhmHChAlyx5EdixWiPmAymVBSUoLU1NRLHmOxWABAWjKThQoRkXNITU3FI488gpaWFukzHAC++uorxMTEYPDgwfDw4CUXdY+vry+MRiPOnj0rdxSHwH85RHbW3t6Ot956C83NzXj00UcRERHR5XGbNm1CeXk5pk+fzvX8iYicTFRUlM39iooKHDx4EEeOHEFaWhr8/PxkSkbOJjU1FXPnzkW/fv3kjuIQWKwQ2Zm3tzeio6Nx9uxZtLW1dXlMW1sbCgoK0NHRgerqahYrREROLjw8HJMmTUJbW5tNoXLgwAFERUUhLCxMxnTkyDQaDfr37y93DIfBpYuJ+kBrays0Gs1lhwE0NTWhsLAQw4cP78NkRETUV1paWrBw4UJYLBY8/vjjLFjIrXHpYiIH4uvre8XxyoGBgSxUiIhcmNFoREpKCmJjY20KldraWmneIhFwfh7r5s2b8d5778FgMMgdR1YcBkbUh4wd7chf+j5K93wPQ7Menr5+GDD6Roy5+z6ovbixGBGRKwsODsbdd99tU5hYLBZ8+OGHAID77rsP4eHhcsUjB6JUKnH48GE0NjaiuLjYrbcyYLFC1EeMHe1Y8uzT0FWdxYU96Y0tzTi4ZiXOHjmIn/z5ZRYsRERu4OIVwxoaGnBhRH5wcLDUbrFYbI4j96JQKDB69GgAQFxcnMxp5MVihaiP7Fv9FZqrK6VC5QIFgHMVZdi3+ivkTb9HjmhERCST8PBwPP3006ivr7cZLvzBBx/A29sbEydOtCliyH1kZ2fLHcEhcM4KUR85tGEdLrWehRAChzas6+NERETkCFQqlc2y9g0NDSgrK8PJkyfh6ekpYzIi+bFnhaiPtDaeu6bHiYjIPYSEhODxxx/HmTNnbDYI3rx5M7y8vJCTkwONRiNjQuorHR0dKCoqglKpREZGhtxxZMFihaiP+AYFo+Vcw2UfJyIiAoCwsDCbFcNaW1uxY8cOWCwWREVFITY2VsZ01FcKCwvx1VdfITIy0m2LFQ4DI+ojWRNugkLx4xkr5ykUCmRNuKmPExERkbPQaDSYMmUKsrKyEBMTI7WfOnUKZ8+elTEZ2VNycjLCw8ORmJgIq9UqdxxZcFNIoj5i7GjHJwueRV1psc3cFYVCgbD4RNy94K9cDYyIiLrNarXi1VdfhV6vx913340BAwbIHYmo27gpJJGDUXt54+4Ff0XezJ/ALzgECoUCfsEhyJv5ExYqRETUYwaDAQkJCQgICEBycrLU3tjYCKPRKGMyot7DnhUiIiIiJ2Y2m22WPV6yZAlqampw55132hQx5LyEEKitrUVwcLDLrBDHnhUiIiIiN3BxodLR0QGdTgeDwYDw8HCp3V3nO7iKxYsX46233kJJSYncUfocVwMjIiIichFeXl6YP38+qqqqbL6tXrNmDRobG3HjjTciKipKxoR0NcLDw1FZWYmmpia5o/Q5FitERERELkSpVNoUJEajEYcPH4bRaMTo0aNlTEZXa+zYsZg0aZLLDAHrCRYrRERERC5MrVZj3rx5OHr0qM3+LPv374der8fQoUPh6+srY0K6Enf++2GxQkREROTiAgMDMWrUKOm+1WrF1q1bodPp4Ovri6FDh8qYjnpCCHHJfdtcESfYExEREbmhCRMmICkpCYMHD5bazp49i5KSEjjwYrFuq66uDsuWLcOSJUvkjtKn2LNCRERE5GaUSiUyMzORmZlp075p0yYUFxdjwoQJNj0xJD8vLy8UFRUBAFpaWuDn5ydzor7BYoWIiIiIYLVaERISgjNnzmDgwIFSe2trK5RKJby9uXmxnPz9/XHbbbchOjrareawcFNIIiIiIpKYTCabVafWrFmDAwcOYPLkycjNzZUxGbkSbgpJRERERD12caEihEBVVRVMJhOCg4OldqvVynkt1Cc4DIyIiIiIuqRQKPDwww+jvLzcZtnjPXv24PDhwxg7diySk5NlTOh+KioqcOzYMaSnp9v8nbgqFitEREREdEkKhQJxcXHSfSEE9u3bh7q6OjQ2NsqYzD0dOHAABQUFsFgsLFaIiIiIiC6mUCjwwAMPYN++fTbLHpeUlODUqVMYPnw4tFqtjAldW0ZGBiwWC1JTU+WO0idYrBARERFRj/j5+WHMmDE2bTt27MDp06dhsVgwZcoUmZK5vqSkJCQlJckdo8+wWCEiIiKia3bdddfBarVixIgRUltTUxOqq6uRlpbmVruuU+9hsUJERERE1yw1NbXT0KQffvgBu3fvRnZ2Nm6//XaZkrmmlpYWnD17FmlpaXJHsSsuXUxEREREduHj4wMvLy9kZmZKbSaTCc3NzTKmcn4tLS145ZVX8Mknn6CtrU3uOHbFnhUiIiIisosxY8YgLy/PZu+WAwcOYP369Rg5ciRuvPFGGdM5Lz8/P0RGRkKpVKK5uRk+Pj5yR7IbFitEREREZDdqtdrm/pkzZ2CxWODr6yu1XdhgkvNaum/OnDnw8HD9S3nXf4dERERE5DDuuOMODBs2DOHh4VJbSUkJ1q1bh+uvvx5ZWVkypnMe7lCoAJyzQkRERER9LDo62qbHZe/evairq8OZM2dkTOWcrFYrDAaD3DHsxj1KMiIiIiJyWLfddhuio6MxYMAAqa2pqQnbt2/HiBEjEBoaKmM6x1VQUICNGzciKysLkydPljuOXbBnhYiIiIhk5eXlhZEjRyI4OFhq27VrF/bt24e1a9fKmMyxeXt7o62tDWVlZXJHsRu7FisnT57E7bffjtDQUAQEBGDUqFHYvHmzPU9JRERERC4gPT0daWlpyMvLk9pMJhMOHz4Mi8UiYzLHkZSUhAceeABz5syRO4rd2LVYmTp1KsxmMzZt2oR9+/YhOzsbt9xyC6qrq+15WiIiIiJycrGxsZg1axaSk5OltoMHD+KLL77A0qVLZUzmONRqNRISEqBSqeSOYjd2K1bq6+tRVFSEZ599FllZWUhJScFf//pXtLW14ejRo/Y6LRERERG5KKVSCV9fX6Snp0ttQgjodDoZU5E92W2CfUhICNLT07F06VLk5ORAo9Hg7bffRkREBHJzc7t8jsFgsFnNQK/X2yseERERETmZnJycTksbl5WVYenSpRg0aBCmTZvmdnu1WK1W/PDDDzh16hRmzZoFLy8vuSP1Krv1rCgUCuTn52P//v3w9/eHl5cX/vnPf2LdunUIDAzs8jkvvfQStFqtdIuJibFXPCIiIiJyQh4eHjZ7jJSWlkIIAU9PT5tC5cJGk65OqVTi4MGDKCsrQ1FRkdxxep1C9PBvcsGCBfjjH/942WP27NmD3NxcTJs2DSaTCc8//zy8vb3x3nvv4euvv8aePXvQr1+/Ts/rqmclJiYGOp0OAQEBPYlJRERERG6itrYWGo0GWq0WAKDT6bB06VIMGzYMw4cPd/nelv3798NkMiE9PR3+/v5yx+kWvV4PrVZ7xev8Hhcr9fX1qK+vv+wx8fHx2LFjByZNmoTGxkabACkpKZgzZw6effbZK56ru2+CiIiIiOiCTZs2Ydu2bYiPj8fs2bPljkNd6O51fo/nrISGhnZrY562tjYA57umLqZUKmG1Wnt6WiIiIiKibrnhhhsQEBBgc81qNpuxdu1aDB06tMsRPuSY7DZnJS8vD0FBQZg9ezYOHjyIkydP4le/+hVKSkowdepUe52WiIiIiNycp6cnhg4divj4eKnt0KFDKCgowMcff+ySX5ybTCacPHkSx48flztKr7JbsRIaGop169ahpaUFN954I4YOHYrt27dj5cqVGDx4sL1OS0RERETUSVRUFAYNGoSRI0dKI3+EEDhy5AhMJpPM6a5dYWEhPvroI5fbgN1uSxcDwNChQ7F+/Xp7noKIiIiI6IoiIiJw55132rRVVFRgxYoVCAgIwM9+9jOn3lwxOTkZQUFBiIuLg8Vicer3cjG7FitERERERI7KYDAgMDAQiYmJNhf3zc3NTrOq1gVeXl742c9+JneMXtfj1cD6ElcDIyIiIiJ7slqtMBqN0maKzc3NePXVVxEfH4+7774bnp6eMid0Td29zrfbnBUiIiIiIkenVCptdn0vKSmB1WqF2Wy2KVQc+Pv9ThobG11iHg7AYWBERERERJKsrCzExMTYbFRuNpvxn//8B+np6cjLy3Po3paPPvoIJ0+exF133YX09HS541wzFitERERERBcJCgqyuX/s2DFUV1ejtbUVo0aNkilV9wQHB0OhUKChoUHuKL2CxQrR/2/vzmOjKhc3jj9nWu060wIDBaS0DT+EBsRCMRMEZLVAILIYLkTTAKkmxEIgmLiRCBoMN7fiRgKCuUGQCL2ECDEqWkSWsERWFxQQtZYwSFrDbacLlFl+f3ipTrhwi7TzHuZ8Pwl/zHuGztO8NJyn73nPAQAAuIl+/frJsixFIpGojfgVFRXq3bu3cnJyZFmWwYR/GDp0qEaMGBF1adudjD0rAAAAwE0kJCTovvvu04ABA1rGzp07pwMHDmjjxo1qbGw0mC5aenp63BQViZUVAAAA4Ja53W4VFhbKsiylpaW1jP/www/Kzs62RWGIRCK2WfH5qygrAAAAwC3KzMzUpEmTosYCgYA2b96shIQElZaWKiMjw0i2S5cuaefOnWpoaNDs2bONZGgrlBUAAACgDQQCAXm9XiUlJUUVlYaGhqjVl/aWlJSk7777TpJUW1trrDS1BR4KCQAAALSRSCSipqYmpaamSpJCoZDefPNNZWZmatq0acrMzIxJjiNHjqhbt27q3r27LS8Fa+15PisrAAAAQBuxLKulqEiS3+9XY2OjIpGI0tPTY5Zj8ODBMfus9kRZAQAAANpJdna2Fi5cqJqaGiUm/nHqvWnTJnm9Xj344IMxvUTsTsOtiwEAAIB2lJ6ertzc3JbXFy5c0JkzZ3To0CGFw+F2+9yLFy9q9+7d+uWXX9rtM9obKysAAABADHXt2lUzZ85UTU2N3G53y/jBgwfVsWNH3XvvvW2yz+To0aM6fPiwAoGAcnJybvvrmUBZAQAAAGLIsiz16dNHffr0aRmrr6/X559/rlAopJKSEvXo0eO2Pyc/P1/19fXq1avXbX8tUygrAAAAgGEul0s+n08XL17UPffc0zJeVVWljh07/qXN+Xl5ecrLy2vLmDFHWQEAAAAMS01N1cMPPxz11PlQKKStW7eqoaFBxcXFd+ylXLeDDfYAAACATfx5r0p9fb08Ho+Sk5OjVluampp0K49KvHz5ss6ePdumOWOFlRUAAADAhjIyMlRSUqJAIBB12+Py8nI1NTXpkUceiSox/83ly5dVVlamcDisp59+OqbPemkLlBUAAADAxv58x7BAICC/369QKBQ1fiPJycnq2rWrmpubVVtbe8eVFStyK2tIMVZXV6eMjAzV1tbK4/GYjgMAAAAY19TUpKqqqqi7iX366acKBoMaOnSoMjMzo95/5coVJSUlxTjlzbX2PJ+VFQAAAOAOkpKSElVUGhsbdeTIEQWDQfXv3/+6snJXMKjqf/5T/y7/l4LV1Urs3FmZM/6mTrNmyZWWFuP0t4aVFQAAAOAOFolEVFlZqdOnT2vcuHEtm/S//fZbRRqblPb3v+vKqVNSOPzHX3K5lJzfVzkbNhgpLK09z+duYAAAAMAdzLIs5eXlafz48S1FJRwOa+fOnTpV9g9d/v776KLy+xt0+ftT+m39egOJW4+yAgAAAMSZUCikgQMH6v9+rpR1owupwmH9u/xfsQ12iygrAAAAQJy56667NGLECCU3Nt70fcHq6hgl+msoKwAAAECcSuzc+baOm0ZZAQAAAOJU5oy/Sa4bnPK7XL8ftzHKCgAAABCnOs2apeT8vtcXlv/cDazTrFlmgrUSZQUAAACIU660NOVs2CDvvFIlZmVJLpcSs7LknVdq7LbFt4LnrAAAAACIKZ6zAgAAAOCORlkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuUFQAAAAC2RFkBAAAAYEuJpgPcTCQSkSTV1dUZTgIAAACgrVw7v792vn8jti4rgUBAkpSdnW04CQAAAIC2FggElJGRccPjVuR/1RmDwuGw/H6/3G63LMsyHeeOV1dXp+zsbJ07d04ej8d0HEdjLuyDubAP5sI+mAv7YC7sg7loW5FIRIFAQN27d5fLdeOdKbZeWXG5XOrRo4fpGHHH4/HwQ2YTzIV9MBf2wVzYB3NhH8yFfTAXbedmKyrXsMEeAAAAgC1RVgAAAADYEmXFQZKSkrRkyRIlJSWZjuJ4zIV9MBf2wVzYB3NhH8yFfTAXZth6gz0AAAAA52JlBQAAAIAtUVYAAAAA2BJlBQAAAIAtUVYAAAAA2BJlBQAAAIAtUVYc7MyZM5o8ebK8Xq88Ho+GDh2qL774wnQsR/roo4/k8/mUkpIir9eradOmmY7kaFeuXFFBQYEsy9KJEydMx3GcyspKlZSUKC8vTykpKerVq5eWLFmi5uZm09EcYdWqVcrLy1NycrIKCwu1b98+05EcZ/ny5XrggQfkdrvVpUsXTZkyRadPnzYdC/p9bizL0sKFC01HcQzKioNNnDhRwWBQu3bt0tGjR1VQUKBJkybp119/NR3NUbZu3ari4mLNmTNHX331lfbv36/HHnvMdCxHe+aZZ9S9e3fTMRzr1KlTCofDWrNmjU6ePKnXX39db7/9tl544QXT0eJeeXm5Fi5cqMWLF+v48eMaPny4JkyYoKqqKtPRHGXPnj0qLS3VoUOHVFFRoWAwqKKiIjU0NJiO5miHDx/W2rVrNWDAANNRHIXnrDhUTU2NOnfurL1792r48OGSpEAgII/Ho507d2rMmDGGEzpDMBhUbm6uXnrpJZWUlJiOA0mffPKJFi1apK1bt6pfv346fvy4CgoKTMdyvLKyMq1evVo//fST6ShxzefzadCgQVq9enXLWH5+vqZMmaLly5cbTOZs1dXV6tKli/bs2aOHHnrIdBxHqq+v16BBg7Rq1SotW7ZMBQUFeuONN0zHcgRWVhyqU6dOys/P14YNG9TQ0KBgMKg1a9YoKytLhYWFpuM5xrFjx3T+/Hm5XC4NHDhQ3bp104QJE3Ty5EnT0Rzp4sWLevLJJ/Xee+8pNTXVdBz8SW1trTp27Gg6Rlxrbm7W0aNHVVRUFDVeVFSkAwcOGEoF6fd//5L4GTCotLRUEydO1NixY01HcZxE0wFghmVZqqio0OTJk+V2u+VyuZSVlaUdO3YoMzPTdDzHuPZb4qVLl+q1115Tbm6uVqxYoREjRujMmTP8xxRDkUhEs2fP1ty5czV48GBVVlaajoT/+PHHH7Vy5UqtWLHCdJS4VlNTo1AopKysrKjxrKwsLg82KBKJaNGiRRo2bJj69+9vOo4jbd68WceOHdPhw4dNR3EkVlbizNKlS2VZ1k3/HDlyRJFIRE899ZS6dOmiffv26csvv9TkyZM1adIkXbhwwfS3ccdr7TyEw2FJ0uLFi/Xoo4+qsLBQ69atk2VZ2rJli+HvIj60di5Wrlypuro6Pf/886Yjx63WzsWf+f1+jR8/XtOnT9cTTzxhKLmzWJYV9ToSiVw3htiZN2+evv76a23atMl0FEc6d+6cFixYoI0bNyo5Odl0HEdiz0qcqampUU1NzU3fk5ubq/3796uoqEiXLl2Sx+NpOda7d2+VlJToueeea++oca2183Dw4EGNHj1a+/bt07Bhw1qO+Xw+jR07Vq+88kp7R417rZ2LmTNn6sMPP4w6KQuFQkpISNDjjz+u9evXt3fUuNfaubh2QuD3+zVq1Cj5fD69++67crn4/Vp7am5uVmpqqrZs2aKpU6e2jC9YsEAnTpzQnj17DKZzpvnz52vbtm3au3ev8vLyTMdxpG3btmnq1KlKSEhoGQuFQrIsSy6XS1euXIk6hrbHZWBxxuv1yuv1/s/3NTY2StJ1//m7XK6W3/bjr2vtPBQWFiopKUmnT59uKStXr15VZWWlcnJy2jumI7R2Lt566y0tW7as5bXf79e4ceNUXl4un8/XnhEdo7VzIUnnz5/XqFGjWlYbKSrt7+6771ZhYaEqKiqiysq1S4YRO5FIRPPnz9cHH3yg3bt3U1QMGjNmjL755puosTlz5qhv37569tlnKSoxQFlxqCFDhqhDhw6aNWuWXnzxRaWkpOidd97Rzz//rIkTJ5qO5xgej0dz587VkiVLlJ2drZycHJWVlUmSpk+fbjids/Ts2TPqdXp6uiSpV69e6tGjh4lIjuX3+zVy5Ej17NlTr776qqqrq1uOde3a1WCy+Ldo0SIVFxdr8ODBGjJkiNauXauqqirNnTvXdDRHKS0t1fvvv6/t27fL7Xa37BnKyMhQSkqK4XTO4na7r9srlJaWpk6dOrGHKEYoKw7l9Xq1Y8cOLV68WKNHj9bVq1fVr18/bd++Xffff7/peI5SVlamxMREFRcXq6mpST6fT7t27VKHDh1MRwOM+Oyzz3T27FmdPXv2uqLIlcvta8aMGfrtt9/08ssv68KFC+rfv78+/vhjVnpj7Nqto0eOHBk1vm7dOs2ePTv2gQCD2LMCAAAAwJa4CBgAAACALVFWAAAAANgSZQUAAACALVFWAAAAANgSZQUAAACALVFWAAAAANgSZQUAAACALVFWAAAAANgSZQUAAACALVFWAAAAANgSZQUAAACALf0/yAY3X/+9QxcAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "j = np.random.randint(train_size)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6), layout='constrained')\n",
    "ax.plot(target_coords[j][:, 0], target_coords[j][:, 1], linestyle='dotted', label='target sequence', zorder=1, color='grey')\n",
    "\n",
    "for i, index in enumerate(target_fields[j]):\n",
    "    if i == 0:\n",
    "        marker = '*'\n",
    "        s = 500\n",
    "        label='start'\n",
    "    elif i == len(target_fields[j])-1:\n",
    "        marker = 's'\n",
    "        s = 200\n",
    "        label='end'\n",
    "    else:\n",
    "        marker = 'o'\n",
    "        s = 30\n",
    "        label=None\n",
    "    ax.scatter(coords[j][index][0], coords[j][index][1], marker=marker, s=s, label=label)\n",
    "# fig.legend(bbox_to_anchor=(1.2, 1), loc='upper right')\n",
    "fig.legend()\n",
    "ax.set_title(f'Dataset {j}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37875af5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65685425, 5.09901951, 2.82842712, 3.60555128, 1.        ,\n",
       "       6.        , 4.47213595, 6.70820393, 1.41421356])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.sum((target_coords[0, :-1] - target_coords[0, 1:])**2, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ec225603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target_fields', 'target_coords', 'stepnum', 'nvisits'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69adb716",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2102578050.py, line 23)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mobs =\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from collections import namedtuple, deque\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Experience stores experience steps gathered in training\n",
    "# essentially maps (current state, action) to (next state, reward)\n",
    "Experience = namedtuple(\n",
    "    \"Experience\",\n",
    "    field_names=[\"obs\", \"action\", \"reward\", \"next_obs\", \"done\", \"action_mask\", \"next_action_mask\"],\n",
    ")\n",
    "\n",
    "# Stores experiences\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, capacity, device):\n",
    "        self.buffer = deque(maxlen=capacity)\n",
    "        self.device = device\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.buffer) \n",
    "    \n",
    "    def load_dataset(self, data_dict: Dict):\n",
    "        for i in \n",
    "        for i, episode in enumerate(t):\n",
    "            \n",
    "            obs = np.array([])\n",
    "            exp_args = \n",
    "            self.buffer.append(exp_args)\n",
    "\n",
    "    def append(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.buffer.append(Experience(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        indices = np.random.choice(len(self.buffer), batch_size, replace=False)\n",
    "        batch = [self.buffer[idx] for idx in indices]\n",
    "        batch = Experience(*zip(*batch))\n",
    "\n",
    "        return (\n",
    "            np.array(batch.obs, dtype=np.float32),\n",
    "            np.array(batch.action, dtype=np.float32),\n",
    "            np.array(batch.reward, dtype=np.float32),\n",
    "            np.array(batch.next_obs, dtype=np.float32),\n",
    "            np.array(batch.done, dtype=np.bool_),\n",
    "            np.array(batch.action_mask, dtype=bool),\n",
    "            np.array(batch.next_action_mask, dtype=bool)\n",
    "        )\n",
    "    \n",
    "    def reset(self):\n",
    "        self.buffer.clear()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3ea7e",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15791e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyEnv_v2(gym.Env):\n",
    "    def __init__(self, coords_dict, max_visits):\n",
    "        super().__init__()\n",
    "        # instantiate static attributes\n",
    "        self.coords_dict = coords_dict # field_id: (x,y)\n",
    "        self.nfields = len(coords_dict)\n",
    "        self.max_visits = max_visits\n",
    "        self.zenith = np.array([0.0, 0.0])\n",
    "        self.total_visits = int(self.nfields * self.max_visits)\n",
    "        self.average_theoret_dist = len(coords) * .52\n",
    "\n",
    "        # Initialize variable attributes - will be set in reset()\n",
    "        self._init_to_nonstate()\n",
    "       \n",
    "        # Define observation space - (step (size 1), coords (size 2), nvisits array)\n",
    "        self.obs_size = 3 + self.nfields\n",
    "\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=-1,\n",
    "            high=1e5,\n",
    "            shape=(self.obs_size,),\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        # Define action space        \n",
    "        self.action_space = gym.spaces.Discrete(self.nfields)\n",
    "\n",
    "    \n",
    "    # ------------------------------------------------------------ #\n",
    "    # -----------------------Gymnasium API ----------------------- #\n",
    "    # ------------------------------------------------------------ #\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Start a new episode.\n",
    "\n",
    "        Args:\n",
    "            seed: Random seed for reproducible episodes\n",
    "            options: Additional configuration (unused in this example)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, info) for the initial state\n",
    "        \"\"\"\n",
    "        # IMPORTANT: Must call this first to seed the random number generator\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # initialize into a non-state.\n",
    "        # this allows first field choice to be learned\n",
    "        self._init_to_nonstate()\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "        return obs, info\n",
    "    \n",
    "    def step(self, action: int):\n",
    "        \"\"\"Execute one timestep within the environment.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        assert self.action_space.contains(action), f\"Invalid action {action}\"\n",
    "        last_field_coord = self._coord\n",
    "        self._update_obs(action)\n",
    "        if self._step_count == 0:\n",
    "            last_field_coord = self.zenith\n",
    "        assert last_field_coord != np.array([None, None])\n",
    "        \n",
    "        if self._step_count < len(self.target_fields):\n",
    "            separation = get_distance(self._coord, last_field_coord)\n",
    "            # correct_field = self.target_fields[self._step_count]\n",
    "            if separation <= self.average_theoret_dist * .2:\n",
    "                reward = 1.0\n",
    "            elif separation <= self.average_theoret_dist:\n",
    "                reward = .25\n",
    "            elif separation <= self.average_theoret_dist * 1.5:\n",
    "                reward = .1\n",
    "            else:\n",
    "                reward = 0\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        # end condition\n",
    "        truncated = False\n",
    "        terminated = self._step_count + 1 >= self.total_visits\n",
    "\n",
    "        # get obs and info\n",
    "        obs = self._get_obs()\n",
    "        info = self._get_info()\n",
    "            \n",
    "        return obs, reward, terminated, truncated, info\n",
    "\n",
    "    # ------------------------------------------------------------ #\n",
    "    # -------------Convenience functions-------------------------- #\n",
    "    # ------------------------------------------------------------ #\n",
    "\n",
    "    def _init_to_nonstate(self):\n",
    "        self._step_count = -1\n",
    "        self._field_id = -1\n",
    "        self._nvisits = np.zeros(self.nfields, dtype=np.int32)\n",
    "        self._coord = np.array([None, None])\n",
    "        self._action_mask = np.ones(self.nfields, dtype=bool)\n",
    "\n",
    "    def _update_action_mask(self):\n",
    "        \"\"\"Update mask for cutting invalid actions.\n",
    "        Must update self._field and self._nvisits before updating actions\n",
    "        \"\"\"\n",
    "        self._action_mask = self._nvisits < self.max_visits\n",
    "\n",
    "    def _update_obs(self, action):\n",
    "        self._step_count += 1\n",
    "        self._field_id = action\n",
    "        self._nvisits[action] += 1\n",
    "        self._coord = np.array(self.coords_dict[action], dtype=np.float32) #TODO need to change for closest distance learning\n",
    "        self._update_action_mask()\n",
    "\n",
    "    def _get_obs(self):\n",
    "        \"\"\"Convert internal state to observation format.\n",
    "    \n",
    "        Returns:\n",
    "            dict: Observation with agent and target positions\n",
    "        \"\"\"\n",
    "        obs = np.concatenate((\n",
    "            np.array([self._step_count], dtype=np.float32),\n",
    "            np.array([self._coord], dtype=np.float32),\n",
    "            self._nvisits.astype(np.float32)\n",
    "        ))\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def _get_info(self):\n",
    "        \"\"\"Compute auxiliary information for debugging.\n",
    "\n",
    "        Returns:\n",
    "            \n",
    "        \"\"\"\n",
    "        return {'action_mask': self._action_mask.copy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0fb3e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment has issues: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)\n"
     ]
    }
   ],
   "source": [
    "# Register the environment so we can create it with gym.make()\n",
    "gym.register(\n",
    "    id=f\"gymnasium_env/{env_name}\",\n",
    "    entry_point=ToyEnv_v2,\n",
    "    max_episode_steps=300,  # Prevent infinite episodes. Here just set to 300 even though episode will terminate when stepping to last element of sequence\n",
    ")\n",
    "env = gym.make(f\"gymnasium_env/{env_name}\", coords_dict=coords_dict, max_visits=1)\n",
    "# Create multiple environments for parallel training\n",
    "# vec_env = gym.make_vec(\"gymnasium_env/SimpleTel-v0\", num_envs=5, vectorization_mode='sync', Nf=Nf, target_sequence=true_sequence, nv_max=nv_max)\n",
    "\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "# This will catch many common issues\n",
    "try:\n",
    "    check_env(env.unwrapped)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fb1c46b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m obs, info = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cosmoML/lib/python3.11/site-packages/gymnasium/wrappers/common.py:146\u001b[39m, in \u001b[36mTimeLimit.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    136\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Resets the environment with :param:`**kwargs` and sets the number of steps elapsed to zero.\u001b[39;00m\n\u001b[32m    137\u001b[39m \n\u001b[32m    138\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    143\u001b[39m \u001b[33;03m    The reset environment\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[38;5;28mself\u001b[39m._elapsed_steps = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cosmoML/lib/python3.11/site-packages/gymnasium/core.py:333\u001b[39m, in \u001b[36mWrapper.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\n\u001b[32m    330\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, seed: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    331\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cosmoML/lib/python3.11/site-packages/gymnasium/wrappers/common.py:400\u001b[39m, in \u001b[36mOrderEnforcing.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    398\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Resets the environment with `kwargs`.\"\"\"\u001b[39;00m\n\u001b[32m    399\u001b[39m \u001b[38;5;28mself\u001b[39m._has_reset = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cosmoML/lib/python3.11/site-packages/gymnasium/core.py:333\u001b[39m, in \u001b[36mWrapper.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreset\u001b[39m(\n\u001b[32m    330\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, seed: \u001b[38;5;28mint\u001b[39m | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m, options: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    331\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Uses the :meth:`reset` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cosmoML/lib/python3.11/site-packages/gymnasium/wrappers/common.py:293\u001b[39m, in \u001b[36mPassiveEnvChecker.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.checked_reset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m.checked_reset = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_reset_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    295\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.reset(seed=seed, options=options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/cosmoML/lib/python3.11/site-packages/gymnasium/utils/passive_env_checker.py:185\u001b[39m, in \u001b[36menv_reset_passive_checker\u001b[39m\u001b[34m(env, **kwargs)\u001b[39m\n\u001b[32m    180\u001b[39m     logger.deprecation(\n\u001b[32m    181\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCurrent gymnasium version requires that `Env.reset` can be passed `options` to allow the environment initialisation to be passed additional information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    182\u001b[39m     )\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# Checks the result of env.reset with kwargs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m result = \u001b[43menv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    188\u001b[39m     logger.warn(\n\u001b[32m    189\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThe result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(result)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    190\u001b[39m     )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 49\u001b[39m, in \u001b[36mToyEnv_v2.reset\u001b[39m\u001b[34m(self, seed, options)\u001b[39m\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# initialize into a non-state.\u001b[39;00m\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# this allows first field choice to be learned\u001b[39;00m\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m._init_to_nonstate()\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m obs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m info = \u001b[38;5;28mself\u001b[39m._get_info()\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obs, info\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 121\u001b[39m, in \u001b[36mToyEnv_v2._get_obs\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_obs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    116\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Convert internal state to observation format.\u001b[39;00m\n\u001b[32m    117\u001b[39m \n\u001b[32m    118\u001b[39m \u001b[33;03m    Returns:\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[33;03m        dict: Observation with agent and target positions\u001b[39;00m\n\u001b[32m    120\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m     obs = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_step_count\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_coord\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_nvisits\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m obs.astype(np.float32)\n",
      "\u001b[31mValueError\u001b[39m: all the input arrays must have same number of dimensions, but the array at index 0 has 1 dimension(s) and the array at index 1 has 2 dimension(s)"
     ]
    }
   ],
   "source": [
    "obs, info = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4456ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "def example_train(env, agent, dataset):\n",
    "    state_dim = env.obs_size\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    replay_buffer = ReplayBuffer()\n",
    "    replay_buffer.load(dataset)\n",
    "\n",
    "    max_action = float(env.action_space.high[0])\n",
    "\n",
    "    optimizer\n",
    "    scheduler\n",
    "\n",
    "    agent = DQNAgent()\n",
    "\n",
    "    def eval_actor(env, actor, device, n_episodes):\n",
    "        actor.eval()\n",
    "        episode_rewars = []\n",
    "        for _ in range(n_episodes):\n",
    "            state, info, done = env.reset(), False\n",
    "            episode_reward = 0.0\n",
    "            while not done:\n",
    "                action = actor.act(state, device)\n",
    "                state, reward, done, _ = env.step(action)\n",
    "                episode_reward += reward\n",
    "            epsisode_rewards.append(episode_reward)\n",
    "        actor.train()\n",
    "        return np.asarray(episode_rewards)\n",
    "        \n",
    "\n",
    "    for t_i in range(total_timesteps):\n",
    "        batch = replay_buffer.sample(batch_size)\n",
    "        batch = [b.to(device) for b in batch]\n",
    "        \n",
    "        # evaluate episode\n",
    "        if (t + 1) % eval_freq == 0:\n",
    "            eval_scores = eval_actor(\n",
    "                env,\n",
    "                actor,\n",
    "                device,\n",
    "                n_episodes,\n",
    "                seed\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "            eval_score = eval_scores.mean()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb420243",
   "metadata": {},
   "source": [
    "## Pytorch Agent and DQN implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cbcb4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(\n",
    "            self,\n",
    "            env: gym.Env, \n",
    "            replay_buffer: ReplayBuffer, \n",
    "            # net: nn.Module,\n",
    "            device,\n",
    "            ):\n",
    "        \"\"\"Base Agent class handling the interaction with the environment.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.replay_buffer = replay_buffer\n",
    "        n_observations = len(self.env.reset()[0])\n",
    "        n_actions = self.env.action_space.n\n",
    "        self.policy_net = DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net = DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.training_phase = True\n",
    "\n",
    "        self.reset()\n",
    "        self.steps_done = 0\n",
    "        self.device = device\n",
    "        self.start_time = time.time()\n",
    "\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the environment and updates the state.\"\"\"\n",
    "        self.obs, self.info = self.env.reset()\n",
    "\n",
    "    def select_action(self, epsilon: float) -> int:\n",
    "        \"\"\"Using the given network, decide what action to carry out using an epsilon-greedy policy.\n",
    "\n",
    "        Args:\n",
    "            net: DQN network\n",
    "            epsilon: value to determine likelihood of taking a random action\n",
    "            device: current device\n",
    "\n",
    "        Returns:\n",
    "            action\n",
    "\n",
    "        \"\"\"\n",
    "        # if random sample less than epsilon, take random action\n",
    "        if self.training_phase and np.random.random() < epsilon:\n",
    "            valid_actions = np.where(self.info['action_mask'])[0]\n",
    "            action = self.env.np_random.choice(valid_actions)\n",
    "            return action\n",
    "\n",
    "        # get action given obs using policy\n",
    "        obs = torch.tensor(self.obs)\n",
    "        if self.device == torch.device('cuda'):\n",
    "            obs = obs.cuda(self.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            obs_tensor = obs.unsqueeze(0)\n",
    "            q_values = self.policy_net(obs_tensor).squeeze(0)\n",
    "\n",
    "            # Apply mask: set invalid actions to -inf\n",
    "            masked_q_values = q_values.clone()\n",
    "            masked_q_values[torch.tensor(~self.info['action_mask'])] = float('-inf')\n",
    "            action = torch.argmax(masked_q_values).item()\n",
    "            # action = int(action.item())\n",
    "        return action\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def play_step(\n",
    "        self,\n",
    "        epsilon: float = 0.0,\n",
    "    ) -> Tuple[float, bool]:\n",
    "        \"\"\"Carries out a single interaction step between dthe agent and the environment.\n",
    "\n",
    "        Args:\n",
    "            net: DQN network\n",
    "            epsilon: value to determine likelihood of taking a random action\n",
    "\n",
    "        Returns:\n",
    "            reward, done\n",
    "\n",
    "        \"\"\"\n",
    "        action_mask = self.info['action_mask']\n",
    "        # select action\n",
    "        action = self.select_action(epsilon)\n",
    "\n",
    "        # interact with environment\n",
    "        next_obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "        next_action_mask = info['action_mask']\n",
    "\n",
    "        # save to experiences\n",
    "        exp_args = self.obs, action, reward, next_obs, terminated, action_mask, next_action_mask\n",
    "        self.replay_buffer.append(*exp_args)\n",
    "\n",
    "        # set next_obs to current obs for next step\n",
    "        self.obs = next_obs\n",
    "        self.info = info\n",
    "\n",
    "        # if finished survey, reset\n",
    "        if terminated or truncated:\n",
    "            self.reset()\n",
    "        return reward, terminated\n",
    "    \n",
    "    def predict(self, nsteps):\n",
    "        obs = []\n",
    "        for t_i in nsteps:\n",
    "            reward, terminated = self.play_step()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27180848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(\n",
    "            self,\n",
    "            env: gym.Env, \n",
    "            replay_buffer: ReplayBuffer, \n",
    "            device,\n",
    "            ):\n",
    "        \"\"\"Base Agent class handling the interaction with the environment.\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.replay_buffer = replay_buffer\n",
    "        self.device = device\n",
    "\n",
    "        # get obs and action dims for network construction\n",
    "        obs, _ = self.env.reset()\n",
    "        n_observations = len(obs)\n",
    "        n_actions = self.env.action_space.n\n",
    "\n",
    "        # initialize networks\n",
    "        self.policy_net = DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net = DQN(n_observations, n_actions).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "\n",
    "        self.reset()\n",
    "        self.steps_done = 0\n",
    "\n",
    "\n",
    "    def reset(self) -> None:\n",
    "        \"\"\"Resets the environment and updates the state.\"\"\"\n",
    "        self.obs, self.info = self.env.reset()\n",
    "\n",
    "    def select_action(self, epsilon: float) -> int:\n",
    "        \"\"\"\n",
    "        Epsilon-greedy action selection\n",
    "        \"\"\"\n",
    "        # if random sample less than epsilon, take random action\n",
    "        if np.random.random() < epsilon:\n",
    "            valid_actions = np.where(self.info['action_mask'])[0]\n",
    "            action = np.random.choice(valid_actions)\n",
    "            return int(action)\n",
    "\n",
    "        # greedy selection from policy\n",
    "        obs = torch.tensor(self.obs, dtype=torch.float32, device=self.device).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            q_values = self.policy_net(obs).squeeze(0)\n",
    "\n",
    "            # mask invalid actions\n",
    "            mask = torch.tensor(self.info['action_mask'], device=self.device, dtype=torch.bool)\n",
    "            q_values[~mask] = float('-inf')\n",
    "            action = torch.argmax(q_values).item()\n",
    "        return int(action)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def play_step(\n",
    "        self,\n",
    "        epsilon: float = 0.0,\n",
    "        buffer=None,\n",
    "    ) -> Tuple[float, bool]:\n",
    "        \"\"\"\n",
    "        Carries out a single interaction step between the agent and the environment and records experience\n",
    "        \"\"\"\n",
    "        # select action\n",
    "        action = self.select_action(epsilon)\n",
    "\n",
    "        # interact with environment\n",
    "        next_obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        exp_args = (\n",
    "            self.obs,\n",
    "            action,\n",
    "            reward,\n",
    "            next_obs,\n",
    "            terminated,\n",
    "            self.info[\"action_mask\"],\n",
    "            info[\"action_mask\"],\n",
    "        )\n",
    "        \n",
    "        # if predicting\n",
    "        if buffer is None:\n",
    "            self.replay_buffer.append(*exp_args)\n",
    "        else: # training\n",
    "            buffer.append(*exp_args)\n",
    "\n",
    "        # reset or move to next obs\n",
    "        if terminated or truncated:\n",
    "            self.reset()\n",
    "        else:\n",
    "            # set next_obs to current obs for next step\n",
    "            self.obs = next_obs\n",
    "            self.info = info\n",
    "\n",
    "        return reward, terminated\n",
    "\n",
    "    \n",
    "    def predict(self, max_timesteps):\n",
    "        \"\"\"\n",
    "        Rolls out policy.\n",
    "\n",
    "        Returns\n",
    "        ------\n",
    "        buffer: ReplayBuffer\n",
    "            Memory of this roll-out\n",
    "        log: Dict\n",
    "            Contains quantities that might be useful for diagnostics\n",
    "        \"\"\"\n",
    "        log = {\n",
    "            'rewards': [],\n",
    "            'obs': [],\n",
    "            'terminated': [],\n",
    "            'action_mask': []\n",
    "            }\n",
    "        \n",
    "        self.reset()\n",
    "        buffer = ReplayBuffer(max_timesteps, device=self.device)\n",
    "        for _ in range(max_timesteps):\n",
    "            reward, terminated = self.play_step(epsilon=0, buffer=buffer)\n",
    "\n",
    "            log['rewards'].append(reward)\n",
    "            log['terminated'].append(terminated)\n",
    "            log['obs'].append(self.obs)\n",
    "            log['action_mask'].append(self.info['action_mask'])\n",
    "\n",
    "            if terminated:\n",
    "                break\n",
    "        return buffer, log\n",
    "    \n",
    "    def evaluate_policy(self):\n",
    "        action = self.select_action(epsilon=0)\n",
    "        obs, \n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91830795-b43e-4d67-826b-2a489c2b54b9",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef577812",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Callable\n",
    "\n",
    "def train_agent(\n",
    "        agent: DQNAgent,\n",
    "        total_timesteps: int,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        gamma: float,\n",
    "        eps_scheduler_kwargs: dict[str, int | str],\n",
    "        tau: float,\n",
    "        eps_scheduler: Callable,\n",
    "        learn_start: int,\n",
    "        train_freq: int, #4\n",
    "        target_freq: int,\n",
    "        optimizer_kwargs: Dict = {},\n",
    "        lr_scheduler_kwargs: Dict = {},\n",
    "        wandb_run=None\n",
    "        ):\n",
    "    \"\"\"\n",
    "    Trains a DQN agent.\n",
    "    \n",
    "    Args\n",
    "    -----\n",
    "    agent: DQNAgent\n",
    "    total_timesteps: int\n",
    "        Total number of timesteps through which to step agent through environment.\n",
    "        Number of episodes is total_timesteps // episode_steps\n",
    "    lr: float\n",
    "    batch_size: int\n",
    "    gamma: float\n",
    "    eps_scheduler_kwargs: dict[str, int | str]\n",
    "        arguments for epsilon scheduling method\n",
    "    tau: float\n",
    "    eps_scheduler: Callable,\n",
    "        Function that calculates epsilon at each time step\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "        Optimizer for neural network. Adamw is recommended.\n",
    "    optimizer_kwargs: Dict,\n",
    "        Kwargs for chosen optimizer\n",
    "    learn_start: int\n",
    "        Time step at which updates to policy network and target network \n",
    "    train_freq: int, #4\n",
    "        Number of time steps between policy network updates  \n",
    "    target_freq: int\n",
    "        Number of time steps between target network updates\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    agent.reset()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(agent.policy_net.parameters(), lr=lr, amsgrad=False, **optimizer_kwargs)\n",
    "\n",
    "    if not lr_scheduler_kwargs:\n",
    "        T_max = (total_timesteps - learn_start) // train_freq\n",
    "        lr_scheduler_kwargs = {'T_max': total_timesteps - learn_start, 'eta_min': 1e-6}\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **lr_scheduler_kwargs)\n",
    "    device = agent.device\n",
    "    loss_history = []\n",
    "\n",
    "    for t_i in range(total_timesteps):\n",
    "        # set epsilon according to scheduler\n",
    "        epsilon = eps_scheduler(t=t_i, **eps_scheduler_kwargs)\n",
    "        if wandb_run:\n",
    "            wandb_run.log({'epsilon': epsilon}, step=t_i)\n",
    "\n",
    "        # agent performs step in environment and sees next observation\n",
    "        reward, terminated = agent.play_step(epsilon)\n",
    "        \n",
    "        # train - use temporal difference between new obs and last obs to update Q-values\n",
    "        if t_i > learn_start and batch_size <= len(agent.replay_buffer) and (t_i % train_freq == 0):\n",
    "            # sample from experiences\n",
    "            obs, actions, rewards, next_obs, dones, _, next_action_masks = agent.replay_buffer.sample(batch_size)\n",
    "            \n",
    "            # convert to tensors\n",
    "            obs = torch.tensor(np.array(obs), device=device, dtype=torch.float32)\n",
    "            actions = torch.tensor(actions, device=device, dtype=torch.long).unsqueeze(1)\n",
    "            rewards = torch.tensor(rewards, device=device, dtype=torch.float32)\n",
    "            dones = torch.tensor(dones, device=device, dtype=torch.float32)\n",
    "            next_obs = torch.tensor(np.array(next_obs), device=device, dtype=torch.float32)\n",
    "\n",
    "            # wandb_run.log({'batch_rewards': rewards}, step=t_i)\n",
    "            # get current q vals\n",
    "            q_vals = agent.policy_net(obs)\n",
    "            current_q = q_vals.gather(1, actions).squeeze()\n",
    "\n",
    "            # print('gamma', gamma)\n",
    "            # print('(1) current_obs', next_obs)\n",
    "            # print('(2) current q', current_q)\n",
    "            # print('(3) next_obs', next_obs)\n",
    "\n",
    "            with torch.no_grad():\n",
    "            # gets maximally valued action for each observation in batch\n",
    "                next_q = agent.target_net(next_obs)\n",
    "                # print('(4) next_q',  next_q)\n",
    "\n",
    "                # mask invalid actions\n",
    "                mask_tensor = torch.tensor(next_action_masks, device=device, dtype=torch.bool)\n",
    "                next_q[~mask_tensor] = -1e9# float('-inf')\n",
    "                # print('(5) mask_tensor',  mask_tensor)\n",
    "                # print('(6) masked next_q',  next_q)\n",
    "\n",
    "                # wandb_run.log({'masked next q': next_q},step=t_i)\n",
    "\n",
    "                max_next_q = next_q.max(dim=1)[0]\n",
    "                # print('(7) max_masked_next_q', max_next_q)\n",
    "\n",
    "                td_target = rewards + gamma * max_next_q * (1 - dones) # , dtype=torch.float32, device=device\n",
    "\n",
    "            \n",
    "            # print('td_target', td_target)\n",
    "            loss = F.mse_loss(current_q, td_target)\n",
    "            if wandb_run:\n",
    "                wandb_run.log({'loss': loss.item()}, step=t_i)\n",
    "            loss_history.append(loss.item())\n",
    "\n",
    "            # optimize w/ backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(agent.policy_net.parameters(), max_norm=1.)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # update target network\n",
    "            if t_i % target_freq == 0:\n",
    "                for target_param, param in zip(agent.target_net.parameters(), agent.policy_net.parameters()):\n",
    "                    target_param.data.copy_(tau * param.data + (1.0 - tau) * target_param.data)\n",
    "    if not wandb_run:\n",
    "        env.close()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43feafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 32,\n",
    "    'gamma': .99,\n",
    "    'eps_scheduler_kwargs': {'eps_start': .9, 'eps_end': .01, 'decay_rate': 2500},\n",
    "    'tau': .005,\n",
    "    'lr': 1e-2,\n",
    "    'total_timesteps': 10000,\n",
    "    'learn_start': 100,\n",
    "    'train_freq': 4,\n",
    "    'target_freq': 100\n",
    "}\n",
    "\n",
    "agent = DQNAgent(\n",
    "    env=env,\n",
    "    replay_buffer=ReplayBuffer(capacity=100000, device=device),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8daa80",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = train_agent(\n",
    "    agent=agent,\n",
    "    eps_scheduler=exponential_schedule,\n",
    "    **config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00a8e7fb",
   "metadata": {},
   "source": [
    "# Train agent on offline data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9754b0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_agent_offline(\n",
    "        agent: DQNAgent,\n",
    "        total_timesteps: int,\n",
    "        lr: float,\n",
    "        batch_size: int,\n",
    "        gamma: float,\n",
    "        eps_scheduler_kwargs: dict[str, int | str],\n",
    "        tau: float,\n",
    "        eps_scheduler: Callable,\n",
    "        learn_start: int,\n",
    "        train_freq: int, #4\n",
    "        target_freq: int,\n",
    "        optimizer_kwargs: Dict = {},\n",
    "        lr_scheduler_kwargs: Dict = {},\n",
    "        wandb_run=None\n",
    "        ):\n",
    "    device = agent.device\n",
    "    agent.reset()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(agent.policy_net.parameters(), lr=lr, amsgrad=False, **optimizer_kwargs)\n",
    "\n",
    "    if not lr_scheduler_kwargs:\n",
    "        T_max = (total_timesteps - learn_start) // train_freq\n",
    "        lr_scheduler_kwargs = {'T_max': total_timesteps - learn_start, 'eta_min': 1e-6}\n",
    "        \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **lr_scheduler_kwargs)\n",
    "    device = agent.device\n",
    "    loss_history = []\n",
    "\n",
    "    for t_i in range(total_timesteps):\n",
    "\n",
    "        # ----------------- get loss: loss = train_agent() ------------------ #\n",
    "        obs, actions, rewards, next_obs, dones, _, next_action_masks = agent.replay_buffer.sample(batch_size)\n",
    "        \n",
    "        # convert to tensors #TODO move conversion to tensor to replay buffer\n",
    "        obs = torch.tensor(np.array(obs), device=device, dtype=torch.float32)\n",
    "        actions = torch.tensor(actions, device=device, dtype=torch.long).unsqueeze(1)\n",
    "        rewards = torch.tensor(rewards, device=device, dtype=torch.float32)\n",
    "        dones = torch.tensor(dones, device=device, dtype=torch.float32)\n",
    "        next_obs = torch.tensor(np.array(next_obs), device=device, dtype=torch.float32)\n",
    "\n",
    "        # get q-vals for actions taken in dataset\n",
    "        q_vals = agent.policy_net(obs)\n",
    "        q_vals_data = q_vals.gather(1, actions).squeeze()\n",
    "\n",
    "        \"\"\"Using DDQN here\"\"\"\n",
    "        with torch.no_grad():\n",
    "            # use policy net to select the next best action\n",
    "            next_q_vals = agent.policy_net(next_obs)\n",
    "            mask_tensor = torch.tensor(next_action_masks, device=device, dtype=torch.bool)\n",
    "            next_q_vals[~mask_tensor] = -1e9\n",
    "            best_actions = next_q_vals.max(1)[1].unsqueeze(-1)\n",
    "\n",
    "            # estimate q-value using target net\n",
    "            next_q_vals = agent.target_net(next_obs).gather(1, best_actions)\n",
    "\n",
    "            td_target = rewards + gamma * next_q_vals * (1 - dones) # , dtype=torch.float32, device=device\n",
    "\n",
    "        loss = F.mse_loss(q_vals_data, td_target)\n",
    "        if wandb_run:\n",
    "            wandb_run.log({'loss': loss.item()}, step=t_i)\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "        # optimize w/ backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(agent.policy_net.parameters(), max_norm=1.)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        # ----------------- get loss: loss = train_agent() ------------------ #\n",
    "\n",
    "        if t_i % target_freq == 0 and loss is not None: #TODO needed?\n",
    "            agent.target_net.load_state_dict(agent.policy_net.state_dict())\n",
    "    if not wandb_run:\n",
    "        env.close()\n",
    "    return loss_history\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228424d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f98bab5b",
   "metadata": {},
   "source": [
    "#  Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e82c0a-5e65-49f2-abea-bf3200d2994f",
   "metadata": {},
   "source": [
    "# Tune hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
