{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0c564147-dfec-4075-963e-541d9e9a0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a74d08ff-a1e7-4564-8dcf-ad27266dc8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 1, 0, 3, 3, 0, 1, 4, 4, 5, 3, 4, 5, 2, 4, 5, 1, 2, 2, 1, 2, 5, 0, 0]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nf = 6\n",
    "T = 100\n",
    "nv_max = 4\n",
    "random.seed(2)\n",
    "true_actions = np.array([np.full(4, i) for i in range(Nf)]).flatten()\n",
    "true_actions = true_actions.tolist()\n",
    "random.shuffle(true_actions)\n",
    "true_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c96c76cc-8472-487d-bb3a-f7df8d57e089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_actions == true_actions[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "562ef95b-b769-4377-9b62-7dde675a6142",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "':' expected after dictionary key (2875554107.py, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[52], line 54\u001b[0;36m\u001b[0m\n\u001b[0;31m    \"\"\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m ':' expected after dictionary key\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.spaces import Dict, Box, Discrete\n",
    "\n",
    "from typing import Optional\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SimpleTelEnv(gym.Env):\n",
    "    def __init__(self, Nf, T, target_sequence, nv_max, starting_field_id):\n",
    "        self.Nf = Nf # number of fields\n",
    "        self.T = 1 # 28800sec = 8hrs\n",
    "        self.nv_max = nv_max\n",
    "        self.target_sequence = target_sequence if target_sequence is not None else np.arange(0, Nf, 1, dtype=int)\n",
    "        # \"Teff_meas\": Box(0, 1, shape=(Nf,), dtype=np.float32),\n",
    "\n",
    "        #TODO\n",
    "        # Initialize positions - will be set in reset()\n",
    "        self._field_id = -1\n",
    "        # self._t = -1\n",
    "        self._nvisits = np.full(shape=(Nf,), fill_value=-1, dtype=int)\n",
    "        # self._Teff_pred = np.full(shape=(Nf,), fill_value=-1, dtype=np.float32)\n",
    "        self._step_num = -1\n",
    "        self._sequence = []\n",
    "\n",
    "        # Map action numbers to actual movements on the grid\n",
    "        self._possible_actions = [i for i in range(Nf)]\n",
    "\n",
    "        #TODO\n",
    "        # Define what the agent can observe\n",
    "        # Dict space gives us structured, human-readable observations\n",
    "        self.observation_space = gym.spaces.Dict(\n",
    "            {\n",
    "                # \"t\": Box(0, T, shape=None, dtype=np.float32),\n",
    "                \"field_id\": Discrete(n=Nf, start=0),\n",
    "                \"nvisits\": Box(0, 4, shape=(Nf,), dtype=int),\n",
    "                # \"Teff_pred\": Box(0, 1, shape=(Nf,), dtype=np.float32),\n",
    "                    #filter\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.action_space = gym.spaces.Discrete(self.Nf)\n",
    "\n",
    "        # remove fields that have \n",
    "        \n",
    "    def _get_obs(self,):\n",
    "        \"\"\"Convert internal state to observation format.\n",
    "    \n",
    "        Returns:\n",
    "            dict: Observation with agent and target positions\n",
    "        \"\"\"\n",
    "        return {\n",
    "            # \"t\": self._t,\n",
    "            \"field_id\": self._field_id,\n",
    "            \"nvisits\": self._nvisits,\n",
    "            \"\"\n",
    "            # \"Teff_pred\": self._Teff_pred,\n",
    "        }\n",
    "\n",
    "    def _get_info(self):\n",
    "        \"\"\"Compute auxiliary information for debugging.\n",
    "\n",
    "        Returns:\n",
    "            \n",
    "        \"\"\"\n",
    "        return {}\n",
    "\n",
    "    def reset(self, seed: Optional[int] = None, options: Optional[dict] = None):\n",
    "        \"\"\"Start a new episode.\n",
    "\n",
    "        Args:\n",
    "            seed: Random seed for reproducible episodes\n",
    "            options: Additional configuration (unused in this example)\n",
    "\n",
    "        Returns:\n",
    "            tuple: (observation, info) for the initial state\n",
    "        \"\"\"\n",
    "        # IMPORTANT: Must call this first to seed the random number generator\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        # Randomly choose initial field id and set time to 0\n",
    "        self._field_id = self.starting_field_id\n",
    "        # self._field_id = self.np_random.integers(0, self.Nf, size=1, dtype=int)[0]\n",
    "        # self._t = np.array([0.0], dtype=np.float32)\n",
    "        self._nvisits = np.full(shape=(self.Nf,), fill_value=0, dtype=int)\n",
    "        # self._Teff_pred = np.linspace(0.1, .98, num=self.Nf, dtype=np.float32)\n",
    "        self._step_num = 0\n",
    "\n",
    "        self._sequence = [self._field_id]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, info\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Execute one timestep within the environment.\n",
    "\n",
    "        Args:\n",
    "\n",
    "        Returns:\n",
    "        \"\"\"\n",
    "        # choose random field for next observation\n",
    "        list_idx = self.np_random.integers(low=0, high=len(self._possible_actions), dtype=int)\n",
    "        proposed_field = self._possible_actions[list_idx]\n",
    "        self._nvisits[proposed_field] += 1\n",
    "        self._field_id = proposed_field\n",
    "\n",
    "        # if this is the last required observation for this field, remove it from possible actions list\n",
    "        if self._nvisits[proposed_field] == self.nv_max:\n",
    "            self._possible_actions.pop(list_idx)\n",
    "\n",
    "        survey_complete = (len(self._sequence) == len(self.target_sequence))\n",
    "        \n",
    "        terminated = self._sequence == self.target_sequence\n",
    "        \n",
    "        if survey_complete and not terminated:\n",
    "            truncated = True\n",
    "        \n",
    "        # Simple reward structure: +1 for reaching target, 0 otherwise\n",
    "        is_exact = self._field_id == self.target_sequence[self._step_num]\n",
    "        is_off_by_one = np.abs(self._field_id - self.target_sequence[self._step_num]) == 1\n",
    "\n",
    "        if not terminated:\n",
    "            if is_exact:\n",
    "                \n",
    "        if is_exact:\n",
    "            reward = .5\n",
    "        elif is_off_by_one:\n",
    "            reward = .1\n",
    "        else:\n",
    "            reward = 0\n",
    "\n",
    "        # automatically update possible actions dict to remove this field if it has been visited 4 times\n",
    "        self.step_num += 1\n",
    "        \n",
    "        if (self._nvisits == self.nv_max).all()\n",
    "            self.reset()\n",
    "\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        info = self._get_info()\n",
    "\n",
    "        return observation, reward, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d812d320-18fb-482f-9d0b-1a16e2795450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 5, 1, 3, 4, 0, 3, 2, 1, 2, 1, 4, 0, 0, 1, 5, 4, 4, 2, 5, 3,\n",
       "       3, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec9a9da7-3f3e-4a06-b9be-3e68b8f0e7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register the environment so we can create it with gym.make()\n",
    "gym.register(\n",
    "    id=\"gymnasium_env/SimpleTel-v0\",\n",
    "    entry_point=SimpleTelEnv,\n",
    "    max_episode_steps=300,  # Prevent infinite episodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ec4b16d-2a90-4f62-a011-754c63b70061",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"gymnasium_env/SimpleTel-v0\", Nf=Nf, T=T, target_sequence=true_actions, nv_max=nv_max)\n",
    "# Create multiple environments for parallel training\n",
    "# vec_env = gym.make_vec(\"gymnasium_env/GridWorld-v0\", num_envs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cce1337d-2b46-43ff-a287-43417a486b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment passes all checks!\n"
     ]
    }
   ],
   "source": [
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "# This will catch many common issues\n",
    "try:\n",
    "    check_env(env.unwrapped)\n",
    "    print(\"Environment passes all checks!\")\n",
    "except Exception as e:\n",
    "    print(f\"Environment has issues: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4187dd5-3916-4443-8a20-2460d1baa3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cosmo_ml",
   "language": "python",
   "name": "cosmo_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
